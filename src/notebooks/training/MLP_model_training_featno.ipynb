{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbbcf75e-6cd4-4aef-ac03-a446902b7cf5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01manndata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mad\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpickle\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpkl\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mMLP_evaluator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_models_results\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluator_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m l2_loss\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import anndata as ad\n",
    "import pickle as pkl\n",
    "\n",
    "from src.evaluator.MLP_evaluator import get_models_results\n",
    "from src.evaluator.evaluator_utils import l2_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b95bdc9c-882f-4e2b-8c2f-70cedec6bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_different_featno(adata_path=None, run_name=None, res_savename=None, input_dim=None, output_dim=None):\n",
    "    DRUG_ENCODING_NAME = \"fmfp\"\n",
    "    DRUG_ENCODING_SIZE = 1024\n",
    "    N_TRIALS = 50\n",
    "    SCHEDULER_MODE = 'min'\n",
    "\n",
    "    with open(\"./data/drug_splits/train_drugs_rand.pkl\", 'rb') as f:\n",
    "        drugs_train_rand = pkl.load(f)\n",
    "\n",
    "    with open(\"./data/drug_splits/val_drugs_rand.pkl\", 'rb') as f:\n",
    "        drugs_val_rand = pkl.load(f)\n",
    "\n",
    "    with open(\"./data/drug_splits/test_drugs_rand.pkl\", 'rb') as f:\n",
    "        drugs_test_rand = pkl.load(f)\n",
    "\n",
    "    drug_splits = dict()\n",
    "    drug_splits['train'] = drugs_train_rand\n",
    "    drug_splits['valid'] = drugs_val_rand\n",
    "    drug_splits['test'] = drugs_test_rand\n",
    "\n",
    "    adata = ad.read_h5ad(adata_path)\n",
    "\n",
    "    get_models_results(drug_splits=drug_splits,\n",
    "                          loss_function=l2_loss,\n",
    "                          adata=adata,\n",
    "                          input_dim=input_dim,\n",
    "                          output_dim=output_dim,\n",
    "                          drug_rep_name=DRUG_ENCODING_NAME,\n",
    "                          drug_emb_size=DRUG_ENCODING_SIZE,\n",
    "                          n_trials=N_TRIALS,\n",
    "                          scheduler_mode=SCHEDULER_MODE,\n",
    "                          run_name=run_name,\n",
    "                          save_path=res_savename,\n",
    "                          add_relu=True\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dd3ea7e-bc21-4f89-8d73-eb59dbfadff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Datasets ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401917/401917 [03:05<00:00, 2162.11it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401917/401917 [01:13<00:00, 5441.96it/s]\n",
      "[I 2025-06-18 12:16:22,461] A new study created in RDB with name: mlp_hvg_500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing Hyperparameters with Optuna ...\n",
      "Epoch:\t 0 Val Loss:\t 0.03604320379219638\n",
      "Epoch:\t 1 Val Loss:\t 0.03647944459937202\n",
      "Epoch:\t 2 Val Loss:\t 0.03639627547509417\n",
      "Epoch:\t 3 Val Loss:\t 0.03625103992999942\n",
      "Epoch:\t 4 Val Loss:\t 0.036146133072027437\n",
      "Epoch:\t 5 Val Loss:\t 0.03616646544295109\n",
      "Epoch:\t 6 Val Loss:\t 0.036119568470110844\n",
      "Epoch:\t 7 Val Loss:\t 0.036087531889893616\n",
      "Epoch:\t 8 Val Loss:\t 0.03601778980787736\n",
      "Epoch:\t 9 Val Loss:\t 0.03627077741039336\n",
      "Epoch:\t 10 Val Loss:\t 0.036098425063960424\n",
      "Epoch:\t 11 Val Loss:\t 0.03624313283364298\n",
      "Epoch:\t 12 Val Loss:\t 0.03614858539709133\n",
      "Epoch:\t 13 Val Loss:\t 0.03606382787970293\n",
      "Epoch:\t 14 Val Loss:\t 0.036161963531442014\n",
      "Epoch:\t 15 Val Loss:\t 0.03600762937804894\n",
      "Epoch:\t 16 Val Loss:\t 0.03607207453447331\n",
      "Epoch:\t 17 Val Loss:\t 0.03608266689434312\n",
      "Epoch:\t 18 Val Loss:\t 0.03614292048229282\n",
      "Epoch:\t 19 Val Loss:\t 0.03615481744840789\n",
      "Epoch:\t 20 Val Loss:\t 0.036189854743971316\n",
      "Epoch:\t 21 Val Loss:\t 0.03608942449308477\n",
      "Epoch:\t 22 Val Loss:\t 0.03596261895330581\n",
      "Epoch:\t 23 Val Loss:\t 0.036140726573789236\n",
      "Epoch:\t 24 Val Loss:\t 0.0359724785988833\n",
      "Epoch:\t 25 Val Loss:\t 0.03612001204318172\n",
      "Epoch:\t 26 Val Loss:\t 0.036152804000872125\n",
      "Epoch:\t 27 Val Loss:\t 0.03599626200806673\n",
      "Epoch:\t 28 Val Loss:\t 0.036051787501889795\n",
      "Epoch:\t 29 Val Loss:\t 0.03608609835985581\n",
      "Epoch:\t 30 Val Loss:\t 0.036059364969946946\n",
      "Epoch:\t 31 Val Loss:\t 0.03607864188587359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:17:16,203] Trial 0 finished with value: 0.03596261895330581 and parameters: {'lr': 0.001, 'weight_decay': 0.001, 'scheduler_factor': 0.1, 'scheduler_patience': 10, 'batch_size': 256, 'dropout': 0.15, 'hidden_dims': 1024}. Best is trial 0 with value: 0.03596261895330581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 32 Val Loss:\t 0.036150687586791644\n",
      "Epoch:\t 0 Val Loss:\t 0.035262776605532606\n",
      "Epoch:\t 1 Val Loss:\t 0.03517082932887909\n",
      "Epoch:\t 2 Val Loss:\t 0.03516092370789512\n",
      "Epoch:\t 3 Val Loss:\t 0.03519663018510537\n",
      "Epoch:\t 4 Val Loss:\t 0.035213203563132296\n",
      "Epoch:\t 5 Val Loss:\t 0.0351970288387504\n",
      "Epoch:\t 6 Val Loss:\t 0.03514785990432469\n",
      "Epoch:\t 7 Val Loss:\t 0.03521427960047154\n",
      "Epoch:\t 8 Val Loss:\t 0.03521955643312722\n",
      "Epoch:\t 9 Val Loss:\t 0.035254226473520785\n",
      "Epoch:\t 10 Val Loss:\t 0.035228751850579595\n",
      "Epoch:\t 11 Val Loss:\t 0.03516889295865994\n",
      "Epoch:\t 12 Val Loss:\t 0.03519169475224173\n",
      "Epoch:\t 13 Val Loss:\t 0.03519844716689858\n",
      "Epoch:\t 14 Val Loss:\t 0.035329598584328985\n",
      "Epoch:\t 15 Val Loss:\t 0.035331560274915616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:21:39,844] Trial 1 finished with value: 0.03514785990432469 and parameters: {'lr': 0.001, 'weight_decay': 1e-06, 'scheduler_factor': 0.3, 'scheduler_patience': 5, 'batch_size': 16, 'dropout': 0.05, 'hidden_dims': 64}. Best is trial 1 with value: 0.03514785990432469.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 16 Val Loss:\t 0.03539593773049645\n",
      "Epoch:\t 0 Val Loss:\t 0.036332862612181056\n",
      "Epoch:\t 1 Val Loss:\t 0.03579529764462927\n",
      "Epoch:\t 2 Val Loss:\t 0.035751859604088006\n",
      "Epoch:\t 3 Val Loss:\t 0.03548951731296723\n",
      "Epoch:\t 4 Val Loss:\t 0.035448316636239596\n",
      "Epoch:\t 5 Val Loss:\t 0.03531028186465671\n",
      "Epoch:\t 6 Val Loss:\t 0.035237885959341915\n",
      "Epoch:\t 7 Val Loss:\t 0.035218085037294275\n",
      "Epoch:\t 8 Val Loss:\t 0.03519860820654399\n",
      "Epoch:\t 9 Val Loss:\t 0.0351780203643268\n",
      "Epoch:\t 10 Val Loss:\t 0.035151195623174696\n",
      "Epoch:\t 11 Val Loss:\t 0.035103574694546766\n",
      "Epoch:\t 12 Val Loss:\t 0.0351321895183148\n",
      "Epoch:\t 13 Val Loss:\t 0.03513819799349757\n",
      "Epoch:\t 14 Val Loss:\t 0.03514433173026016\n",
      "Epoch:\t 15 Val Loss:\t 0.03518305586908528\n",
      "Epoch:\t 16 Val Loss:\t 0.03517363212987751\n",
      "Epoch:\t 17 Val Loss:\t 0.035196839408101685\n",
      "Epoch:\t 18 Val Loss:\t 0.035196465542745255\n",
      "Epoch:\t 19 Val Loss:\t 0.03520635854161693\n",
      "Epoch:\t 20 Val Loss:\t 0.035209770888119996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:24:14,595] Trial 2 finished with value: 0.035103574694546766 and parameters: {'lr': 0.0001, 'weight_decay': 1e-05, 'scheduler_factor': 0.3, 'scheduler_patience': 1, 'batch_size': 32, 'dropout': 0.2, 'hidden_dims': 512}. Best is trial 2 with value: 0.035103574694546766.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 21 Val Loss:\t 0.0351900540262401\n",
      "Epoch:\t 0 Val Loss:\t 0.04102310499306335\n",
      "Epoch:\t 1 Val Loss:\t 0.03994101095786311\n",
      "Epoch:\t 2 Val Loss:\t 0.039257253284932805\n",
      "Epoch:\t 3 Val Loss:\t 0.03874139754369006\n",
      "Epoch:\t 4 Val Loss:\t 0.03833032974789596\n",
      "Epoch:\t 5 Val Loss:\t 0.03817902284927529\n",
      "Epoch:\t 6 Val Loss:\t 0.03790758542847949\n",
      "Epoch:\t 7 Val Loss:\t 0.03765502433145438\n",
      "Epoch:\t 8 Val Loss:\t 0.03753679525480571\n",
      "Epoch:\t 9 Val Loss:\t 0.03745314759540625\n",
      "Epoch:\t 10 Val Loss:\t 0.037377900583632204\n",
      "Epoch:\t 11 Val Loss:\t 0.03722892006009267\n",
      "Epoch:\t 12 Val Loss:\t 0.037178970904723586\n",
      "Epoch:\t 13 Val Loss:\t 0.03707638143471412\n",
      "Epoch:\t 14 Val Loss:\t 0.036966405668517735\n",
      "Epoch:\t 15 Val Loss:\t 0.03694183116072211\n",
      "Epoch:\t 16 Val Loss:\t 0.03688705189910858\n",
      "Epoch:\t 17 Val Loss:\t 0.036796041942816216\n",
      "Epoch:\t 18 Val Loss:\t 0.036796801079007846\n",
      "Epoch:\t 19 Val Loss:\t 0.03670043363844574\n",
      "Epoch:\t 20 Val Loss:\t 0.03664971478044413\n",
      "Epoch:\t 21 Val Loss:\t 0.036628343823642946\n",
      "Epoch:\t 22 Val Loss:\t 0.03663174033840131\n",
      "Epoch:\t 23 Val Loss:\t 0.036547301903235595\n",
      "Epoch:\t 24 Val Loss:\t 0.03654015477994679\n",
      "Epoch:\t 25 Val Loss:\t 0.03650519425690222\n",
      "Epoch:\t 26 Val Loss:\t 0.03646489707775468\n",
      "Epoch:\t 27 Val Loss:\t 0.03644411640918389\n",
      "Epoch:\t 28 Val Loss:\t 0.036389818020708675\n",
      "Epoch:\t 29 Val Loss:\t 0.0363872919467658\n",
      "Epoch:\t 30 Val Loss:\t 0.03636332601906303\n",
      "Epoch:\t 31 Val Loss:\t 0.03631156229928626\n",
      "Epoch:\t 32 Val Loss:\t 0.03632243826489451\n",
      "Epoch:\t 33 Val Loss:\t 0.03629896405459932\n",
      "Epoch:\t 34 Val Loss:\t 0.036241196207971026\n",
      "Epoch:\t 35 Val Loss:\t 0.03621580563455749\n",
      "Epoch:\t 36 Val Loss:\t 0.0362482587414784\n",
      "Epoch:\t 37 Val Loss:\t 0.036197230821802505\n",
      "Epoch:\t 38 Val Loss:\t 0.036216931741717535\n",
      "Epoch:\t 39 Val Loss:\t 0.03619195934035535\n",
      "Epoch:\t 40 Val Loss:\t 0.036181039565990426\n",
      "Epoch:\t 41 Val Loss:\t 0.03614840072033734\n",
      "Epoch:\t 42 Val Loss:\t 0.03615167500554273\n",
      "Epoch:\t 43 Val Loss:\t 0.03616167366080458\n",
      "Epoch:\t 44 Val Loss:\t 0.03609616551085195\n",
      "Epoch:\t 45 Val Loss:\t 0.036090714861463334\n",
      "Epoch:\t 46 Val Loss:\t 0.03612060029038737\n",
      "Epoch:\t 47 Val Loss:\t 0.03611368115815097\n",
      "Epoch:\t 48 Val Loss:\t 0.036105459917459184\n",
      "Epoch:\t 49 Val Loss:\t 0.03608246738839455\n",
      "Epoch:\t 50 Val Loss:\t 0.03608273429932026\n",
      "Epoch:\t 51 Val Loss:\t 0.03604661410565413\n",
      "Epoch:\t 52 Val Loss:\t 0.0360391918456282\n",
      "Epoch:\t 53 Val Loss:\t 0.036049906422818\n",
      "Epoch:\t 54 Val Loss:\t 0.03604185299196526\n",
      "Epoch:\t 55 Val Loss:\t 0.036036991143080836\n",
      "Epoch:\t 56 Val Loss:\t 0.0360533202869135\n",
      "Epoch:\t 57 Val Loss:\t 0.03605431770725114\n",
      "Epoch:\t 58 Val Loss:\t 0.03603290902105636\n",
      "Epoch:\t 59 Val Loss:\t 0.036049251844202795\n",
      "Epoch:\t 60 Val Loss:\t 0.03606185515701723\n",
      "Epoch:\t 61 Val Loss:\t 0.03601928756877768\n",
      "Epoch:\t 62 Val Loss:\t 0.03603382937687822\n",
      "Epoch:\t 63 Val Loss:\t 0.036047541159231276\n",
      "Epoch:\t 64 Val Loss:\t 0.0360227566340874\n",
      "Epoch:\t 65 Val Loss:\t 0.036034856922177665\n",
      "Epoch:\t 66 Val Loss:\t 0.036024603976269866\n",
      "Epoch:\t 67 Val Loss:\t 0.0360069519794623\n",
      "Epoch:\t 68 Val Loss:\t 0.036026346055849034\n",
      "Epoch:\t 69 Val Loss:\t 0.03603727836983388\n",
      "Epoch:\t 70 Val Loss:\t 0.03598818547258926\n",
      "Epoch:\t 71 Val Loss:\t 0.0360320949764159\n",
      "Epoch:\t 72 Val Loss:\t 0.03603607087239993\n",
      "Epoch:\t 73 Val Loss:\t 0.036006474195297664\n",
      "Epoch:\t 74 Val Loss:\t 0.03603098879970831\n",
      "Epoch:\t 75 Val Loss:\t 0.03600188280487883\n",
      "Epoch:\t 76 Val Loss:\t 0.036008580216619616\n",
      "Epoch:\t 77 Val Loss:\t 0.036024140757183694\n",
      "Epoch:\t 78 Val Loss:\t 0.03598095560423976\n",
      "Epoch:\t 79 Val Loss:\t 0.035997020827536114\n",
      "Epoch:\t 80 Val Loss:\t 0.03601681407759117\n",
      "Epoch:\t 81 Val Loss:\t 0.03601582997359795\n",
      "Epoch:\t 82 Val Loss:\t 0.03600961247902683\n",
      "Epoch:\t 83 Val Loss:\t 0.03598713253437278\n",
      "Epoch:\t 84 Val Loss:\t 0.0359951546318596\n",
      "Epoch:\t 85 Val Loss:\t 0.03598646867240584\n",
      "Epoch:\t 86 Val Loss:\t 0.035985158757869014\n",
      "Epoch:\t 87 Val Loss:\t 0.03601089637030481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:29:07,769] Trial 3 finished with value: 0.03598095560423976 and parameters: {'lr': 1e-05, 'weight_decay': 1e-05, 'scheduler_factor': 0.3, 'scheduler_patience': 10, 'batch_size': 64, 'dropout': 0.05, 'hidden_dims': 1024}. Best is trial 2 with value: 0.035103574694546766.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 88 Val Loss:\t 0.0360145472996863\n",
      "Epoch:\t 0 Val Loss:\t 0.035366225883113736\n",
      "Epoch:\t 1 Val Loss:\t 0.0352463154204387\n",
      "Epoch:\t 2 Val Loss:\t 0.03515916608076815\n",
      "Epoch:\t 3 Val Loss:\t 0.03511608338973813\n",
      "Epoch:\t 4 Val Loss:\t 0.03513618444825232\n",
      "Epoch:\t 5 Val Loss:\t 0.03514934718644705\n",
      "Epoch:\t 6 Val Loss:\t 0.03509838996363958\n",
      "Epoch:\t 7 Val Loss:\t 0.03512670541123906\n",
      "Epoch:\t 8 Val Loss:\t 0.03509501511650795\n",
      "Epoch:\t 9 Val Loss:\t 0.03511978869730459\n",
      "Epoch:\t 10 Val Loss:\t 0.03512353587629753\n",
      "Epoch:\t 11 Val Loss:\t 0.03511706081688786\n",
      "Epoch:\t 12 Val Loss:\t 0.0351079089093562\n",
      "Epoch:\t 13 Val Loss:\t 0.03514328676947327\n",
      "Epoch:\t 14 Val Loss:\t 0.0351465169770558\n",
      "Epoch:\t 15 Val Loss:\t 0.03510426207420916\n",
      "Epoch:\t 16 Val Loss:\t 0.03513570476260631\n",
      "Epoch:\t 17 Val Loss:\t 0.0351146837216955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:30:09,323] Trial 4 finished with value: 0.03509501511650795 and parameters: {'lr': 0.001, 'weight_decay': 1e-05, 'scheduler_factor': 0.1, 'scheduler_patience': 20, 'batch_size': 64, 'dropout': 0.05, 'hidden_dims': 256}. Best is trial 4 with value: 0.03509501511650795.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 18 Val Loss:\t 0.035096760634586825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:30:10,943] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.048184404227511295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:30:13,072] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.038420440841400415\n",
      "Epoch:\t 0 Val Loss:\t 0.03573763756552815\n",
      "Epoch:\t 1 Val Loss:\t 0.035411881757450414\n",
      "Epoch:\t 2 Val Loss:\t 0.03532459548605668\n",
      "Epoch:\t 3 Val Loss:\t 0.03529235161747615\n",
      "Epoch:\t 4 Val Loss:\t 0.035230015698791244\n",
      "Epoch:\t 5 Val Loss:\t 0.03522723338706111\n",
      "Epoch:\t 6 Val Loss:\t 0.03523334834528361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:33:18,781] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 7 Val Loss:\t 0.03524030010309052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:33:27,729] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.044395080256557654\n",
      "Epoch:\t 0 Val Loss:\t 0.03542921494068197\n",
      "Epoch:\t 1 Val Loss:\t 0.03545534037017736\n",
      "Epoch:\t 2 Val Loss:\t 0.03585510144985573\n",
      "Epoch:\t 3 Val Loss:\t 0.03589656279715855\n",
      "Epoch:\t 4 Val Loss:\t 0.0358838380957448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:33:46,504] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 5 Val Loss:\t 0.035886756378228225\n",
      "Epoch:\t 0 Val Loss:\t 0.03545552365177138\n",
      "Epoch:\t 1 Val Loss:\t 0.03537181402767957\n",
      "Epoch:\t 2 Val Loss:\t 0.03535104142210679\n",
      "Epoch:\t 3 Val Loss:\t 0.03535747088181227\n",
      "Epoch:\t 4 Val Loss:\t 0.0353466469179107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:34:05,913] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 5 Val Loss:\t 0.03540555816576924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:34:15,369] Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.04647270422540829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:34:25,932] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.036282549961983324\n",
      "Epoch:\t 0 Val Loss:\t 0.035515550491108556\n",
      "Epoch:\t 1 Val Loss:\t 0.035224431285553914\n",
      "Epoch:\t 2 Val Loss:\t 0.03518878396175933\n",
      "Epoch:\t 3 Val Loss:\t 0.035152708474744\n",
      "Epoch:\t 4 Val Loss:\t 0.035129360474921156\n",
      "Epoch:\t 5 Val Loss:\t 0.03511947184430367\n",
      "Epoch:\t 6 Val Loss:\t 0.03511351683920019\n",
      "Epoch:\t 7 Val Loss:\t 0.035149986522323054\n",
      "Epoch:\t 8 Val Loss:\t 0.03511819120849308\n",
      "Epoch:\t 9 Val Loss:\t 0.035101717938915686\n",
      "Epoch:\t 10 Val Loss:\t 0.03509013626850053\n",
      "Epoch:\t 11 Val Loss:\t 0.035084358576451986\n",
      "Epoch:\t 12 Val Loss:\t 0.03509779018237828\n",
      "Epoch:\t 13 Val Loss:\t 0.03509728241873304\n",
      "Epoch:\t 14 Val Loss:\t 0.035081468746783646\n",
      "Epoch:\t 15 Val Loss:\t 0.03508875107042862\n",
      "Epoch:\t 16 Val Loss:\t 0.0350788285175449\n",
      "Epoch:\t 17 Val Loss:\t 0.0350958328114084\n",
      "Epoch:\t 18 Val Loss:\t 0.03509679598132833\n",
      "Epoch:\t 19 Val Loss:\t 0.03509688731073664\n",
      "Epoch:\t 20 Val Loss:\t 0.03508531767725466\n",
      "Epoch:\t 21 Val Loss:\t 0.03509231096501335\n",
      "Epoch:\t 22 Val Loss:\t 0.03510223022612771\n",
      "Epoch:\t 23 Val Loss:\t 0.03510264683975262\n",
      "Epoch:\t 24 Val Loss:\t 0.0350841861457398\n",
      "Epoch:\t 25 Val Loss:\t 0.035090375395662135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:35:22,790] Trial 13 finished with value: 0.0350788285175449 and parameters: {'lr': 0.001, 'weight_decay': 1e-05, 'scheduler_factor': 0.3, 'scheduler_patience': 1, 'batch_size': 128, 'dropout': 0.1, 'hidden_dims': 256}. Best is trial 13 with value: 0.0350788285175449.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 26 Val Loss:\t 0.03509653211357505\n",
      "Epoch:\t 0 Val Loss:\t 0.03553214170230047\n",
      "Epoch:\t 1 Val Loss:\t 0.03522673327577439\n",
      "Epoch:\t 2 Val Loss:\t 0.03515099995675382\n",
      "Epoch:\t 3 Val Loss:\t 0.035117096290064084\n",
      "Epoch:\t 4 Val Loss:\t 0.035146071454495144\n",
      "Epoch:\t 5 Val Loss:\t 0.03510095165327885\n",
      "Epoch:\t 6 Val Loss:\t 0.03510749083233588\n",
      "Epoch:\t 7 Val Loss:\t 0.035116155217752985\n",
      "Epoch:\t 8 Val Loss:\t 0.035056697476780814\n",
      "Epoch:\t 9 Val Loss:\t 0.0350717305658717\n",
      "Epoch:\t 10 Val Loss:\t 0.035072508954217305\n",
      "Epoch:\t 11 Val Loss:\t 0.03506771951949711\n",
      "Epoch:\t 12 Val Loss:\t 0.035064417282851895\n",
      "Epoch:\t 13 Val Loss:\t 0.03506993491615185\n",
      "Epoch:\t 14 Val Loss:\t 0.0350679483916461\n",
      "Epoch:\t 15 Val Loss:\t 0.035071550274976375\n",
      "Epoch:\t 16 Val Loss:\t 0.03505895233580044\n",
      "Epoch:\t 17 Val Loss:\t 0.035074760028150645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:36:04,039] Trial 14 finished with value: 0.035056697476780814 and parameters: {'lr': 0.001, 'weight_decay': 1e-05, 'scheduler_factor': 0.1, 'scheduler_patience': 1, 'batch_size': 128, 'dropout': 0.1, 'hidden_dims': 256}. Best is trial 14 with value: 0.035056697476780814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 18 Val Loss:\t 0.0350619905731412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:36:06,285] Trial 15 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03554776535454665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:36:08,508] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.036124698360290614\n",
      "Epoch:\t 0 Val Loss:\t 0.03536192499053325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:36:12,826] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 1 Val Loss:\t 0.03537523830503847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:36:15,032] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03596809945617881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:36:17,254] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.0794880704335378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:36:19,428] Trial 20 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.04372584327672687\n",
      "Epoch:\t 0 Val Loss:\t 0.03532836868397073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:36:25,995] Trial 21 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 1 Val Loss:\t 0.03524879214548787\n",
      "Epoch:\t 0 Val Loss:\t 0.03531447040408539\n",
      "Epoch:\t 1 Val Loss:\t 0.035199434867647046\n",
      "Epoch:\t 2 Val Loss:\t 0.03516439122163542\n",
      "Epoch:\t 3 Val Loss:\t 0.035167657521515246\n",
      "Epoch:\t 4 Val Loss:\t 0.03518576163622314\n",
      "Epoch:\t 5 Val Loss:\t 0.0351295546892173\n",
      "Epoch:\t 6 Val Loss:\t 0.03517109970319433\n",
      "Epoch:\t 7 Val Loss:\t 0.03512413200489884\n",
      "Epoch:\t 8 Val Loss:\t 0.03511472162435843\n",
      "Epoch:\t 9 Val Loss:\t 0.035115450741641026\n",
      "Epoch:\t 10 Val Loss:\t 0.03513556059954782\n",
      "Epoch:\t 11 Val Loss:\t 0.035132236825040845\n",
      "Epoch:\t 12 Val Loss:\t 0.035126500254393865\n",
      "Epoch:\t 13 Val Loss:\t 0.03512930158755735\n",
      "Epoch:\t 14 Val Loss:\t 0.0351428207078741\n",
      "Epoch:\t 15 Val Loss:\t 0.035121481894024774\n",
      "Epoch:\t 16 Val Loss:\t 0.03517506469665476\n",
      "Epoch:\t 17 Val Loss:\t 0.03512688241032667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:37:27,102] Trial 22 finished with value: 0.03511472162435843 and parameters: {'lr': 0.001, 'weight_decay': 1e-05, 'scheduler_factor': 0.1, 'scheduler_patience': 20, 'batch_size': 64, 'dropout': 0.15, 'hidden_dims': 256}. Best is trial 14 with value: 0.035056697476780814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 18 Val Loss:\t 0.0351538676290557\n",
      "Epoch:\t 0 Val Loss:\t 0.035478034327299984\n",
      "Epoch:\t 1 Val Loss:\t 0.03522554499188357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:37:33,570] Trial 23 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 2 Val Loss:\t 0.03519132440344671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:37:35,250] Trial 24 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03573228336774843\n",
      "Epoch:\t 0 Val Loss:\t 0.03522644174551885\n",
      "Epoch:\t 1 Val Loss:\t 0.03519071117241292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:38:45,135] Trial 25 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 2 Val Loss:\t 0.03524001448020933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:38:48,428] Trial 26 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03648183517958655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:38:50,617] Trial 27 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.0358382866001818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:38:52,784] Trial 28 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.04383939163188299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:38:54,432] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03625118734249157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:38:57,728] Trial 30 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.05186593863566398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:39:07,061] Trial 31 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.036125957973316344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:39:16,331] Trial 32 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.036422820641605076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:39:25,561] Trial 33 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03629770794424241\n",
      "Epoch:\t 0 Val Loss:\t 0.03527238564440756\n",
      "Epoch:\t 1 Val Loss:\t 0.03515756845476482\n",
      "Epoch:\t 2 Val Loss:\t 0.03517650903402816\n",
      "Epoch:\t 3 Val Loss:\t 0.03517911886541459\n",
      "Epoch:\t 4 Val Loss:\t 0.035166143847618604\n",
      "Epoch:\t 5 Val Loss:\t 0.03523350139455491\n",
      "Epoch:\t 6 Val Loss:\t 0.035338339126370126\n",
      "Epoch:\t 7 Val Loss:\t 0.03541127348793034\n",
      "Epoch:\t 8 Val Loss:\t 0.035442846238298145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:43:11,408] Trial 34 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 9 Val Loss:\t 0.03544552468302326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:43:13,226] Trial 35 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.043184752189748925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:43:22,943] Trial 36 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03640260416977033\n",
      "Epoch:\t 0 Val Loss:\t 0.03523150752025164\n",
      "Epoch:\t 1 Val Loss:\t 0.03524809490095886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:44:34,140] Trial 37 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 2 Val Loss:\t 0.03523564896712565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:44:37,486] Trial 38 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03611081570040348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:44:39,728] Trial 39 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.042229616305944816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:44:49,183] Trial 40 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.050831434877219805\n",
      "Epoch:\t 0 Val Loss:\t 0.035258277152824036\n",
      "Epoch:\t 1 Val Loss:\t 0.03519202657671288\n",
      "Epoch:\t 2 Val Loss:\t 0.03512957426118153\n",
      "Epoch:\t 3 Val Loss:\t 0.03513323114296151\n",
      "Epoch:\t 4 Val Loss:\t 0.03514739795145075\n",
      "Epoch:\t 5 Val Loss:\t 0.035134815226317215\n",
      "Epoch:\t 6 Val Loss:\t 0.035172480015859375\n",
      "Epoch:\t 7 Val Loss:\t 0.035163467743978466\n",
      "Epoch:\t 8 Val Loss:\t 0.03512647140057162\n",
      "Epoch:\t 9 Val Loss:\t 0.035128650661041094\n",
      "Epoch:\t 10 Val Loss:\t 0.03516855491765901\n",
      "Epoch:\t 11 Val Loss:\t 0.03510125250867011\n",
      "Epoch:\t 12 Val Loss:\t 0.03512630135615587\n",
      "Epoch:\t 13 Val Loss:\t 0.03514511432161117\n",
      "Epoch:\t 14 Val Loss:\t 0.03517987525632789\n",
      "Epoch:\t 15 Val Loss:\t 0.03511341236555634\n",
      "Epoch:\t 16 Val Loss:\t 0.03513656349878074\n",
      "Epoch:\t 17 Val Loss:\t 0.03515854926291426\n",
      "Epoch:\t 18 Val Loss:\t 0.03515510919034099\n",
      "Epoch:\t 19 Val Loss:\t 0.035162352797752296\n",
      "Epoch:\t 20 Val Loss:\t 0.03513224846844015\n",
      "Epoch:\t 21 Val Loss:\t 0.03508521679941185\n",
      "Epoch:\t 22 Val Loss:\t 0.035136488981025164\n",
      "Epoch:\t 23 Val Loss:\t 0.03509309200036736\n",
      "Epoch:\t 24 Val Loss:\t 0.03512590138186382\n",
      "Epoch:\t 25 Val Loss:\t 0.03510877307961488\n",
      "Epoch:\t 26 Val Loss:\t 0.03511131011732311\n",
      "Epoch:\t 27 Val Loss:\t 0.03515160757728644\n",
      "Epoch:\t 28 Val Loss:\t 0.03511347947754235\n",
      "Epoch:\t 29 Val Loss:\t 0.035164828371158\n",
      "Epoch:\t 30 Val Loss:\t 0.03515624797454144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:46:34,357] Trial 41 finished with value: 0.03508521679941185 and parameters: {'lr': 0.001, 'weight_decay': 1e-05, 'scheduler_factor': 0.1, 'scheduler_patience': 20, 'batch_size': 64, 'dropout': 0.15, 'hidden_dims': 256}. Best is trial 14 with value: 0.035056697476780814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 31 Val Loss:\t 0.03513783718509347\n",
      "Epoch:\t 0 Val Loss:\t 0.035334892333473984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:46:40,685] Trial 42 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 1 Val Loss:\t 0.035247469766016185\n",
      "Epoch:\t 0 Val Loss:\t 0.03529505553836811\n",
      "Epoch:\t 1 Val Loss:\t 0.03521880664755893\n",
      "Epoch:\t 2 Val Loss:\t 0.035160272814626206\n",
      "Epoch:\t 3 Val Loss:\t 0.03514578158174789\n",
      "Epoch:\t 4 Val Loss:\t 0.03510936542019045\n",
      "Epoch:\t 5 Val Loss:\t 0.03515284304725904\n",
      "Epoch:\t 6 Val Loss:\t 0.03513599420750533\n",
      "Epoch:\t 7 Val Loss:\t 0.03514317724235362\n",
      "Epoch:\t 8 Val Loss:\t 0.03514456653365538\n",
      "Epoch:\t 9 Val Loss:\t 0.03515633567570206\n",
      "Epoch:\t 10 Val Loss:\t 0.03510819678736288\n",
      "Epoch:\t 11 Val Loss:\t 0.03517527806138696\n",
      "Epoch:\t 12 Val Loss:\t 0.03513434608470657\n",
      "Epoch:\t 13 Val Loss:\t 0.035139216443205605\n",
      "Epoch:\t 14 Val Loss:\t 0.035160850425816195\n",
      "Epoch:\t 15 Val Loss:\t 0.03515367837863247\n",
      "Epoch:\t 16 Val Loss:\t 0.03516519807559926\n",
      "Epoch:\t 17 Val Loss:\t 0.035123343394999035\n",
      "Epoch:\t 18 Val Loss:\t 0.03513051308810998\n",
      "Epoch:\t 19 Val Loss:\t 0.035119513390285545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:47:49,579] Trial 43 finished with value: 0.03510819678736288 and parameters: {'lr': 0.001, 'weight_decay': 1e-05, 'scheduler_factor': 0.1, 'scheduler_patience': 20, 'batch_size': 64, 'dropout': 0.15, 'hidden_dims': 256}. Best is trial 14 with value: 0.035056697476780814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 20 Val Loss:\t 0.03513960121012776\n",
      "Epoch:\t 0 Val Loss:\t 0.035282513450864035\n",
      "Epoch:\t 1 Val Loss:\t 0.03520291357778413\n",
      "Epoch:\t 2 Val Loss:\t 0.035141584940655\n",
      "Epoch:\t 3 Val Loss:\t 0.03512533000687551\n",
      "Epoch:\t 4 Val Loss:\t 0.035169857150091584\n",
      "Epoch:\t 5 Val Loss:\t 0.03509657116160215\n",
      "Epoch:\t 6 Val Loss:\t 0.03516631643493221\n",
      "Epoch:\t 7 Val Loss:\t 0.035148499003270196\n",
      "Epoch:\t 8 Val Loss:\t 0.035144379323627725\n",
      "Epoch:\t 9 Val Loss:\t 0.035142638591366855\n",
      "Epoch:\t 10 Val Loss:\t 0.035139178432996215\n",
      "Epoch:\t 11 Val Loss:\t 0.0351484653053756\n",
      "Epoch:\t 12 Val Loss:\t 0.035147967802864034\n",
      "Epoch:\t 13 Val Loss:\t 0.03512005588605868\n",
      "Epoch:\t 14 Val Loss:\t 0.03512060300334272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:48:42,031] Trial 44 finished with value: 0.03509657116160215 and parameters: {'lr': 0.001, 'weight_decay': 1e-05, 'scheduler_factor': 0.1, 'scheduler_patience': 20, 'batch_size': 64, 'dropout': 0.15, 'hidden_dims': 256}. Best is trial 14 with value: 0.035056697476780814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 15 Val Loss:\t 0.03512738437900423\n",
      "Epoch:\t 0 Val Loss:\t 0.035299946466623634\n",
      "Epoch:\t 1 Val Loss:\t 0.03520362020291705\n",
      "Epoch:\t 2 Val Loss:\t 0.03512936747918965\n",
      "Epoch:\t 3 Val Loss:\t 0.03514370895808663\n",
      "Epoch:\t 4 Val Loss:\t 0.0351425342862259\n",
      "Epoch:\t 5 Val Loss:\t 0.035112754001902786\n",
      "Epoch:\t 6 Val Loss:\t 0.03513724985140366\n",
      "Epoch:\t 7 Val Loss:\t 0.0351555432419277\n",
      "Epoch:\t 8 Val Loss:\t 0.03513705940004483\n",
      "Epoch:\t 9 Val Loss:\t 0.035142233021670854\n",
      "Epoch:\t 10 Val Loss:\t 0.03515725941774409\n",
      "Epoch:\t 11 Val Loss:\t 0.03515997966385499\n",
      "Epoch:\t 12 Val Loss:\t 0.03510054538912217\n",
      "Epoch:\t 13 Val Loss:\t 0.03514856001348761\n",
      "Epoch:\t 14 Val Loss:\t 0.03510866380044959\n",
      "Epoch:\t 15 Val Loss:\t 0.0351513534464665\n",
      "Epoch:\t 16 Val Loss:\t 0.03510991871542183\n",
      "Epoch:\t 17 Val Loss:\t 0.035114804735375864\n",
      "Epoch:\t 18 Val Loss:\t 0.03513053359513103\n",
      "Epoch:\t 19 Val Loss:\t 0.03513339281219574\n",
      "Epoch:\t 20 Val Loss:\t 0.03513733652788539\n",
      "Epoch:\t 21 Val Loss:\t 0.035132638052548036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:49:58,456] Trial 45 finished with value: 0.03510054538912217 and parameters: {'lr': 0.001, 'weight_decay': 1e-05, 'scheduler_factor': 0.1, 'scheduler_patience': 20, 'batch_size': 64, 'dropout': 0.15, 'hidden_dims': 256}. Best is trial 14 with value: 0.035056697476780814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 22 Val Loss:\t 0.03515110531285608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:50:01,867] Trial 46 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03647941934525871\n",
      "Epoch:\t 0 Val Loss:\t 0.0353169447944799\n",
      "Epoch:\t 1 Val Loss:\t 0.03521930004836754\n",
      "Epoch:\t 2 Val Loss:\t 0.035145603540056976\n",
      "Epoch:\t 3 Val Loss:\t 0.0351686576394769\n",
      "Epoch:\t 4 Val Loss:\t 0.03517033351673397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:50:22,138] Trial 47 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 5 Val Loss:\t 0.03514711701019153\n",
      "Epoch:\t 0 Val Loss:\t 0.03529175567054567\n",
      "Epoch:\t 1 Val Loss:\t 0.035166825264178476\n",
      "Epoch:\t 2 Val Loss:\t 0.03512596252651433\n",
      "Epoch:\t 3 Val Loss:\t 0.0351409105466023\n",
      "Epoch:\t 4 Val Loss:\t 0.035097910434832166\n",
      "Epoch:\t 5 Val Loss:\t 0.03514811883694713\n",
      "Epoch:\t 6 Val Loss:\t 0.035149504293918415\n",
      "Epoch:\t 7 Val Loss:\t 0.03511492236881086\n",
      "Epoch:\t 8 Val Loss:\t 0.03510759960122126\n",
      "Epoch:\t 9 Val Loss:\t 0.03513950488881866\n",
      "Epoch:\t 10 Val Loss:\t 0.035131839670856285\n",
      "Epoch:\t 11 Val Loss:\t 0.03513599472432588\n",
      "Epoch:\t 12 Val Loss:\t 0.035125204265631475\n",
      "Epoch:\t 13 Val Loss:\t 0.03516459437244017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:51:13,232] Trial 48 finished with value: 0.035097910434832166 and parameters: {'lr': 0.001, 'weight_decay': 1e-05, 'scheduler_factor': 0.1, 'scheduler_patience': 20, 'batch_size': 64, 'dropout': 0.15, 'hidden_dims': 256}. Best is trial 14 with value: 0.035056697476780814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 14 Val Loss:\t 0.03513035975372734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 12:51:16,482] Trial 49 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.035378893341423995\n",
      "Training model with best parameters on train+validation ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401917/401917 [04:07<00:00, 1620.82it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401917/401917 [01:13<00:00, 5458.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting test set predictions and saving results ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 611/611 [00:00<00:00, 865.46it/s]\n"
     ]
    }
   ],
   "source": [
    "train_different_featno(\n",
    "        adata_path=\"./data/feature_number/sciplex_hvg_500.h5ad\",\n",
    "        run_name=\"mlp_hvg_500\",\n",
    "        res_savename=\"./results/feature_number/mlp_hvg_500_res.pkl\",\n",
    "        input_dim=500,\n",
    "        output_dim=500,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84b8c143-6b0b-4f82-989b-0a133e6b6769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Datasets ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401917/401917 [03:11<00:00, 2098.45it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401917/401917 [01:13<00:00, 5436.66it/s]\n",
      "[I 2025-06-18 13:01:27,370] A new study created in RDB with name: mlp_hvg_1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing Hyperparameters with Optuna ...\n",
      "Epoch:\t 0 Val Loss:\t 0.031162933329677275\n",
      "Epoch:\t 1 Val Loss:\t 0.03091663352761813\n",
      "Epoch:\t 2 Val Loss:\t 0.030863802341019608\n",
      "Epoch:\t 3 Val Loss:\t 0.030829301343518054\n",
      "Epoch:\t 4 Val Loss:\t 0.030856133920778416\n",
      "Epoch:\t 5 Val Loss:\t 0.030786189259631842\n",
      "Epoch:\t 6 Val Loss:\t 0.03092897580966497\n",
      "Epoch:\t 7 Val Loss:\t 0.030839654536157175\n",
      "Epoch:\t 8 Val Loss:\t 0.03089511497515191\n",
      "Epoch:\t 9 Val Loss:\t 0.030956272395189936\n",
      "Epoch:\t 10 Val Loss:\t 0.03115232413413057\n",
      "Epoch:\t 11 Val Loss:\t 0.031516809423732604\n",
      "Epoch:\t 12 Val Loss:\t 0.03163022568922526\n",
      "Epoch:\t 13 Val Loss:\t 0.031629196742483656\n",
      "Epoch:\t 14 Val Loss:\t 0.031595986588016586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 13:01:58,599] Trial 0 finished with value: 0.030786189259631842 and parameters: {'lr': 0.0001, 'weight_decay': 0.001, 'scheduler_factor': 0.1, 'scheduler_patience': 20, 'batch_size': 256, 'dropout': 0.1, 'hidden_dims': 256}. Best is trial 0 with value: 0.030786189259631842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 15 Val Loss:\t 0.03171558343353187\n",
      "Epoch:\t 0 Val Loss:\t 0.030978758762503743\n",
      "Epoch:\t 1 Val Loss:\t 0.030871553735813528\n",
      "Epoch:\t 2 Val Loss:\t 0.030911258155318318\n",
      "Epoch:\t 3 Val Loss:\t 0.030872578460160175\n",
      "Epoch:\t 4 Val Loss:\t 0.030831841991501605\n",
      "Epoch:\t 5 Val Loss:\t 0.030820378638396692\n",
      "Epoch:\t 6 Val Loss:\t 0.030797718470119587\n",
      "Epoch:\t 7 Val Loss:\t 0.030870813523026907\n",
      "Epoch:\t 8 Val Loss:\t 0.0307748220154231\n",
      "Epoch:\t 9 Val Loss:\t 0.030776849250126498\n",
      "Epoch:\t 10 Val Loss:\t 0.030829548314692888\n",
      "Epoch:\t 11 Val Loss:\t 0.03079537292073969\n",
      "Epoch:\t 12 Val Loss:\t 0.030772724647039004\n",
      "Epoch:\t 13 Val Loss:\t 0.03078960896832\n",
      "Epoch:\t 14 Val Loss:\t 0.030756356751612146\n",
      "Epoch:\t 15 Val Loss:\t 0.03076578525173511\n",
      "Epoch:\t 16 Val Loss:\t 0.030746468184126536\n",
      "Epoch:\t 17 Val Loss:\t 0.030754796382027806\n",
      "Epoch:\t 18 Val Loss:\t 0.030809802407476678\n",
      "Epoch:\t 19 Val Loss:\t 0.03078014760538696\n",
      "Epoch:\t 20 Val Loss:\t 0.0307783369226471\n",
      "Epoch:\t 21 Val Loss:\t 0.030797290732527086\n",
      "Epoch:\t 22 Val Loss:\t 0.030764371929300944\n",
      "Epoch:\t 23 Val Loss:\t 0.030781964666638344\n",
      "Epoch:\t 24 Val Loss:\t 0.030785366976663613\n",
      "Epoch:\t 25 Val Loss:\t 0.03077064677354224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 13:02:51,754] Trial 1 finished with value: 0.030746468184126536 and parameters: {'lr': 0.0001, 'weight_decay': 0.001, 'scheduler_factor': 0.5, 'scheduler_patience': 1, 'batch_size': 256, 'dropout': 0.2, 'hidden_dims': 512}. Best is trial 1 with value: 0.030746468184126536.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 26 Val Loss:\t 0.030761772048003806\n",
      "Epoch:\t 0 Val Loss:\t 0.03441367161372501\n",
      "Epoch:\t 1 Val Loss:\t 0.03348953499643502\n",
      "Epoch:\t 2 Val Loss:\t 0.03294422325261968\n",
      "Epoch:\t 3 Val Loss:\t 0.032682497066283275\n",
      "Epoch:\t 4 Val Loss:\t 0.03246215974430522\n",
      "Epoch:\t 5 Val Loss:\t 0.03227869093507708\n",
      "Epoch:\t 6 Val Loss:\t 0.032306437182402566\n",
      "Epoch:\t 7 Val Loss:\t 0.0321617635433564\n",
      "Epoch:\t 8 Val Loss:\t 0.0321471099579382\n",
      "Epoch:\t 9 Val Loss:\t 0.032072401346866494\n",
      "Epoch:\t 10 Val Loss:\t 0.03213579665891871\n",
      "Epoch:\t 11 Val Loss:\t 0.0320474658937815\n",
      "Epoch:\t 12 Val Loss:\t 0.03199441879315821\n",
      "Epoch:\t 13 Val Loss:\t 0.031971189199026695\n",
      "Epoch:\t 14 Val Loss:\t 0.031938704926677365\n",
      "Epoch:\t 15 Val Loss:\t 0.03197729136861995\n",
      "Epoch:\t 16 Val Loss:\t 0.03186692151731862\n",
      "Epoch:\t 17 Val Loss:\t 0.03181146422628769\n",
      "Epoch:\t 18 Val Loss:\t 0.031779410873720784\n",
      "Epoch:\t 19 Val Loss:\t 0.03173976390583362\n",
      "Epoch:\t 20 Val Loss:\t 0.0318035811320216\n",
      "Epoch:\t 21 Val Loss:\t 0.031790929932692245\n",
      "Epoch:\t 22 Val Loss:\t 0.03171747737603341\n",
      "Epoch:\t 23 Val Loss:\t 0.03167653515009221\n",
      "Epoch:\t 24 Val Loss:\t 0.03169075401876876\n",
      "Epoch:\t 25 Val Loss:\t 0.031698901250301476\n",
      "Epoch:\t 26 Val Loss:\t 0.031778477275658225\n",
      "Epoch:\t 27 Val Loss:\t 0.03163682752940244\n",
      "Epoch:\t 28 Val Loss:\t 0.03169157304437103\n",
      "Epoch:\t 29 Val Loss:\t 0.03164492429333005\n",
      "Epoch:\t 30 Val Loss:\t 0.03162107000683615\n",
      "Epoch:\t 31 Val Loss:\t 0.03164531909123451\n",
      "Epoch:\t 32 Val Loss:\t 0.03168065560111899\n",
      "Epoch:\t 33 Val Loss:\t 0.031625031303606915\n",
      "Epoch:\t 34 Val Loss:\t 0.03161448839686079\n",
      "Epoch:\t 35 Val Loss:\t 0.03159593957026521\n",
      "Epoch:\t 36 Val Loss:\t 0.03163908396311896\n",
      "Epoch:\t 37 Val Loss:\t 0.03167492628903809\n",
      "Epoch:\t 38 Val Loss:\t 0.03157685229364402\n",
      "Epoch:\t 39 Val Loss:\t 0.031595200160611604\n",
      "Epoch:\t 40 Val Loss:\t 0.03157489274615396\n",
      "Epoch:\t 41 Val Loss:\t 0.03151669324803089\n",
      "Epoch:\t 42 Val Loss:\t 0.03157523089575624\n",
      "Epoch:\t 43 Val Loss:\t 0.03159731422627498\n",
      "Epoch:\t 44 Val Loss:\t 0.03153400983967499\n",
      "Epoch:\t 45 Val Loss:\t 0.03155071048778976\n",
      "Epoch:\t 46 Val Loss:\t 0.031579468456024155\n",
      "Epoch:\t 47 Val Loss:\t 0.031570372355724866\n",
      "Epoch:\t 48 Val Loss:\t 0.03158042313071912\n",
      "Epoch:\t 49 Val Loss:\t 0.03154110023322588\n",
      "Epoch:\t 50 Val Loss:\t 0.03150480072609408\n",
      "Epoch:\t 51 Val Loss:\t 0.031547479195621064\n",
      "Epoch:\t 52 Val Loss:\t 0.03150230523922998\n",
      "Epoch:\t 53 Val Loss:\t 0.03153957085224813\n",
      "Epoch:\t 54 Val Loss:\t 0.0315817356968153\n",
      "Epoch:\t 55 Val Loss:\t 0.03158197174061515\n",
      "Epoch:\t 56 Val Loss:\t 0.03155789851530162\n",
      "Epoch:\t 57 Val Loss:\t 0.03158642799408737\n",
      "Epoch:\t 58 Val Loss:\t 0.03158441607528674\n",
      "Epoch:\t 59 Val Loss:\t 0.03160564736771082\n",
      "Epoch:\t 60 Val Loss:\t 0.03159717464883007\n",
      "Epoch:\t 61 Val Loss:\t 0.03167785870542149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 13:09:31,268] Trial 2 finished with value: 0.03150230523922998 and parameters: {'lr': 1e-05, 'weight_decay': 1e-06, 'scheduler_factor': 0.3, 'scheduler_patience': 20, 'batch_size': 32, 'dropout': 0.15, 'hidden_dims': 1024}. Best is trial 1 with value: 0.030746468184126536.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 62 Val Loss:\t 0.031599288895905374\n",
      "Epoch:\t 0 Val Loss:\t 0.03255983247432146\n",
      "Epoch:\t 1 Val Loss:\t 0.03186070624840585\n",
      "Epoch:\t 2 Val Loss:\t 0.03168883455400004\n",
      "Epoch:\t 3 Val Loss:\t 0.031486893778317045\n",
      "Epoch:\t 4 Val Loss:\t 0.03134614852874466\n",
      "Epoch:\t 5 Val Loss:\t 0.03136147593071813\n",
      "Epoch:\t 6 Val Loss:\t 0.031292828783560336\n",
      "Epoch:\t 7 Val Loss:\t 0.03122176103784223\n",
      "Epoch:\t 8 Val Loss:\t 0.031233385477340624\n",
      "Epoch:\t 9 Val Loss:\t 0.031180150232862316\n",
      "Epoch:\t 10 Val Loss:\t 0.03110174262480598\n",
      "Epoch:\t 11 Val Loss:\t 0.031164030740291695\n",
      "Epoch:\t 12 Val Loss:\t 0.031069520520073262\n",
      "Epoch:\t 13 Val Loss:\t 0.03108435082002685\n",
      "Epoch:\t 14 Val Loss:\t 0.031059091007800393\n",
      "Epoch:\t 15 Val Loss:\t 0.03098155057018871\n",
      "Epoch:\t 16 Val Loss:\t 0.031023422450449072\n",
      "Epoch:\t 17 Val Loss:\t 0.031007559928164053\n",
      "Epoch:\t 18 Val Loss:\t 0.031015630354013526\n",
      "Epoch:\t 19 Val Loss:\t 0.030970958804481485\n",
      "Epoch:\t 20 Val Loss:\t 0.030949047131293466\n",
      "Epoch:\t 21 Val Loss:\t 0.03096433425468675\n",
      "Epoch:\t 22 Val Loss:\t 0.030968473996985015\n",
      "Epoch:\t 23 Val Loss:\t 0.030947785172760964\n",
      "Epoch:\t 24 Val Loss:\t 0.030948687554075476\n",
      "Epoch:\t 25 Val Loss:\t 0.03094928909577489\n",
      "Epoch:\t 26 Val Loss:\t 0.030905070740065835\n",
      "Epoch:\t 27 Val Loss:\t 0.030908581305947005\n",
      "Epoch:\t 28 Val Loss:\t 0.03091310719880208\n",
      "Epoch:\t 29 Val Loss:\t 0.030898443496461665\n",
      "Epoch:\t 30 Val Loss:\t 0.030897149648726654\n",
      "Epoch:\t 31 Val Loss:\t 0.030892648974831186\n",
      "Epoch:\t 32 Val Loss:\t 0.03088827994181199\n",
      "Epoch:\t 33 Val Loss:\t 0.030899745004063242\n",
      "Epoch:\t 34 Val Loss:\t 0.030878279426913964\n",
      "Epoch:\t 35 Val Loss:\t 0.03089102084358278\n",
      "Epoch:\t 36 Val Loss:\t 0.030884794227145074\n",
      "Epoch:\t 37 Val Loss:\t 0.030884668455245408\n",
      "Epoch:\t 38 Val Loss:\t 0.030886234057825028\n",
      "Epoch:\t 39 Val Loss:\t 0.03087598139518815\n",
      "Epoch:\t 40 Val Loss:\t 0.03087532012925198\n",
      "Epoch:\t 41 Val Loss:\t 0.03087023796026339\n",
      "Epoch:\t 42 Val Loss:\t 0.03085151808650306\n",
      "Epoch:\t 43 Val Loss:\t 0.030877046059835014\n",
      "Epoch:\t 44 Val Loss:\t 0.030877591704241154\n",
      "Epoch:\t 45 Val Loss:\t 0.030873016784652277\n",
      "Epoch:\t 46 Val Loss:\t 0.03088113431778421\n",
      "Epoch:\t 47 Val Loss:\t 0.03087093329197618\n",
      "Epoch:\t 48 Val Loss:\t 0.0308779285679516\n",
      "Epoch:\t 49 Val Loss:\t 0.030886132117617954\n",
      "Epoch:\t 50 Val Loss:\t 0.030883763317335666\n",
      "Epoch:\t 51 Val Loss:\t 0.030878928452610588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 13:11:39,075] Trial 3 finished with value: 0.03085151808650306 and parameters: {'lr': 0.0001, 'weight_decay': 1e-06, 'scheduler_factor': 0.1, 'scheduler_patience': 5, 'batch_size': 128, 'dropout': 0.2, 'hidden_dims': 256}. Best is trial 1 with value: 0.030746468184126536.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 52 Val Loss:\t 0.030881711719841675\n",
      "Epoch:\t 0 Val Loss:\t 0.10490943215955109\n",
      "Epoch:\t 1 Val Loss:\t 0.09659710138365386\n",
      "Epoch:\t 2 Val Loss:\t 0.0875787776191135\n",
      "Epoch:\t 3 Val Loss:\t 0.08076542093631156\n",
      "Epoch:\t 4 Val Loss:\t 0.07499868841991547\n",
      "Epoch:\t 5 Val Loss:\t 0.0697210868790602\n",
      "Epoch:\t 6 Val Loss:\t 0.06535718403157698\n",
      "Epoch:\t 7 Val Loss:\t 0.06200990203013374\n",
      "Epoch:\t 8 Val Loss:\t 0.05908913015600569\n",
      "Epoch:\t 9 Val Loss:\t 0.05659124642083499\n",
      "Epoch:\t 10 Val Loss:\t 0.05410325123518226\n",
      "Epoch:\t 11 Val Loss:\t 0.05219338592321543\n",
      "Epoch:\t 12 Val Loss:\t 0.050711345730103864\n",
      "Epoch:\t 13 Val Loss:\t 0.04945351982375433\n",
      "Epoch:\t 14 Val Loss:\t 0.04795802050416876\n",
      "Epoch:\t 15 Val Loss:\t 0.0468514111623695\n",
      "Epoch:\t 16 Val Loss:\t 0.04564875233738752\n",
      "Epoch:\t 17 Val Loss:\t 0.04489740740112553\n",
      "Epoch:\t 18 Val Loss:\t 0.044050424632248\n",
      "Epoch:\t 19 Val Loss:\t 0.04337881547413838\n",
      "Epoch:\t 20 Val Loss:\t 0.042644007365036624\n",
      "Epoch:\t 21 Val Loss:\t 0.042116900744258015\n",
      "Epoch:\t 22 Val Loss:\t 0.04136937473364582\n",
      "Epoch:\t 23 Val Loss:\t 0.0409985724417343\n",
      "Epoch:\t 24 Val Loss:\t 0.04047838986590744\n",
      "Epoch:\t 25 Val Loss:\t 0.03993237950506701\n",
      "Epoch:\t 26 Val Loss:\t 0.03943910884560113\n",
      "Epoch:\t 27 Val Loss:\t 0.03901576284331141\n",
      "Epoch:\t 28 Val Loss:\t 0.03867630077184588\n",
      "Epoch:\t 29 Val Loss:\t 0.03838951884502383\n",
      "Epoch:\t 30 Val Loss:\t 0.03803747848059587\n",
      "Epoch:\t 31 Val Loss:\t 0.03773911143997474\n",
      "Epoch:\t 32 Val Loss:\t 0.03753906669292802\n",
      "Epoch:\t 33 Val Loss:\t 0.037282801409913795\n",
      "Epoch:\t 34 Val Loss:\t 0.037022409595285584\n",
      "Epoch:\t 35 Val Loss:\t 0.03679482547799874\n",
      "Epoch:\t 36 Val Loss:\t 0.03660423288247593\n",
      "Epoch:\t 37 Val Loss:\t 0.03640349626157828\n",
      "Epoch:\t 38 Val Loss:\t 0.036309916849496665\n",
      "Epoch:\t 39 Val Loss:\t 0.03605029288787167\n",
      "Epoch:\t 40 Val Loss:\t 0.03596963900533712\n",
      "Epoch:\t 41 Val Loss:\t 0.03577025634778658\n",
      "Epoch:\t 42 Val Loss:\t 0.03560734796562379\n",
      "Epoch:\t 43 Val Loss:\t 0.03550768031520092\n",
      "Epoch:\t 44 Val Loss:\t 0.035410137775195374\n",
      "Epoch:\t 45 Val Loss:\t 0.035381068777999694\n",
      "Epoch:\t 46 Val Loss:\t 0.03521713159882563\n",
      "Epoch:\t 47 Val Loss:\t 0.03512582318839345\n",
      "Epoch:\t 48 Val Loss:\t 0.03508047577460863\n",
      "Epoch:\t 49 Val Loss:\t 0.03497013038808893\n",
      "Epoch:\t 50 Val Loss:\t 0.03492496044066558\n",
      "Epoch:\t 51 Val Loss:\t 0.0348213053820505\n",
      "Epoch:\t 52 Val Loss:\t 0.0347296008211336\n",
      "Epoch:\t 53 Val Loss:\t 0.034708648351084\n",
      "Epoch:\t 54 Val Loss:\t 0.03463151199305939\n",
      "Epoch:\t 55 Val Loss:\t 0.03463050965638981\n",
      "Epoch:\t 56 Val Loss:\t 0.03454402810819088\n",
      "Epoch:\t 57 Val Loss:\t 0.034480126209293534\n",
      "Epoch:\t 58 Val Loss:\t 0.03443321559302676\n",
      "Epoch:\t 59 Val Loss:\t 0.034374478641430284\n",
      "Epoch:\t 60 Val Loss:\t 0.034353218793006575\n",
      "Epoch:\t 61 Val Loss:\t 0.03436118352954602\n",
      "Epoch:\t 62 Val Loss:\t 0.034305457433032836\n",
      "Epoch:\t 63 Val Loss:\t 0.03421521530609422\n",
      "Epoch:\t 64 Val Loss:\t 0.034238253094231966\n",
      "Epoch:\t 65 Val Loss:\t 0.0341887871863566\n",
      "Epoch:\t 66 Val Loss:\t 0.03413115752040381\n",
      "Epoch:\t 67 Val Loss:\t 0.03411070603002881\n",
      "Epoch:\t 68 Val Loss:\t 0.034025183648254326\n",
      "Epoch:\t 69 Val Loss:\t 0.033989010869833816\n",
      "Epoch:\t 70 Val Loss:\t 0.03399785968603812\n",
      "Epoch:\t 71 Val Loss:\t 0.033918403538237434\n",
      "Epoch:\t 72 Val Loss:\t 0.03389022972470694\n",
      "Epoch:\t 73 Val Loss:\t 0.0338745473725332\n",
      "Epoch:\t 74 Val Loss:\t 0.03382048233624823\n",
      "Epoch:\t 75 Val Loss:\t 0.03382727734960161\n",
      "Epoch:\t 76 Val Loss:\t 0.03380943731168267\n",
      "Epoch:\t 77 Val Loss:\t 0.03377449226796244\n",
      "Epoch:\t 78 Val Loss:\t 0.033774075688273196\n",
      "Epoch:\t 79 Val Loss:\t 0.03371336385967072\n",
      "Epoch:\t 80 Val Loss:\t 0.03369179704013937\n",
      "Epoch:\t 81 Val Loss:\t 0.033659570799523614\n",
      "Epoch:\t 82 Val Loss:\t 0.03367890672716297\n",
      "Epoch:\t 83 Val Loss:\t 0.03361129284599778\n",
      "Epoch:\t 84 Val Loss:\t 0.033611938638846206\n",
      "Epoch:\t 85 Val Loss:\t 0.03359350848380009\n",
      "Epoch:\t 86 Val Loss:\t 0.03352943986917807\n",
      "Epoch:\t 87 Val Loss:\t 0.03353029058892819\n",
      "Epoch:\t 88 Val Loss:\t 0.0335183711632655\n",
      "Epoch:\t 89 Val Loss:\t 0.033521445288391745\n",
      "Epoch:\t 90 Val Loss:\t 0.033451950842352925\n",
      "Epoch:\t 91 Val Loss:\t 0.03344307682354159\n",
      "Epoch:\t 92 Val Loss:\t 0.033403945332123534\n",
      "Epoch:\t 93 Val Loss:\t 0.03341981687753722\n",
      "Epoch:\t 94 Val Loss:\t 0.033348658730027375\n",
      "Epoch:\t 95 Val Loss:\t 0.033351623360367066\n",
      "Epoch:\t 96 Val Loss:\t 0.0333226590246633\n",
      "Epoch:\t 97 Val Loss:\t 0.03330747465755778\n",
      "Epoch:\t 98 Val Loss:\t 0.033299480519973196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 13:14:53,829] Trial 4 finished with value: 0.03326033799043614 and parameters: {'lr': 1e-06, 'weight_decay': 0.0001, 'scheduler_factor': 0.1, 'scheduler_patience': 1, 'batch_size': 256, 'dropout': 0.15, 'hidden_dims': 64}. Best is trial 1 with value: 0.030746468184126536.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 99 Val Loss:\t 0.03326033799043614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 13:14:56,274] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.037799951756435836\n",
      "Epoch:\t 0 Val Loss:\t 0.031235127475762178\n",
      "Epoch:\t 1 Val Loss:\t 0.031907341717359775\n",
      "Epoch:\t 2 Val Loss:\t 0.03184783483644526\n",
      "Epoch:\t 3 Val Loss:\t 0.03162778645216344\n",
      "Epoch:\t 4 Val Loss:\t 0.031770578176081775\n",
      "Epoch:\t 5 Val Loss:\t 0.03160420994989141\n",
      "Epoch:\t 6 Val Loss:\t 0.03168558049835041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 13:15:42,862] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 7 Val Loss:\t 0.03154356272700793\n",
      "Epoch:\t 0 Val Loss:\t 0.03241701871694856\n",
      "Epoch:\t 1 Val Loss:\t 0.03138290013801037\n",
      "Epoch:\t 2 Val Loss:\t 0.031184287057116174\n",
      "Epoch:\t 3 Val Loss:\t 0.03107668420249061\n",
      "Epoch:\t 4 Val Loss:\t 0.031070072063354007\n",
      "Epoch:\t 5 Val Loss:\t 0.031009414494874772\n",
      "Epoch:\t 6 Val Loss:\t 0.030951566638404066\n",
      "Epoch:\t 7 Val Loss:\t 0.03084956192042242\n",
      "Epoch:\t 8 Val Loss:\t 0.03082346036300709\n",
      "Epoch:\t 9 Val Loss:\t 0.030835427801284707\n",
      "Epoch:\t 10 Val Loss:\t 0.030795850272306854\n",
      "Epoch:\t 11 Val Loss:\t 0.030819582589939356\n",
      "Epoch:\t 12 Val Loss:\t 0.0308308137302701\n",
      "Epoch:\t 13 Val Loss:\t 0.03081441866488078\n",
      "Epoch:\t 14 Val Loss:\t 0.03081832912243771\n",
      "Epoch:\t 15 Val Loss:\t 0.030825917574653274\n",
      "Epoch:\t 16 Val Loss:\t 0.030837459286396807\n",
      "Epoch:\t 17 Val Loss:\t 0.030833405453000177\n",
      "Epoch:\t 18 Val Loss:\t 0.03081280194270764\n",
      "Epoch:\t 19 Val Loss:\t 0.030814554051975952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 13:16:33,966] Trial 7 finished with value: 0.030795850272306854 and parameters: {'lr': 0.001, 'weight_decay': 1e-06, 'scheduler_factor': 0.5, 'scheduler_patience': 20, 'batch_size': 128, 'dropout': 0.15, 'hidden_dims': 1024}. Best is trial 1 with value: 0.030746468184126536.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 20 Val Loss:\t 0.03083474620172147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 13:16:36,343] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03447395909643384\n",
      "Epoch:\t 0 Val Loss:\t 0.030809826901855412\n",
      "Epoch:\t 1 Val Loss:\t 0.03079601381036752\n",
      "Epoch:\t 2 Val Loss:\t 0.03078554575283926\n",
      "Epoch:\t 3 Val Loss:\t 0.030765967538005198\n",
      "Epoch:\t 4 Val Loss:\t 0.030736572868439817\n",
      "Epoch:\t 5 Val Loss:\t 0.03073354947814194\n",
      "Epoch:\t 6 Val Loss:\t 0.030753512409810693\n",
      "Epoch:\t 7 Val Loss:\t 0.03073448635711654\n",
      "Epoch:\t 8 Val Loss:\t 0.030726988450367473\n",
      "Epoch:\t 9 Val Loss:\t 0.03071802826174704\n",
      "Epoch:\t 10 Val Loss:\t 0.030734485705321356\n",
      "Epoch:\t 11 Val Loss:\t 0.030760384451741986\n",
      "Epoch:\t 12 Val Loss:\t 0.030709956706382307\n",
      "Epoch:\t 13 Val Loss:\t 0.030746665097096837\n",
      "Epoch:\t 14 Val Loss:\t 0.030739081826637978\n",
      "Epoch:\t 15 Val Loss:\t 0.03072014828538177\n",
      "Epoch:\t 16 Val Loss:\t 0.030717290838442532\n",
      "Epoch:\t 17 Val Loss:\t 0.030752623349799883\n",
      "Epoch:\t 18 Val Loss:\t 0.030710100868623164\n",
      "Epoch:\t 19 Val Loss:\t 0.03069389887725846\n",
      "Epoch:\t 20 Val Loss:\t 0.0306937871624006\n",
      "Epoch:\t 21 Val Loss:\t 0.030680574672089518\n",
      "Epoch:\t 22 Val Loss:\t 0.030693132689129765\n",
      "Epoch:\t 23 Val Loss:\t 0.03070227055174271\n",
      "Epoch:\t 24 Val Loss:\t 0.030697706086063606\n",
      "Epoch:\t 25 Val Loss:\t 0.030694100825350037\n",
      "Epoch:\t 26 Val Loss:\t 0.03068164735491345\n",
      "Epoch:\t 27 Val Loss:\t 0.03069491648441582\n",
      "Epoch:\t 28 Val Loss:\t 0.030690644705935678\n",
      "Epoch:\t 29 Val Loss:\t 0.03068339913162421\n",
      "Epoch:\t 30 Val Loss:\t 0.03066384588653549\n",
      "Epoch:\t 31 Val Loss:\t 0.03067808741178536\n",
      "Epoch:\t 32 Val Loss:\t 0.030692104628431645\n",
      "Epoch:\t 33 Val Loss:\t 0.030684515578771936\n",
      "Epoch:\t 34 Val Loss:\t 0.030687455469871172\n",
      "Epoch:\t 35 Val Loss:\t 0.03068066304211828\n",
      "Epoch:\t 36 Val Loss:\t 0.030666468117331615\n",
      "Epoch:\t 37 Val Loss:\t 0.030700450468091122\n",
      "Epoch:\t 38 Val Loss:\t 0.030676026862734927\n",
      "Epoch:\t 39 Val Loss:\t 0.030679130122107344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 13:31:33,908] Trial 9 finished with value: 0.03066384588653549 and parameters: {'lr': 0.0001, 'weight_decay': 0.0001, 'scheduler_factor': 0.3, 'scheduler_patience': 5, 'batch_size': 16, 'dropout': 0.05, 'hidden_dims': 512}. Best is trial 9 with value: 0.03066384588653549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 40 Val Loss:\t 0.030671222923064883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 13:31:57,340] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03764291133965227\n",
      "Epoch:\t 0 Val Loss:\t 0.0318355720756096\n",
      "Epoch:\t 1 Val Loss:\t 0.03134597822689207\n",
      "Epoch:\t 2 Val Loss:\t 0.031141195715119002\n",
      "Epoch:\t 3 Val Loss:\t 0.03107218513206998\n",
      "Epoch:\t 4 Val Loss:\t 0.030956521549627317\n",
      "Epoch:\t 5 Val Loss:\t 0.030866035970514932\n",
      "Epoch:\t 6 Val Loss:\t 0.03079853667231589\n",
      "Epoch:\t 7 Val Loss:\t 0.03075938667047473\n",
      "Epoch:\t 8 Val Loss:\t 0.030727356727553924\n",
      "Epoch:\t 9 Val Loss:\t 0.030729991268088747\n",
      "Epoch:\t 10 Val Loss:\t 0.0307266538187491\n",
      "Epoch:\t 11 Val Loss:\t 0.030708626666985327\n",
      "Epoch:\t 12 Val Loss:\t 0.030708242467669553\n",
      "Epoch:\t 13 Val Loss:\t 0.03070282500084869\n",
      "Epoch:\t 14 Val Loss:\t 0.030703905665143166\n",
      "Epoch:\t 15 Val Loss:\t 0.030714583751217498\n",
      "Epoch:\t 16 Val Loss:\t 0.030706908742045055\n",
      "Epoch:\t 17 Val Loss:\t 0.030701141596832272\n",
      "Epoch:\t 18 Val Loss:\t 0.030709208535223173\n",
      "Epoch:\t 19 Val Loss:\t 0.030718172009386056\n",
      "Epoch:\t 20 Val Loss:\t 0.03070238629339596\n",
      "Epoch:\t 21 Val Loss:\t 0.030711684192276135\n",
      "Epoch:\t 22 Val Loss:\t 0.030713927423478414\n",
      "Epoch:\t 23 Val Loss:\t 0.0307144977170272\n",
      "Epoch:\t 24 Val Loss:\t 0.030713298673940927\n",
      "Epoch:\t 25 Val Loss:\t 0.03072369450131176\n",
      "Epoch:\t 26 Val Loss:\t 0.030708283665436886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 13:33:35,623] Trial 11 finished with value: 0.030701141596832272 and parameters: {'lr': 0.0001, 'weight_decay': 1e-05, 'scheduler_factor': 0.5, 'scheduler_patience': 1, 'batch_size': 64, 'dropout': 0.05, 'hidden_dims': 512}. Best is trial 9 with value: 0.03066384588653549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 27 Val Loss:\t 0.030719960296605717\n",
      "Epoch:\t 0 Val Loss:\t 0.03081046050203831\n",
      "Epoch:\t 1 Val Loss:\t 0.030761425309450797\n",
      "Epoch:\t 2 Val Loss:\t 0.030734647123655416\n",
      "Epoch:\t 3 Val Loss:\t 0.03073829841600625\n",
      "Epoch:\t 4 Val Loss:\t 0.030756765216254384\n",
      "Epoch:\t 5 Val Loss:\t 0.03071799572727493\n",
      "Epoch:\t 6 Val Loss:\t 0.030727870427759152\n",
      "Epoch:\t 7 Val Loss:\t 0.030751222504098223\n",
      "Epoch:\t 8 Val Loss:\t 0.03072198712190056\n",
      "Epoch:\t 9 Val Loss:\t 0.030705391192613073\n",
      "Epoch:\t 10 Val Loss:\t 0.030722497773462042\n",
      "Epoch:\t 11 Val Loss:\t 0.03071173294518313\n",
      "Epoch:\t 12 Val Loss:\t 0.030706089121418756\n",
      "Epoch:\t 13 Val Loss:\t 0.030720182176927326\n",
      "Epoch:\t 14 Val Loss:\t 0.030698869068178543\n",
      "Epoch:\t 15 Val Loss:\t 0.030703477008804474\n",
      "Epoch:\t 16 Val Loss:\t 0.030708305837934553\n",
      "Epoch:\t 17 Val Loss:\t 0.03072000920485762\n",
      "Epoch:\t 18 Val Loss:\t 0.03071962961958424\n",
      "Epoch:\t 19 Val Loss:\t 0.030718315117891637\n",
      "Epoch:\t 20 Val Loss:\t 0.030729646444225083\n",
      "Epoch:\t 21 Val Loss:\t 0.030698431322669258\n",
      "Epoch:\t 22 Val Loss:\t 0.030694795932259288\n",
      "Epoch:\t 23 Val Loss:\t 0.03070952947779522\n",
      "Epoch:\t 24 Val Loss:\t 0.030715041869314747\n",
      "Epoch:\t 25 Val Loss:\t 0.03068723085201207\n",
      "Epoch:\t 26 Val Loss:\t 0.030709644878147216\n",
      "Epoch:\t 27 Val Loss:\t 0.03070523003870569\n",
      "Epoch:\t 28 Val Loss:\t 0.030678587929071573\n",
      "Epoch:\t 29 Val Loss:\t 0.030719002702817882\n",
      "Epoch:\t 30 Val Loss:\t 0.030715639000189428\n",
      "Epoch:\t 31 Val Loss:\t 0.030714639176486872\n",
      "Epoch:\t 32 Val Loss:\t 0.03071124959250116\n",
      "Epoch:\t 33 Val Loss:\t 0.030707840615795342\n",
      "Epoch:\t 34 Val Loss:\t 0.030689258551122\n",
      "Epoch:\t 35 Val Loss:\t 0.03070242848895556\n",
      "Epoch:\t 36 Val Loss:\t 0.03068826526982983\n",
      "Epoch:\t 37 Val Loss:\t 0.030687172599166705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 13:35:47,625] Trial 12 finished with value: 0.030678587929071573 and parameters: {'lr': 0.001, 'weight_decay': 1e-05, 'scheduler_factor': 0.8, 'scheduler_patience': 5, 'batch_size': 64, 'dropout': 0.05, 'hidden_dims': 128}. Best is trial 9 with value: 0.03066384588653549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 38 Val Loss:\t 0.030696245669159492\n",
      "Epoch:\t 0 Val Loss:\t 0.030871042854779228\n",
      "Epoch:\t 1 Val Loss:\t 0.030735495922237083\n",
      "Epoch:\t 2 Val Loss:\t 0.03073731751450798\n",
      "Epoch:\t 3 Val Loss:\t 0.03072549992426931\n",
      "Epoch:\t 4 Val Loss:\t 0.03072675795062074\n",
      "Epoch:\t 5 Val Loss:\t 0.030708246224327572\n",
      "Epoch:\t 6 Val Loss:\t 0.030706229621922387\n",
      "Epoch:\t 7 Val Loss:\t 0.03070975486084568\n",
      "Epoch:\t 8 Val Loss:\t 0.030712544505798828\n",
      "Epoch:\t 9 Val Loss:\t 0.030707684222313052\n",
      "Epoch:\t 10 Val Loss:\t 0.030722089510623128\n",
      "Epoch:\t 11 Val Loss:\t 0.03071119030003989\n",
      "Epoch:\t 12 Val Loss:\t 0.030694837575149517\n",
      "Epoch:\t 13 Val Loss:\t 0.030695950573589578\n",
      "Epoch:\t 14 Val Loss:\t 0.03069203622704902\n",
      "Epoch:\t 15 Val Loss:\t 0.030695493550375163\n",
      "Epoch:\t 16 Val Loss:\t 0.03069422738634068\n",
      "Epoch:\t 17 Val Loss:\t 0.030691506308238317\n",
      "Epoch:\t 18 Val Loss:\t 0.030703280143493543\n",
      "Epoch:\t 19 Val Loss:\t 0.03069575717814607\n",
      "Epoch:\t 20 Val Loss:\t 0.030711328791515675\n",
      "Epoch:\t 21 Val Loss:\t 0.03070205485309327\n",
      "Epoch:\t 22 Val Loss:\t 0.03069910245597267\n",
      "Epoch:\t 23 Val Loss:\t 0.030702397454329844\n",
      "Epoch:\t 24 Val Loss:\t 0.030697586603385025\n",
      "Epoch:\t 25 Val Loss:\t 0.03068126455313842\n",
      "Epoch:\t 26 Val Loss:\t 0.030697563930497516\n",
      "Epoch:\t 27 Val Loss:\t 0.030683813407515276\n",
      "Epoch:\t 28 Val Loss:\t 0.030683975704103923\n",
      "Epoch:\t 29 Val Loss:\t 0.03067361968535849\n",
      "Epoch:\t 30 Val Loss:\t 0.03070383364037456\n",
      "Epoch:\t 31 Val Loss:\t 0.030701014249859663\n",
      "Epoch:\t 32 Val Loss:\t 0.030697724685586732\n",
      "Epoch:\t 33 Val Loss:\t 0.03069213658433823\n",
      "Epoch:\t 34 Val Loss:\t 0.030671332739502694\n",
      "Epoch:\t 35 Val Loss:\t 0.03068887396493767\n",
      "Epoch:\t 36 Val Loss:\t 0.03068157865455988\n",
      "Epoch:\t 37 Val Loss:\t 0.03068382711969047\n",
      "Epoch:\t 38 Val Loss:\t 0.030672851655671095\n",
      "Epoch:\t 39 Val Loss:\t 0.030660669880216374\n",
      "Epoch:\t 40 Val Loss:\t 0.030667374525951117\n",
      "Epoch:\t 41 Val Loss:\t 0.030691921486912868\n",
      "Epoch:\t 42 Val Loss:\t 0.03068359052193289\n",
      "Epoch:\t 43 Val Loss:\t 0.03068413131638059\n",
      "Epoch:\t 44 Val Loss:\t 0.030683644459476064\n",
      "Epoch:\t 45 Val Loss:\t 0.030688984461469275\n",
      "Epoch:\t 46 Val Loss:\t 0.03065980081360581\n",
      "Epoch:\t 47 Val Loss:\t 0.030674830585443316\n",
      "Epoch:\t 48 Val Loss:\t 0.030695696109674316\n",
      "Epoch:\t 49 Val Loss:\t 0.03067578789990906\n",
      "Epoch:\t 50 Val Loss:\t 0.03068338987457102\n",
      "Epoch:\t 51 Val Loss:\t 0.03067148388262596\n",
      "Epoch:\t 52 Val Loss:\t 0.030670824722829778\n",
      "Epoch:\t 53 Val Loss:\t 0.03066225477465172\n",
      "Epoch:\t 54 Val Loss:\t 0.030649624484103494\n",
      "Epoch:\t 55 Val Loss:\t 0.030663943735235868\n",
      "Epoch:\t 56 Val Loss:\t 0.03067783259584269\n",
      "Epoch:\t 57 Val Loss:\t 0.030657957024938027\n",
      "Epoch:\t 58 Val Loss:\t 0.030673732636040847\n",
      "Epoch:\t 59 Val Loss:\t 0.03066137121167294\n",
      "Epoch:\t 60 Val Loss:\t 0.030680105478503555\n",
      "Epoch:\t 61 Val Loss:\t 0.03065794242102333\n",
      "Epoch:\t 62 Val Loss:\t 0.030674568063011148\n",
      "Epoch:\t 63 Val Loss:\t 0.03066094122743406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 13:39:30,361] Trial 13 finished with value: 0.030649624484103494 and parameters: {'lr': 0.001, 'weight_decay': 1e-05, 'scheduler_factor': 0.8, 'scheduler_patience': 5, 'batch_size': 64, 'dropout': 0.05, 'hidden_dims': 128}. Best is trial 13 with value: 0.030649624484103494.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 64 Val Loss:\t 0.030671708556168444\n",
      "Epoch:\t 0 Val Loss:\t 0.030799304751298263\n",
      "Epoch:\t 1 Val Loss:\t 0.030800515807085777\n",
      "Epoch:\t 2 Val Loss:\t 0.03080366706194595\n",
      "Epoch:\t 3 Val Loss:\t 0.030777931917235598\n",
      "Epoch:\t 4 Val Loss:\t 0.03080844573629563\n",
      "Epoch:\t 5 Val Loss:\t 0.030778053585731765\n",
      "Epoch:\t 6 Val Loss:\t 0.03077330187719186\n",
      "Epoch:\t 7 Val Loss:\t 0.03078310056644591\n",
      "Epoch:\t 8 Val Loss:\t 0.030813294489730088\n",
      "Epoch:\t 9 Val Loss:\t 0.030758103800434086\n",
      "Epoch:\t 10 Val Loss:\t 0.03076935390283286\n",
      "Epoch:\t 11 Val Loss:\t 0.030771187793980723\n",
      "Epoch:\t 12 Val Loss:\t 0.030783397753326815\n",
      "Epoch:\t 13 Val Loss:\t 0.0307489935571055\n",
      "Epoch:\t 14 Val Loss:\t 0.030755835733270266\n",
      "Epoch:\t 15 Val Loss:\t 0.030774373728151228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 13:46:09,780] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 16 Val Loss:\t 0.030787398452560604\n",
      "Epoch:\t 0 Val Loss:\t 0.030932178516194835\n",
      "Epoch:\t 1 Val Loss:\t 0.030904882885485815\n",
      "Epoch:\t 2 Val Loss:\t 0.030909491009836972\n",
      "Epoch:\t 3 Val Loss:\t 0.030877274881567395\n",
      "Epoch:\t 4 Val Loss:\t 0.030866451919939197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 13:46:30,919] Trial 15 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 5 Val Loss:\t 0.030866308030227996\n",
      "Epoch:\t 0 Val Loss:\t 0.031014785660940954\n",
      "Epoch:\t 1 Val Loss:\t 0.030963152939234653\n",
      "Epoch:\t 2 Val Loss:\t 0.030955931879176963\n",
      "Epoch:\t 3 Val Loss:\t 0.03092008272301241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 13:48:34,101] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 4 Val Loss:\t 0.030945219722020557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 13:48:37,588] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.07164856670805236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 13:49:02,087] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.032701209880354895\n",
      "Epoch:\t 0 Val Loss:\t 0.030934017616135172\n",
      "Epoch:\t 1 Val Loss:\t 0.030891638001204494\n",
      "Epoch:\t 2 Val Loss:\t 0.030748334297284474\n",
      "Epoch:\t 3 Val Loss:\t 0.03074021875983778\n",
      "Epoch:\t 4 Val Loss:\t 0.030728939129002302\n",
      "Epoch:\t 5 Val Loss:\t 0.030712140051897468\n",
      "Epoch:\t 6 Val Loss:\t 0.030726361849495384\n",
      "Epoch:\t 7 Val Loss:\t 0.030711568369206754\n",
      "Epoch:\t 8 Val Loss:\t 0.03072857635384\n",
      "Epoch:\t 9 Val Loss:\t 0.030751021917978093\n",
      "Epoch:\t 10 Val Loss:\t 0.03072781114276639\n",
      "Epoch:\t 11 Val Loss:\t 0.030725642720591383\n",
      "Epoch:\t 12 Val Loss:\t 0.03071549302676533\n",
      "Epoch:\t 13 Val Loss:\t 0.030734718530031808\n",
      "Epoch:\t 14 Val Loss:\t 0.030746620493465264\n",
      "Epoch:\t 15 Val Loss:\t 0.030703884412765312\n",
      "Epoch:\t 16 Val Loss:\t 0.03069543528856759\n",
      "Epoch:\t 17 Val Loss:\t 0.030725116134227612\n",
      "Epoch:\t 18 Val Loss:\t 0.030717579780838063\n",
      "Epoch:\t 19 Val Loss:\t 0.030727416306805783\n",
      "Epoch:\t 20 Val Loss:\t 0.03073108998525353\n",
      "Epoch:\t 21 Val Loss:\t 0.03072128120328822\n",
      "Epoch:\t 22 Val Loss:\t 0.0307038924488767\n",
      "Epoch:\t 23 Val Loss:\t 0.030731918796622095\n",
      "Epoch:\t 24 Val Loss:\t 0.03072039824824574\n",
      "Epoch:\t 25 Val Loss:\t 0.03072322611252642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 13:50:38,015] Trial 19 finished with value: 0.03069543528856759 and parameters: {'lr': 0.001, 'weight_decay': 1e-05, 'scheduler_factor': 0.8, 'scheduler_patience': 10, 'batch_size': 64, 'dropout': 0.1, 'hidden_dims': 512}. Best is trial 13 with value: 0.030649624484103494.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 26 Val Loss:\t 0.030717532231854073\n",
      "Epoch:\t 0 Val Loss:\t 0.030936125525952794\n",
      "Epoch:\t 1 Val Loss:\t 0.0307644026600641\n",
      "Epoch:\t 2 Val Loss:\t 0.030734803541402043\n",
      "Epoch:\t 3 Val Loss:\t 0.030721636703810753\n",
      "Epoch:\t 4 Val Loss:\t 0.03070044765210455\n",
      "Epoch:\t 5 Val Loss:\t 0.03070749643390677\n",
      "Epoch:\t 6 Val Loss:\t 0.030696339451823033\n",
      "Epoch:\t 7 Val Loss:\t 0.030744146980551255\n",
      "Epoch:\t 8 Val Loss:\t 0.030708083025499076\n",
      "Epoch:\t 9 Val Loss:\t 0.03071343110964983\n",
      "Epoch:\t 10 Val Loss:\t 0.03071720378917137\n",
      "Epoch:\t 11 Val Loss:\t 0.030707028250528515\n",
      "Epoch:\t 12 Val Loss:\t 0.030701052680935547\n",
      "Epoch:\t 13 Val Loss:\t 0.030690674835741758\n",
      "Epoch:\t 14 Val Loss:\t 0.030712881789807148\n",
      "Epoch:\t 15 Val Loss:\t 0.030703695042555556\n",
      "Epoch:\t 16 Val Loss:\t 0.030712413900697715\n",
      "Epoch:\t 17 Val Loss:\t 0.030742908641733298\n",
      "Epoch:\t 18 Val Loss:\t 0.030743628374760495\n",
      "Epoch:\t 19 Val Loss:\t 0.03075501785086077\n",
      "Epoch:\t 20 Val Loss:\t 0.030767056221253253\n",
      "Epoch:\t 21 Val Loss:\t 0.03077391316366713\n",
      "Epoch:\t 22 Val Loss:\t 0.03076508363898813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:00:05,352] Trial 20 finished with value: 0.030690674835741758 and parameters: {'lr': 0.0001, 'weight_decay': 1e-05, 'scheduler_factor': 0.3, 'scheduler_patience': 5, 'batch_size': 16, 'dropout': 0.05, 'hidden_dims': 64}. Best is trial 13 with value: 0.030649624484103494.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 23 Val Loss:\t 0.030800973715873047\n",
      "Epoch:\t 0 Val Loss:\t 0.03087977208077621\n",
      "Epoch:\t 1 Val Loss:\t 0.030750665954092357\n",
      "Epoch:\t 2 Val Loss:\t 0.03074163925754087\n",
      "Epoch:\t 3 Val Loss:\t 0.03074313501686264\n",
      "Epoch:\t 4 Val Loss:\t 0.030690378788037116\n",
      "Epoch:\t 5 Val Loss:\t 0.030692437381364866\n",
      "Epoch:\t 6 Val Loss:\t 0.030726979696509258\n",
      "Epoch:\t 7 Val Loss:\t 0.030719744488178678\n",
      "Epoch:\t 8 Val Loss:\t 0.030693713036375515\n",
      "Epoch:\t 9 Val Loss:\t 0.03068511505740446\n",
      "Epoch:\t 10 Val Loss:\t 0.030694039541490095\n",
      "Epoch:\t 11 Val Loss:\t 0.03072312635869242\n",
      "Epoch:\t 12 Val Loss:\t 0.0306976329409775\n",
      "Epoch:\t 13 Val Loss:\t 0.030698153019286006\n",
      "Epoch:\t 14 Val Loss:\t 0.030723783628956832\n",
      "Epoch:\t 15 Val Loss:\t 0.030707012291373303\n",
      "Epoch:\t 16 Val Loss:\t 0.03068325821378992\n",
      "Epoch:\t 17 Val Loss:\t 0.030715805181894384\n",
      "Epoch:\t 18 Val Loss:\t 0.03070522390855678\n",
      "Epoch:\t 19 Val Loss:\t 0.03068819006347809\n",
      "Epoch:\t 20 Val Loss:\t 0.03069537865788151\n",
      "Epoch:\t 21 Val Loss:\t 0.03070740884359636\n",
      "Epoch:\t 22 Val Loss:\t 0.030706817536661886\n",
      "Epoch:\t 23 Val Loss:\t 0.03069848273735144\n",
      "Epoch:\t 24 Val Loss:\t 0.030703288009323017\n",
      "Epoch:\t 25 Val Loss:\t 0.030674392130426054\n",
      "Epoch:\t 26 Val Loss:\t 0.03067559468968448\n",
      "Epoch:\t 27 Val Loss:\t 0.03067109142314365\n",
      "Epoch:\t 28 Val Loss:\t 0.030677758963851807\n",
      "Epoch:\t 29 Val Loss:\t 0.030672427725402372\n",
      "Epoch:\t 30 Val Loss:\t 0.030684412808815478\n",
      "Epoch:\t 31 Val Loss:\t 0.030693668528566767\n",
      "Epoch:\t 32 Val Loss:\t 0.030701386076850037\n",
      "Epoch:\t 33 Val Loss:\t 0.03068988438346143\n",
      "Epoch:\t 34 Val Loss:\t 0.030661960669405575\n",
      "Epoch:\t 35 Val Loss:\t 0.030678313134391975\n",
      "Epoch:\t 36 Val Loss:\t 0.030674575766027213\n",
      "Epoch:\t 37 Val Loss:\t 0.030698731934476968\n",
      "Epoch:\t 38 Val Loss:\t 0.030693181903185898\n",
      "Epoch:\t 39 Val Loss:\t 0.03069364976469478\n",
      "Epoch:\t 40 Val Loss:\t 0.030672806372631523\n",
      "Epoch:\t 41 Val Loss:\t 0.030650251111091858\n",
      "Epoch:\t 42 Val Loss:\t 0.03068228368890123\n",
      "Epoch:\t 43 Val Loss:\t 0.03066827362640772\n",
      "Epoch:\t 44 Val Loss:\t 0.03067847876193386\n",
      "Epoch:\t 45 Val Loss:\t 0.030669934499438226\n",
      "Epoch:\t 46 Val Loss:\t 0.03070217598776341\n",
      "Epoch:\t 47 Val Loss:\t 0.030664122568588307\n",
      "Epoch:\t 48 Val Loss:\t 0.03066317350233949\n",
      "Epoch:\t 49 Val Loss:\t 0.030650723438766736\n",
      "Epoch:\t 50 Val Loss:\t 0.030674325079681784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:03:08,970] Trial 21 finished with value: 0.030650251111091858 and parameters: {'lr': 0.001, 'weight_decay': 1e-05, 'scheduler_factor': 0.8, 'scheduler_patience': 5, 'batch_size': 64, 'dropout': 0.05, 'hidden_dims': 128}. Best is trial 13 with value: 0.030649624484103494.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 51 Val Loss:\t 0.03067561997953614\n",
      "Epoch:\t 0 Val Loss:\t 0.030843193135683594\n",
      "Epoch:\t 1 Val Loss:\t 0.030760021957941502\n",
      "Epoch:\t 2 Val Loss:\t 0.030734586557067196\n",
      "Epoch:\t 3 Val Loss:\t 0.030726174112191272\n",
      "Epoch:\t 4 Val Loss:\t 0.030737255018058067\n",
      "Epoch:\t 5 Val Loss:\t 0.03072491023202562\n",
      "Epoch:\t 6 Val Loss:\t 0.030718223551032823\n",
      "Epoch:\t 7 Val Loss:\t 0.03072772563585254\n",
      "Epoch:\t 8 Val Loss:\t 0.030713265788619673\n",
      "Epoch:\t 9 Val Loss:\t 0.030715037406136153\n",
      "Epoch:\t 10 Val Loss:\t 0.030712105090331822\n",
      "Epoch:\t 11 Val Loss:\t 0.030719655527828117\n",
      "Epoch:\t 12 Val Loss:\t 0.030727619294797122\n",
      "Epoch:\t 13 Val Loss:\t 0.030692137280402893\n",
      "Epoch:\t 14 Val Loss:\t 0.030719557935379463\n",
      "Epoch:\t 15 Val Loss:\t 0.03069426363547659\n",
      "Epoch:\t 16 Val Loss:\t 0.030716480074843216\n",
      "Epoch:\t 17 Val Loss:\t 0.03071737052826472\n",
      "Epoch:\t 18 Val Loss:\t 0.030722302722997825\n",
      "Epoch:\t 19 Val Loss:\t 0.030713873787662844\n",
      "Epoch:\t 20 Val Loss:\t 0.0307159194216407\n",
      "Epoch:\t 21 Val Loss:\t 0.0306994754092136\n",
      "Epoch:\t 22 Val Loss:\t 0.030694259263413758\n",
      "Epoch:\t 23 Val Loss:\t 0.03067623474504485\n",
      "Epoch:\t 24 Val Loss:\t 0.03068784096762956\n",
      "Epoch:\t 25 Val Loss:\t 0.030697177538428672\n",
      "Epoch:\t 26 Val Loss:\t 0.03069271397296677\n",
      "Epoch:\t 27 Val Loss:\t 0.030699816727361013\n",
      "Epoch:\t 28 Val Loss:\t 0.030687912651834338\n",
      "Epoch:\t 29 Val Loss:\t 0.030719572551243766\n",
      "Epoch:\t 30 Val Loss:\t 0.0306886236669545\n",
      "Epoch:\t 31 Val Loss:\t 0.030692467168750244\n",
      "Epoch:\t 32 Val Loss:\t 0.030688848791594683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:05:08,976] Trial 22 finished with value: 0.03067623474504485 and parameters: {'lr': 0.001, 'weight_decay': 1e-05, 'scheduler_factor': 0.8, 'scheduler_patience': 5, 'batch_size': 64, 'dropout': 0.05, 'hidden_dims': 128}. Best is trial 13 with value: 0.030649624484103494.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 33 Val Loss:\t 0.030689880440090786\n",
      "Epoch:\t 0 Val Loss:\t 0.030866915627465595\n",
      "Epoch:\t 1 Val Loss:\t 0.030766322514237932\n",
      "Epoch:\t 2 Val Loss:\t 0.030714976651341607\n",
      "Epoch:\t 3 Val Loss:\t 0.0307283058849185\n",
      "Epoch:\t 4 Val Loss:\t 0.030742248653194477\n",
      "Epoch:\t 5 Val Loss:\t 0.030754867383990653\n",
      "Epoch:\t 6 Val Loss:\t 0.030710630929926538\n",
      "Epoch:\t 7 Val Loss:\t 0.0307233835351687\n",
      "Epoch:\t 8 Val Loss:\t 0.030696496286794675\n",
      "Epoch:\t 9 Val Loss:\t 0.030716674886315274\n",
      "Epoch:\t 10 Val Loss:\t 0.030703159025254112\n",
      "Epoch:\t 11 Val Loss:\t 0.030718277412397247\n",
      "Epoch:\t 12 Val Loss:\t 0.03069194834066948\n",
      "Epoch:\t 13 Val Loss:\t 0.03071894644107595\n",
      "Epoch:\t 14 Val Loss:\t 0.03071121619633416\n",
      "Epoch:\t 15 Val Loss:\t 0.0307314464480354\n",
      "Epoch:\t 16 Val Loss:\t 0.03070267777570315\n",
      "Epoch:\t 17 Val Loss:\t 0.030708870836313285\n",
      "Epoch:\t 18 Val Loss:\t 0.03070018554603757\n",
      "Epoch:\t 19 Val Loss:\t 0.03068175282159039\n",
      "Epoch:\t 20 Val Loss:\t 0.030689107947224795\n",
      "Epoch:\t 21 Val Loss:\t 0.030704278047790315\n",
      "Epoch:\t 22 Val Loss:\t 0.03070821344505909\n",
      "Epoch:\t 23 Val Loss:\t 0.03070043176920441\n",
      "Epoch:\t 24 Val Loss:\t 0.030711845178889006\n",
      "Epoch:\t 25 Val Loss:\t 0.03071865169503207\n",
      "Epoch:\t 26 Val Loss:\t 0.030704794590508545\n",
      "Epoch:\t 27 Val Loss:\t 0.030687349761067722\n",
      "Epoch:\t 28 Val Loss:\t 0.030692079129129194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:06:54,774] Trial 23 finished with value: 0.03068175282159039 and parameters: {'lr': 0.001, 'weight_decay': 1e-05, 'scheduler_factor': 0.8, 'scheduler_patience': 5, 'batch_size': 64, 'dropout': 0.05, 'hidden_dims': 128}. Best is trial 13 with value: 0.030649624484103494.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 29 Val Loss:\t 0.030686244444731912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:06:58,406] Trial 24 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.030987520711892303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:07:04,432] Trial 25 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03098228767603815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:07:28,680] Trial 26 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.033709304714383215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:07:32,291] Trial 27 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.0714679780119691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:07:36,114] Trial 28 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03246877865855371\n",
      "Epoch:\t 0 Val Loss:\t 0.030925851171518828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:07:40,035] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 1 Val Loss:\t 0.030949141872130406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:08:03,447] Trial 30 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.030960831178926593\n",
      "Epoch:\t 0 Val Loss:\t 0.03082640153753968\n",
      "Epoch:\t 1 Val Loss:\t 0.030771329588202258\n",
      "Epoch:\t 2 Val Loss:\t 0.030742752605506966\n",
      "Epoch:\t 3 Val Loss:\t 0.03072752295406991\n",
      "Epoch:\t 4 Val Loss:\t 0.030739841866213605\n",
      "Epoch:\t 5 Val Loss:\t 0.030706812090628033\n",
      "Epoch:\t 6 Val Loss:\t 0.030721381606882155\n",
      "Epoch:\t 7 Val Loss:\t 0.030716643355780827\n",
      "Epoch:\t 8 Val Loss:\t 0.030727289561794678\n",
      "Epoch:\t 9 Val Loss:\t 0.030696881796086227\n",
      "Epoch:\t 10 Val Loss:\t 0.03071105413575027\n",
      "Epoch:\t 11 Val Loss:\t 0.030708949678333264\n",
      "Epoch:\t 12 Val Loss:\t 0.030713601627871814\n",
      "Epoch:\t 13 Val Loss:\t 0.030713224180084566\n",
      "Epoch:\t 14 Val Loss:\t 0.030715822646246494\n",
      "Epoch:\t 15 Val Loss:\t 0.03071981695358908\n",
      "Epoch:\t 16 Val Loss:\t 0.03071836690749277\n",
      "Epoch:\t 17 Val Loss:\t 0.030700802165229222\n",
      "Epoch:\t 18 Val Loss:\t 0.03070247216626655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:09:14,322] Trial 31 finished with value: 0.030696881796086227 and parameters: {'lr': 0.001, 'weight_decay': 1e-05, 'scheduler_factor': 0.8, 'scheduler_patience': 5, 'batch_size': 64, 'dropout': 0.05, 'hidden_dims': 128}. Best is trial 13 with value: 0.030649624484103494.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 19 Val Loss:\t 0.030713200233070108\n",
      "Epoch:\t 0 Val Loss:\t 0.030854155543262516\n",
      "Epoch:\t 1 Val Loss:\t 0.030776340828098672\n",
      "Epoch:\t 2 Val Loss:\t 0.030714491779565714\n",
      "Epoch:\t 3 Val Loss:\t 0.030741569891560048\n",
      "Epoch:\t 4 Val Loss:\t 0.030713716079723674\n",
      "Epoch:\t 5 Val Loss:\t 0.030712323439544262\n",
      "Epoch:\t 6 Val Loss:\t 0.030712887635805555\n",
      "Epoch:\t 7 Val Loss:\t 0.03070908566785987\n",
      "Epoch:\t 8 Val Loss:\t 0.03071143919245042\n",
      "Epoch:\t 9 Val Loss:\t 0.030690354001562694\n",
      "Epoch:\t 10 Val Loss:\t 0.030695623051264616\n",
      "Epoch:\t 11 Val Loss:\t 0.030694290180037092\n",
      "Epoch:\t 12 Val Loss:\t 0.03070943314005541\n",
      "Epoch:\t 13 Val Loss:\t 0.03069990308269703\n",
      "Epoch:\t 14 Val Loss:\t 0.03070816861311722\n",
      "Epoch:\t 15 Val Loss:\t 0.030702206599671742\n",
      "Epoch:\t 16 Val Loss:\t 0.030698126268594764\n",
      "Epoch:\t 17 Val Loss:\t 0.030696532335774653\n",
      "Epoch:\t 18 Val Loss:\t 0.030692042974096445\n",
      "Epoch:\t 19 Val Loss:\t 0.03068020607030382\n",
      "Epoch:\t 20 Val Loss:\t 0.030696775390801664\n",
      "Epoch:\t 21 Val Loss:\t 0.030690347953567336\n",
      "Epoch:\t 22 Val Loss:\t 0.030681923532196783\n",
      "Epoch:\t 23 Val Loss:\t 0.030701469883932145\n",
      "Epoch:\t 24 Val Loss:\t 0.0306999596954587\n",
      "Epoch:\t 25 Val Loss:\t 0.030676787566773014\n",
      "Epoch:\t 26 Val Loss:\t 0.030701518039358743\n",
      "Epoch:\t 27 Val Loss:\t 0.030690613841307862\n",
      "Epoch:\t 28 Val Loss:\t 0.030700948189439158\n",
      "Epoch:\t 29 Val Loss:\t 0.030676025220617926\n",
      "Epoch:\t 30 Val Loss:\t 0.03068315191754553\n",
      "Epoch:\t 31 Val Loss:\t 0.030696168816749247\n",
      "Epoch:\t 32 Val Loss:\t 0.03069037003943035\n",
      "Epoch:\t 33 Val Loss:\t 0.030664829265418872\n",
      "Epoch:\t 34 Val Loss:\t 0.030676894926532517\n",
      "Epoch:\t 35 Val Loss:\t 0.03067785324775274\n",
      "Epoch:\t 36 Val Loss:\t 0.030685456808725163\n",
      "Epoch:\t 37 Val Loss:\t 0.030660006998117294\n",
      "Epoch:\t 38 Val Loss:\t 0.030682227575035696\n",
      "Epoch:\t 39 Val Loss:\t 0.030675693281419104\n",
      "Epoch:\t 40 Val Loss:\t 0.030694538764745212\n",
      "Epoch:\t 41 Val Loss:\t 0.030681819654254313\n",
      "Epoch:\t 42 Val Loss:\t 0.030668462902223862\n",
      "Epoch:\t 43 Val Loss:\t 0.030686250636122566\n",
      "Epoch:\t 44 Val Loss:\t 0.030676184114555693\n",
      "Epoch:\t 45 Val Loss:\t 0.0306564686370307\n",
      "Epoch:\t 46 Val Loss:\t 0.030666273447245047\n",
      "Epoch:\t 47 Val Loss:\t 0.030673905682795603\n",
      "Epoch:\t 48 Val Loss:\t 0.03066395329492228\n",
      "Epoch:\t 49 Val Loss:\t 0.030693177522160858\n",
      "Epoch:\t 50 Val Loss:\t 0.03066920168673935\n",
      "Epoch:\t 51 Val Loss:\t 0.030674889706128965\n",
      "Epoch:\t 52 Val Loss:\t 0.030667014063037963\n",
      "Epoch:\t 53 Val Loss:\t 0.03066428879510429\n",
      "Epoch:\t 54 Val Loss:\t 0.03065681390153616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:12:31,158] Trial 32 finished with value: 0.0306564686370307 and parameters: {'lr': 0.001, 'weight_decay': 1e-05, 'scheduler_factor': 0.8, 'scheduler_patience': 5, 'batch_size': 64, 'dropout': 0.05, 'hidden_dims': 128}. Best is trial 13 with value: 0.030649624484103494.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 55 Val Loss:\t 0.03066389856422387\n",
      "Epoch:\t 0 Val Loss:\t 0.030821509170850084\n",
      "Epoch:\t 1 Val Loss:\t 0.030747028427689956\n",
      "Epoch:\t 2 Val Loss:\t 0.030724265716474058\n",
      "Epoch:\t 3 Val Loss:\t 0.030738668710459396\n",
      "Epoch:\t 4 Val Loss:\t 0.03073586478124357\n",
      "Epoch:\t 5 Val Loss:\t 0.030721631298422716\n",
      "Epoch:\t 6 Val Loss:\t 0.030742456137225833\n",
      "Epoch:\t 7 Val Loss:\t 0.030723703735371352\n",
      "Epoch:\t 8 Val Loss:\t 0.030710523643358384\n",
      "Epoch:\t 9 Val Loss:\t 0.030710011895420365\n",
      "Epoch:\t 10 Val Loss:\t 0.030699996321007263\n",
      "Epoch:\t 11 Val Loss:\t 0.03070806820504218\n",
      "Epoch:\t 12 Val Loss:\t 0.03072229664214105\n",
      "Epoch:\t 13 Val Loss:\t 0.030716121510424035\n",
      "Epoch:\t 14 Val Loss:\t 0.030705503412875635\n",
      "Epoch:\t 15 Val Loss:\t 0.030721081688151707\n",
      "Epoch:\t 16 Val Loss:\t 0.030728623169416797\n",
      "Epoch:\t 17 Val Loss:\t 0.030715933664079754\n",
      "Epoch:\t 18 Val Loss:\t 0.03070686908577716\n",
      "Epoch:\t 19 Val Loss:\t 0.03068362461864566\n",
      "Epoch:\t 20 Val Loss:\t 0.030680548268241126\n",
      "Epoch:\t 21 Val Loss:\t 0.03067682980266254\n",
      "Epoch:\t 22 Val Loss:\t 0.030702226117862733\n",
      "Epoch:\t 23 Val Loss:\t 0.03070553097016542\n",
      "Epoch:\t 24 Val Loss:\t 0.03070729816184583\n",
      "Epoch:\t 25 Val Loss:\t 0.030689389217098236\n",
      "Epoch:\t 26 Val Loss:\t 0.030685589571857606\n",
      "Epoch:\t 27 Val Loss:\t 0.030699031820345994\n",
      "Epoch:\t 28 Val Loss:\t 0.03068009468502012\n",
      "Epoch:\t 29 Val Loss:\t 0.030686523823579885\n",
      "Epoch:\t 30 Val Loss:\t 0.03068915115401997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:14:23,461] Trial 33 finished with value: 0.03067682980266254 and parameters: {'lr': 0.001, 'weight_decay': 1e-05, 'scheduler_factor': 0.8, 'scheduler_patience': 5, 'batch_size': 64, 'dropout': 0.05, 'hidden_dims': 128}. Best is trial 13 with value: 0.030649624484103494.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 31 Val Loss:\t 0.030692147401720882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:14:25,526] Trial 34 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03221541934218437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:14:31,473] Trial 35 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03229485958784759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:14:35,071] Trial 36 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03528244284511138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:14:37,233] Trial 37 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03300370792244408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:14:39,713] Trial 38 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.07535545268420422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:14:45,225] Trial 39 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03143239610255481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:14:48,910] Trial 40 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03146409896690079\n",
      "Epoch:\t 0 Val Loss:\t 0.0308561074295781\n",
      "Epoch:\t 1 Val Loss:\t 0.03078444843399305\n",
      "Epoch:\t 2 Val Loss:\t 0.030736883237372423\n",
      "Epoch:\t 3 Val Loss:\t 0.030726682802523338\n",
      "Epoch:\t 4 Val Loss:\t 0.03072484694092677\n",
      "Epoch:\t 5 Val Loss:\t 0.030717630896780045\n",
      "Epoch:\t 6 Val Loss:\t 0.03072083157090636\n",
      "Epoch:\t 7 Val Loss:\t 0.030700403557673586\n",
      "Epoch:\t 8 Val Loss:\t 0.03071559688230228\n",
      "Epoch:\t 9 Val Loss:\t 0.030723656099752705\n",
      "Epoch:\t 10 Val Loss:\t 0.030688184892285225\n",
      "Epoch:\t 11 Val Loss:\t 0.030735340018688724\n",
      "Epoch:\t 12 Val Loss:\t 0.03069933820680178\n",
      "Epoch:\t 13 Val Loss:\t 0.030726901964309127\n",
      "Epoch:\t 14 Val Loss:\t 0.030717238177393757\n",
      "Epoch:\t 15 Val Loss:\t 0.030704591468084116\n",
      "Epoch:\t 16 Val Loss:\t 0.030710358918011906\n",
      "Epoch:\t 17 Val Loss:\t 0.03068731203615522\n",
      "Epoch:\t 18 Val Loss:\t 0.030714586695302172\n",
      "Epoch:\t 19 Val Loss:\t 0.030704213487045613\n",
      "Epoch:\t 20 Val Loss:\t 0.03070826692552976\n",
      "Epoch:\t 21 Val Loss:\t 0.030698637336898826\n",
      "Epoch:\t 22 Val Loss:\t 0.03071747063013106\n",
      "Epoch:\t 23 Val Loss:\t 0.03066852550323285\n",
      "Epoch:\t 24 Val Loss:\t 0.030689338626939004\n",
      "Epoch:\t 25 Val Loss:\t 0.030674800547116167\n",
      "Epoch:\t 26 Val Loss:\t 0.03068274790577967\n",
      "Epoch:\t 27 Val Loss:\t 0.030693360360125686\n",
      "Epoch:\t 28 Val Loss:\t 0.03068174960117103\n",
      "Epoch:\t 29 Val Loss:\t 0.030699296495201308\n",
      "Epoch:\t 30 Val Loss:\t 0.03068300806368315\n",
      "Epoch:\t 31 Val Loss:\t 0.030673989990267547\n",
      "Epoch:\t 32 Val Loss:\t 0.030673875051469162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:16:48,545] Trial 41 finished with value: 0.03066852550323285 and parameters: {'lr': 0.001, 'weight_decay': 1e-05, 'scheduler_factor': 0.8, 'scheduler_patience': 5, 'batch_size': 64, 'dropout': 0.05, 'hidden_dims': 128}. Best is trial 13 with value: 0.030649624484103494.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 33 Val Loss:\t 0.030683384076023733\n",
      "Epoch:\t 0 Val Loss:\t 0.03081687651992848\n",
      "Epoch:\t 1 Val Loss:\t 0.03075465769376292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:16:59,027] Trial 42 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 2 Val Loss:\t 0.030756676211092793\n",
      "Epoch:\t 0 Val Loss:\t 0.030826088293502592\n",
      "Epoch:\t 1 Val Loss:\t 0.030754114972440932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:17:10,155] Trial 43 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 2 Val Loss:\t 0.030745954520898813\n",
      "Epoch:\t 0 Val Loss:\t 0.030846644606689212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:17:17,501] Trial 44 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 1 Val Loss:\t 0.030791448025927606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:17:19,951] Trial 45 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03196214222278966\n",
      "Epoch:\t 0 Val Loss:\t 0.03086930639002212\n",
      "Epoch:\t 1 Val Loss:\t 0.03077356869081497\n",
      "Epoch:\t 2 Val Loss:\t 0.030714021209976915\n",
      "Epoch:\t 3 Val Loss:\t 0.03070663517518768\n",
      "Epoch:\t 4 Val Loss:\t 0.03072192353056781\n",
      "Epoch:\t 5 Val Loss:\t 0.030719863597390262\n",
      "Epoch:\t 6 Val Loss:\t 0.030688630788920875\n",
      "Epoch:\t 7 Val Loss:\t 0.030716715519463623\n",
      "Epoch:\t 8 Val Loss:\t 0.030699665076379404\n",
      "Epoch:\t 9 Val Loss:\t 0.03069854452728078\n",
      "Epoch:\t 10 Val Loss:\t 0.03069662433281935\n",
      "Epoch:\t 11 Val Loss:\t 0.030687627679076113\n",
      "Epoch:\t 12 Val Loss:\t 0.03068960099402627\n",
      "Epoch:\t 13 Val Loss:\t 0.03066386775813441\n",
      "Epoch:\t 14 Val Loss:\t 0.030681868677521193\n",
      "Epoch:\t 15 Val Loss:\t 0.030662587625008158\n",
      "Epoch:\t 16 Val Loss:\t 0.030679892215343025\n",
      "Epoch:\t 17 Val Loss:\t 0.03068131666537897\n",
      "Epoch:\t 18 Val Loss:\t 0.030669500506105857\n",
      "Epoch:\t 19 Val Loss:\t 0.03066983646933518\n",
      "Epoch:\t 20 Val Loss:\t 0.03066693780960182\n",
      "Epoch:\t 21 Val Loss:\t 0.03065510131657697\n",
      "Epoch:\t 22 Val Loss:\t 0.030673092025023704\n",
      "Epoch:\t 23 Val Loss:\t 0.030664911263629066\n",
      "Epoch:\t 24 Val Loss:\t 0.03065025779391014\n",
      "Epoch:\t 25 Val Loss:\t 0.0306789315027075\n",
      "Epoch:\t 26 Val Loss:\t 0.030668119010429623\n",
      "Epoch:\t 27 Val Loss:\t 0.030658920036379395\n",
      "Epoch:\t 28 Val Loss:\t 0.030675120580024307\n",
      "Epoch:\t 29 Val Loss:\t 0.03065618420797964\n",
      "Epoch:\t 30 Val Loss:\t 0.030670568932508028\n",
      "Epoch:\t 31 Val Loss:\t 0.030670441313681837\n",
      "Epoch:\t 32 Val Loss:\t 0.030663678970758498\n",
      "Epoch:\t 33 Val Loss:\t 0.030653516233935293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:19:23,130] Trial 46 finished with value: 0.03065025779391014 and parameters: {'lr': 0.001, 'weight_decay': 1e-05, 'scheduler_factor': 0.8, 'scheduler_patience': 1, 'batch_size': 64, 'dropout': 0.05, 'hidden_dims': 64}. Best is trial 13 with value: 0.030649624484103494.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 34 Val Loss:\t 0.03066390583854775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:19:47,131] Trial 47 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03161394993428076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:19:50,643] Trial 48 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03098358786735854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:20:15,443] Trial 49 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.04979784015257847\n",
      "Training model with best parameters on train+validation ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401917/401917 [04:06<00:00, 1629.15it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401917/401917 [01:13<00:00, 5484.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting test set predictions and saving results ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1223/1223 [00:01<00:00, 1100.14it/s]\n"
     ]
    }
   ],
   "source": [
    "train_different_featno(\n",
    "        adata_path=\"./data/feature_number/sciplex_hvg_1000.h5ad\",\n",
    "        run_name=\"mlp_hvg_1000\",\n",
    "        res_savename=\"./results/feature_number/mlp_hvg_1000_res.pkl\",\n",
    "        input_dim=1000,\n",
    "        output_dim=1000,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4498a7a8-65c6-4ea8-b465-b4eb2874adc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Datasets ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401917/401917 [03:10<00:00, 2108.27it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401917/401917 [01:13<00:00, 5447.67it/s]\n",
      "[I 2025-06-18 14:33:38,242] A new study created in RDB with name: mlp_hvg_2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing Hyperparameters with Optuna ...\n",
      "Epoch:\t 0 Val Loss:\t 0.030755623050907066\n",
      "Epoch:\t 1 Val Loss:\t 0.02638357961146732\n",
      "Epoch:\t 2 Val Loss:\t 0.024993684758726705\n",
      "Epoch:\t 3 Val Loss:\t 0.024452339134285194\n",
      "Epoch:\t 4 Val Loss:\t 0.024320955165507897\n",
      "Epoch:\t 5 Val Loss:\t 0.024248274548478534\n",
      "Epoch:\t 6 Val Loss:\t 0.02421444614700387\n",
      "Epoch:\t 7 Val Loss:\t 0.024176415878185108\n",
      "Epoch:\t 8 Val Loss:\t 0.024177045553898734\n",
      "Epoch:\t 9 Val Loss:\t 0.024158459126853635\n",
      "Epoch:\t 10 Val Loss:\t 0.02416513188118728\n",
      "Epoch:\t 11 Val Loss:\t 0.024175458493527403\n",
      "Epoch:\t 12 Val Loss:\t 0.024160296248083704\n",
      "Epoch:\t 13 Val Loss:\t 0.024158735773010392\n",
      "Epoch:\t 14 Val Loss:\t 0.02418236452398484\n",
      "Epoch:\t 15 Val Loss:\t 0.02416250476221977\n",
      "Epoch:\t 16 Val Loss:\t 0.02417181192764214\n",
      "Epoch:\t 17 Val Loss:\t 0.024167238894616812\n",
      "Epoch:\t 18 Val Loss:\t 0.02415857930483826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:34:33,995] Trial 0 finished with value: 0.024158459126853635 and parameters: {'lr': 1e-05, 'weight_decay': 0.001, 'scheduler_factor': 0.8, 'scheduler_patience': 5, 'batch_size': 128, 'dropout': 0.15, 'hidden_dims': 256}. Best is trial 0 with value: 0.024158459126853635.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 19 Val Loss:\t 0.024161054225067456\n",
      "Epoch:\t 0 Val Loss:\t 0.024568801884229854\n",
      "Epoch:\t 1 Val Loss:\t 0.024549613264524622\n",
      "Epoch:\t 2 Val Loss:\t 0.024619676319028016\n",
      "Epoch:\t 3 Val Loss:\t 0.024898694761536316\n",
      "Epoch:\t 4 Val Loss:\t 0.025350728513535984\n",
      "Epoch:\t 5 Val Loss:\t 0.025756050954233056\n",
      "Epoch:\t 6 Val Loss:\t 0.025792409387288197\n",
      "Epoch:\t 7 Val Loss:\t 0.02589136899503605\n",
      "Epoch:\t 8 Val Loss:\t 0.02588511461795475\n",
      "Epoch:\t 9 Val Loss:\t 0.025868305643119906\n",
      "Epoch:\t 10 Val Loss:\t 0.025960071756166915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:37:12,264] Trial 1 finished with value: 0.024549613264524622 and parameters: {'lr': 1e-05, 'weight_decay': 0.001, 'scheduler_factor': 0.8, 'scheduler_patience': 20, 'batch_size': 16, 'dropout': 0.05, 'hidden_dims': 64}. Best is trial 0 with value: 0.024158459126853635.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 11 Val Loss:\t 0.025852785616115922\n",
      "Epoch:\t 0 Val Loss:\t 0.04010801758754694\n",
      "Epoch:\t 1 Val Loss:\t 0.032598822899342156\n",
      "Epoch:\t 2 Val Loss:\t 0.03009607424334672\n",
      "Epoch:\t 3 Val Loss:\t 0.028791075132870943\n",
      "Epoch:\t 4 Val Loss:\t 0.02794608689641302\n",
      "Epoch:\t 5 Val Loss:\t 0.027327589251184732\n",
      "Epoch:\t 6 Val Loss:\t 0.02682813188811558\n",
      "Epoch:\t 7 Val Loss:\t 0.026393627652219746\n",
      "Epoch:\t 8 Val Loss:\t 0.026025136696536506\n",
      "Epoch:\t 9 Val Loss:\t 0.025727059608430004\n",
      "Epoch:\t 10 Val Loss:\t 0.025459626118501538\n",
      "Epoch:\t 11 Val Loss:\t 0.025250647853862607\n",
      "Epoch:\t 12 Val Loss:\t 0.025074781832041558\n",
      "Epoch:\t 13 Val Loss:\t 0.02493592949933933\n",
      "Epoch:\t 14 Val Loss:\t 0.02482218390411397\n",
      "Epoch:\t 15 Val Loss:\t 0.02472180322434508\n",
      "Epoch:\t 16 Val Loss:\t 0.024637755212847914\n",
      "Epoch:\t 17 Val Loss:\t 0.024576509377379478\n",
      "Epoch:\t 18 Val Loss:\t 0.024524907292992497\n",
      "Epoch:\t 19 Val Loss:\t 0.02448723301064241\n",
      "Epoch:\t 20 Val Loss:\t 0.0244505787044046\n",
      "Epoch:\t 21 Val Loss:\t 0.024429101377342905\n",
      "Epoch:\t 22 Val Loss:\t 0.024393635902129247\n",
      "Epoch:\t 23 Val Loss:\t 0.024385830028697153\n",
      "Epoch:\t 24 Val Loss:\t 0.024381813854816255\n",
      "Epoch:\t 25 Val Loss:\t 0.024362700385898113\n",
      "Epoch:\t 26 Val Loss:\t 0.024357848966652662\n",
      "Epoch:\t 27 Val Loss:\t 0.0243580210086909\n",
      "Epoch:\t 28 Val Loss:\t 0.024368773960474023\n",
      "Epoch:\t 29 Val Loss:\t 0.024364251063398144\n",
      "Epoch:\t 30 Val Loss:\t 0.02437182145722414\n",
      "Epoch:\t 31 Val Loss:\t 0.024367048660738702\n",
      "Epoch:\t 32 Val Loss:\t 0.024372817727215407\n",
      "Epoch:\t 33 Val Loss:\t 0.02438051015868137\n",
      "Epoch:\t 34 Val Loss:\t 0.024397366361791212\n",
      "Epoch:\t 35 Val Loss:\t 0.024403851625792096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:38:58,040] Trial 2 finished with value: 0.024357848966652662 and parameters: {'lr': 1e-06, 'weight_decay': 0.001, 'scheduler_factor': 0.5, 'scheduler_patience': 20, 'batch_size': 128, 'dropout': 0.15, 'hidden_dims': 1024}. Best is trial 0 with value: 0.024158459126853635.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 36 Val Loss:\t 0.024405451108780757\n",
      "Epoch:\t 0 Val Loss:\t 0.02433427773942247\n",
      "Epoch:\t 1 Val Loss:\t 0.024236915665970186\n",
      "Epoch:\t 2 Val Loss:\t 0.02419921995871618\n",
      "Epoch:\t 3 Val Loss:\t 0.02420215065894502\n",
      "Epoch:\t 4 Val Loss:\t 0.024194858755982134\n",
      "Epoch:\t 5 Val Loss:\t 0.024188003764393624\n",
      "Epoch:\t 6 Val Loss:\t 0.02420512032822181\n",
      "Epoch:\t 7 Val Loss:\t 0.024182090535759926\n",
      "Epoch:\t 8 Val Loss:\t 0.024205841306435546\n",
      "Epoch:\t 9 Val Loss:\t 0.02419180561449038\n",
      "Epoch:\t 10 Val Loss:\t 0.024188866127240524\n",
      "Epoch:\t 11 Val Loss:\t 0.024179104984667674\n",
      "Epoch:\t 12 Val Loss:\t 0.02419058079225868\n",
      "Epoch:\t 13 Val Loss:\t 0.024193344796210957\n",
      "Epoch:\t 14 Val Loss:\t 0.024189371833903642\n",
      "Epoch:\t 15 Val Loss:\t 0.02418934234551021\n",
      "Epoch:\t 16 Val Loss:\t 0.024191744843823762\n",
      "Epoch:\t 17 Val Loss:\t 0.024173728843633665\n",
      "Epoch:\t 18 Val Loss:\t 0.024185870524442023\n",
      "Epoch:\t 19 Val Loss:\t 0.024190279306846866\n",
      "Epoch:\t 20 Val Loss:\t 0.02418940525986314\n",
      "Epoch:\t 21 Val Loss:\t 0.024191726011076095\n",
      "Epoch:\t 22 Val Loss:\t 0.0241829092714511\n",
      "Epoch:\t 23 Val Loss:\t 0.024183257804349375\n",
      "Epoch:\t 24 Val Loss:\t 0.024194382020477117\n",
      "Epoch:\t 25 Val Loss:\t 0.024189489069925456\n",
      "Epoch:\t 26 Val Loss:\t 0.024193998524862346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:40:17,041] Trial 3 finished with value: 0.024173728843633665 and parameters: {'lr': 0.001, 'weight_decay': 1e-05, 'scheduler_factor': 0.3, 'scheduler_patience': 10, 'batch_size': 128, 'dropout': 0.2, 'hidden_dims': 64}. Best is trial 0 with value: 0.024158459126853635.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 27 Val Loss:\t 0.02417929211024488\n",
      "Epoch:\t 0 Val Loss:\t 0.03310353314890896\n",
      "Epoch:\t 1 Val Loss:\t 0.029134818005473403\n",
      "Epoch:\t 2 Val Loss:\t 0.0276366894677843\n",
      "Epoch:\t 3 Val Loss:\t 0.026805257577069683\n",
      "Epoch:\t 4 Val Loss:\t 0.026140051479387878\n",
      "Epoch:\t 5 Val Loss:\t 0.025637732221242323\n",
      "Epoch:\t 6 Val Loss:\t 0.02529276478004962\n",
      "Epoch:\t 7 Val Loss:\t 0.02501923293054534\n",
      "Epoch:\t 8 Val Loss:\t 0.024835685619064206\n",
      "Epoch:\t 9 Val Loss:\t 0.02469105066458225\n",
      "Epoch:\t 10 Val Loss:\t 0.024604585463869733\n",
      "Epoch:\t 11 Val Loss:\t 0.024558050178570948\n",
      "Epoch:\t 12 Val Loss:\t 0.024505327141275384\n",
      "Epoch:\t 13 Val Loss:\t 0.024434801942423142\n",
      "Epoch:\t 14 Val Loss:\t 0.024402284183641768\n",
      "Epoch:\t 15 Val Loss:\t 0.024377868657912267\n",
      "Epoch:\t 16 Val Loss:\t 0.02437736437997296\n",
      "Epoch:\t 17 Val Loss:\t 0.024365026200580044\n",
      "Epoch:\t 18 Val Loss:\t 0.02436894715077273\n",
      "Epoch:\t 19 Val Loss:\t 0.02437791191250588\n",
      "Epoch:\t 20 Val Loss:\t 0.024373611034982284\n",
      "Epoch:\t 21 Val Loss:\t 0.024384002287146943\n",
      "Epoch:\t 22 Val Loss:\t 0.02437292417300732\n",
      "Epoch:\t 23 Val Loss:\t 0.024383885611174293\n",
      "Epoch:\t 24 Val Loss:\t 0.024417118310522058\n",
      "Epoch:\t 25 Val Loss:\t 0.024390787881020077\n",
      "Epoch:\t 26 Val Loss:\t 0.024406922898989443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:42:11,133] Trial 4 finished with value: 0.024365026200580044 and parameters: {'lr': 1e-06, 'weight_decay': 0.001, 'scheduler_factor': 0.1, 'scheduler_patience': 10, 'batch_size': 64, 'dropout': 0.15, 'hidden_dims': 1024}. Best is trial 0 with value: 0.024158459126853635.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 27 Val Loss:\t 0.02439262771586131\n",
      "Epoch:\t 0 Val Loss:\t 0.024661402104941305\n",
      "Epoch:\t 1 Val Loss:\t 0.024504317502996965\n",
      "Epoch:\t 2 Val Loss:\t 0.02442490000180706\n",
      "Epoch:\t 3 Val Loss:\t 0.024371621935051643\n",
      "Epoch:\t 4 Val Loss:\t 0.02434453268149095\n",
      "Epoch:\t 5 Val Loss:\t 0.024296017287145994\n",
      "Epoch:\t 6 Val Loss:\t 0.02428341316421309\n",
      "Epoch:\t 7 Val Loss:\t 0.024250860583552258\n",
      "Epoch:\t 8 Val Loss:\t 0.024249576642094012\n",
      "Epoch:\t 9 Val Loss:\t 0.024231361445479976\n",
      "Epoch:\t 10 Val Loss:\t 0.02420842561475141\n",
      "Epoch:\t 11 Val Loss:\t 0.02421553286692064\n",
      "Epoch:\t 12 Val Loss:\t 0.02419674979832643\n",
      "Epoch:\t 13 Val Loss:\t 0.024210676299650707\n",
      "Epoch:\t 14 Val Loss:\t 0.024189682111502412\n",
      "Epoch:\t 15 Val Loss:\t 0.024181605930363607\n",
      "Epoch:\t 16 Val Loss:\t 0.024187093811531463\n",
      "Epoch:\t 17 Val Loss:\t 0.024183662524652146\n",
      "Epoch:\t 18 Val Loss:\t 0.024169653897474188\n",
      "Epoch:\t 19 Val Loss:\t 0.024174764370900357\n",
      "Epoch:\t 20 Val Loss:\t 0.024192364317157822\n",
      "Epoch:\t 21 Val Loss:\t 0.02416604558801006\n",
      "Epoch:\t 22 Val Loss:\t 0.02415791932560638\n",
      "Epoch:\t 23 Val Loss:\t 0.024166395690642998\n",
      "Epoch:\t 24 Val Loss:\t 0.024169333515416287\n",
      "Epoch:\t 25 Val Loss:\t 0.024168162579407435\n",
      "Epoch:\t 26 Val Loss:\t 0.02415697842702001\n",
      "Epoch:\t 27 Val Loss:\t 0.024165315822677644\n",
      "Epoch:\t 28 Val Loss:\t 0.024160738708171432\n",
      "Epoch:\t 29 Val Loss:\t 0.024162343959277403\n",
      "Epoch:\t 30 Val Loss:\t 0.02416189635071702\n",
      "Epoch:\t 31 Val Loss:\t 0.0241667429093488\n",
      "Epoch:\t 32 Val Loss:\t 0.024151146181957996\n",
      "Epoch:\t 33 Val Loss:\t 0.02416980046263797\n",
      "Epoch:\t 34 Val Loss:\t 0.024163809519089415\n",
      "Epoch:\t 35 Val Loss:\t 0.024157345495774654\n",
      "Epoch:\t 36 Val Loss:\t 0.024178924691491948\n",
      "Epoch:\t 37 Val Loss:\t 0.024173011795388076\n",
      "Epoch:\t 38 Val Loss:\t 0.024161187898300452\n",
      "Epoch:\t 39 Val Loss:\t 0.024157221301762996\n",
      "Epoch:\t 40 Val Loss:\t 0.024153982309665614\n",
      "Epoch:\t 41 Val Loss:\t 0.024167963415981535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:47:08,707] Trial 5 finished with value: 0.024151146181957996 and parameters: {'lr': 0.0001, 'weight_decay': 1e-06, 'scheduler_factor': 0.5, 'scheduler_patience': 20, 'batch_size': 32, 'dropout': 0.1, 'hidden_dims': 512}. Best is trial 5 with value: 0.024151146181957996.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 42 Val Loss:\t 0.0241632908022774\n",
      "Epoch:\t 0 Val Loss:\t 0.02547733734251027\n",
      "Epoch:\t 1 Val Loss:\t 0.02488928887142629\n",
      "Epoch:\t 2 Val Loss:\t 0.0246161946074564\n",
      "Epoch:\t 3 Val Loss:\t 0.024492347583030965\n",
      "Epoch:\t 4 Val Loss:\t 0.024413991527829523\n",
      "Epoch:\t 5 Val Loss:\t 0.024378192494249037\n",
      "Epoch:\t 6 Val Loss:\t 0.02431861065040639\n",
      "Epoch:\t 7 Val Loss:\t 0.024288677487678084\n",
      "Epoch:\t 8 Val Loss:\t 0.024298331793098205\n",
      "Epoch:\t 9 Val Loss:\t 0.024266453807233232\n",
      "Epoch:\t 10 Val Loss:\t 0.024234765242198274\n",
      "Epoch:\t 11 Val Loss:\t 0.02419298860900272\n",
      "Epoch:\t 12 Val Loss:\t 0.024193920841937663\n",
      "Epoch:\t 13 Val Loss:\t 0.02418910978523673\n",
      "Epoch:\t 14 Val Loss:\t 0.024175128201771395\n",
      "Epoch:\t 15 Val Loss:\t 0.024168352946830715\n",
      "Epoch:\t 16 Val Loss:\t 0.02415721101081448\n",
      "Epoch:\t 17 Val Loss:\t 0.024148772018467497\n",
      "Epoch:\t 18 Val Loss:\t 0.024134654108542722\n",
      "Epoch:\t 19 Val Loss:\t 0.024133186739453166\n",
      "Epoch:\t 20 Val Loss:\t 0.024159500117853908\n",
      "Epoch:\t 21 Val Loss:\t 0.02414304568429277\n",
      "Epoch:\t 22 Val Loss:\t 0.024140375765142334\n",
      "Epoch:\t 23 Val Loss:\t 0.024125472651465148\n",
      "Epoch:\t 24 Val Loss:\t 0.02412937528235161\n",
      "Epoch:\t 25 Val Loss:\t 0.0241338863513669\n",
      "Epoch:\t 26 Val Loss:\t 0.024132333150870162\n",
      "Epoch:\t 27 Val Loss:\t 0.024132644643833398\n",
      "Epoch:\t 28 Val Loss:\t 0.02412069691914071\n",
      "Epoch:\t 29 Val Loss:\t 0.024135604339061825\n",
      "Epoch:\t 30 Val Loss:\t 0.02413969894817213\n",
      "Epoch:\t 31 Val Loss:\t 0.0241250031990062\n",
      "Epoch:\t 32 Val Loss:\t 0.024133005368125016\n",
      "Epoch:\t 33 Val Loss:\t 0.02413417869681714\n",
      "Epoch:\t 34 Val Loss:\t 0.024120106364801\n",
      "Epoch:\t 35 Val Loss:\t 0.024120624934793285\n",
      "Epoch:\t 36 Val Loss:\t 0.024133131914200124\n",
      "Epoch:\t 37 Val Loss:\t 0.024125748855987162\n",
      "Epoch:\t 38 Val Loss:\t 0.024126827668913692\n",
      "Epoch:\t 39 Val Loss:\t 0.02412151439876035\n",
      "Epoch:\t 40 Val Loss:\t 0.02411457940552779\n",
      "Epoch:\t 41 Val Loss:\t 0.0241197427716765\n",
      "Epoch:\t 42 Val Loss:\t 0.02412193399102358\n",
      "Epoch:\t 43 Val Loss:\t 0.02412591641619083\n",
      "Epoch:\t 44 Val Loss:\t 0.024128108216491542\n",
      "Epoch:\t 45 Val Loss:\t 0.02412865162374889\n",
      "Epoch:\t 46 Val Loss:\t 0.024121966230955538\n",
      "Epoch:\t 47 Val Loss:\t 0.024124465152094217\n",
      "Epoch:\t 48 Val Loss:\t 0.02412249783946387\n",
      "Epoch:\t 49 Val Loss:\t 0.024118585859416383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:49:15,701] Trial 6 finished with value: 0.02411457940552779 and parameters: {'lr': 0.0001, 'weight_decay': 1e-05, 'scheduler_factor': 0.5, 'scheduler_patience': 10, 'batch_size': 256, 'dropout': 0.1, 'hidden_dims': 1024}. Best is trial 6 with value: 0.02411457940552779.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 50 Val Loss:\t 0.02411526837461056\n",
      "Epoch:\t 0 Val Loss:\t 0.024270618896079767\n",
      "Epoch:\t 1 Val Loss:\t 0.024254245463362367\n",
      "Epoch:\t 2 Val Loss:\t 0.024247304376112486\n",
      "Epoch:\t 3 Val Loss:\t 0.024223347264654565\n",
      "Epoch:\t 4 Val Loss:\t 0.024226779266340988\n",
      "Epoch:\t 5 Val Loss:\t 0.024225840611863628\n",
      "Epoch:\t 6 Val Loss:\t 0.024222381443585406\n",
      "Epoch:\t 7 Val Loss:\t 0.024218608969137703\n",
      "Epoch:\t 8 Val Loss:\t 0.024224396119727577\n",
      "Epoch:\t 9 Val Loss:\t 0.024222889498803198\n",
      "Epoch:\t 10 Val Loss:\t 0.024238543775835023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:53:15,554] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 11 Val Loss:\t 0.02423370099081422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:53:18,579] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03747707433149482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:53:24,908] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.031012341718307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:53:27,243] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.02666747020228116\n",
      "Epoch:\t 0 Val Loss:\t 0.02475416033952413\n",
      "Epoch:\t 1 Val Loss:\t 0.024494631149860207\n",
      "Epoch:\t 2 Val Loss:\t 0.024458446807950316\n",
      "Epoch:\t 3 Val Loss:\t 0.02438898162024174\n",
      "Epoch:\t 4 Val Loss:\t 0.02431046731381832\n",
      "Epoch:\t 5 Val Loss:\t 0.02431681841828362\n",
      "Epoch:\t 6 Val Loss:\t 0.024269824818836782\n",
      "Epoch:\t 7 Val Loss:\t 0.024276921585321666\n",
      "Epoch:\t 8 Val Loss:\t 0.024256101489544872\n",
      "Epoch:\t 9 Val Loss:\t 0.024217005738454735\n",
      "Epoch:\t 10 Val Loss:\t 0.024207980892731098\n",
      "Epoch:\t 11 Val Loss:\t 0.024207236184803898\n",
      "Epoch:\t 12 Val Loss:\t 0.024189049453065846\n",
      "Epoch:\t 13 Val Loss:\t 0.024204068982932633\n",
      "Epoch:\t 14 Val Loss:\t 0.024193916015162735\n",
      "Epoch:\t 15 Val Loss:\t 0.024177925406259022\n",
      "Epoch:\t 16 Val Loss:\t 0.024182608107735735\n",
      "Epoch:\t 17 Val Loss:\t 0.0241928684575584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:55:35,898] Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 18 Val Loss:\t 0.024191920805670217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:55:38,275] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.025878044935332616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:55:40,601] Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.026786288030900756\n",
      "Epoch:\t 0 Val Loss:\t 0.024902809369480444\n",
      "Epoch:\t 1 Val Loss:\t 0.02445813445318378\n",
      "Epoch:\t 2 Val Loss:\t 0.024451924526022528\n",
      "Epoch:\t 3 Val Loss:\t 0.024442200484370184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:56:20,696] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 4 Val Loss:\t 0.02446292410147393\n",
      "Epoch:\t 0 Val Loss:\t 0.02466079008368941\n",
      "Epoch:\t 1 Val Loss:\t 0.024359602600622865\n",
      "Epoch:\t 2 Val Loss:\t 0.024308261514582343\n",
      "Epoch:\t 3 Val Loss:\t 0.024262285916061523\n",
      "Epoch:\t 4 Val Loss:\t 0.024211294024453798\n",
      "Epoch:\t 5 Val Loss:\t 0.024182976759020196\n",
      "Epoch:\t 6 Val Loss:\t 0.024163199331739854\n",
      "Epoch:\t 7 Val Loss:\t 0.024150270063492806\n",
      "Epoch:\t 8 Val Loss:\t 0.024150624641224014\n",
      "Epoch:\t 9 Val Loss:\t 0.024144561220417523\n",
      "Epoch:\t 10 Val Loss:\t 0.02414040631333063\n",
      "Epoch:\t 11 Val Loss:\t 0.024141260792457205\n",
      "Epoch:\t 12 Val Loss:\t 0.02414090095391107\n",
      "Epoch:\t 13 Val Loss:\t 0.024138485352600585\n",
      "Epoch:\t 14 Val Loss:\t 0.0241493670883758\n",
      "Epoch:\t 15 Val Loss:\t 0.024138538386454654\n",
      "Epoch:\t 16 Val Loss:\t 0.024146806886352436\n",
      "Epoch:\t 17 Val Loss:\t 0.024134747271740448\n",
      "Epoch:\t 18 Val Loss:\t 0.024144212303813115\n",
      "Epoch:\t 19 Val Loss:\t 0.02413265971405657\n",
      "Epoch:\t 20 Val Loss:\t 0.024135531802342812\n",
      "Epoch:\t 21 Val Loss:\t 0.024147560642233064\n",
      "Epoch:\t 22 Val Loss:\t 0.024132658033642944\n",
      "Epoch:\t 23 Val Loss:\t 0.024157324663954156\n",
      "Epoch:\t 24 Val Loss:\t 0.024147829726493732\n",
      "Epoch:\t 25 Val Loss:\t 0.024142096176110177\n",
      "Epoch:\t 26 Val Loss:\t 0.024142149032213827\n",
      "Epoch:\t 27 Val Loss:\t 0.024137750093219466\n",
      "Epoch:\t 28 Val Loss:\t 0.024138443352715817\n",
      "Epoch:\t 29 Val Loss:\t 0.024128708479076073\n",
      "Epoch:\t 30 Val Loss:\t 0.024134575990540273\n",
      "Epoch:\t 31 Val Loss:\t 0.024133968473962524\n",
      "Epoch:\t 32 Val Loss:\t 0.024134684749897613\n",
      "Epoch:\t 33 Val Loss:\t 0.024131645192336158\n",
      "Epoch:\t 34 Val Loss:\t 0.024128895851917142\n",
      "Epoch:\t 35 Val Loss:\t 0.024122347300924486\n",
      "Epoch:\t 36 Val Loss:\t 0.024142663840745197\n",
      "Epoch:\t 37 Val Loss:\t 0.02412416472427589\n",
      "Epoch:\t 38 Val Loss:\t 0.02412737427994836\n",
      "Epoch:\t 39 Val Loss:\t 0.024126233576342117\n",
      "Epoch:\t 40 Val Loss:\t 0.024131709500645387\n",
      "Epoch:\t 41 Val Loss:\t 0.024123520865952767\n",
      "Epoch:\t 42 Val Loss:\t 0.024128420562233174\n",
      "Epoch:\t 43 Val Loss:\t 0.024122464003783754\n",
      "Epoch:\t 44 Val Loss:\t 0.024138021415044234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 14:59:31,519] Trial 15 finished with value: 0.024122347300924486 and parameters: {'lr': 0.0001, 'weight_decay': 1e-05, 'scheduler_factor': 0.5, 'scheduler_patience': 10, 'batch_size': 64, 'dropout': 0.2, 'hidden_dims': 512}. Best is trial 6 with value: 0.02411457940552779.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 45 Val Loss:\t 0.024132353296233065\n",
      "Epoch:\t 0 Val Loss:\t 0.024638005715302686\n",
      "Epoch:\t 1 Val Loss:\t 0.024392630093833304\n",
      "Epoch:\t 2 Val Loss:\t 0.024319696384269233\n",
      "Epoch:\t 3 Val Loss:\t 0.024225894651512384\n",
      "Epoch:\t 4 Val Loss:\t 0.024190845209940873\n",
      "Epoch:\t 5 Val Loss:\t 0.024158772778695072\n",
      "Epoch:\t 6 Val Loss:\t 0.02415507380442086\n",
      "Epoch:\t 7 Val Loss:\t 0.024152442187058896\n",
      "Epoch:\t 8 Val Loss:\t 0.024145332757314876\n",
      "Epoch:\t 9 Val Loss:\t 0.024143407978685073\n",
      "Epoch:\t 10 Val Loss:\t 0.02414174524749052\n",
      "Epoch:\t 11 Val Loss:\t 0.02414119863657112\n",
      "Epoch:\t 12 Val Loss:\t 0.024150251000880623\n",
      "Epoch:\t 13 Val Loss:\t 0.024133649604647468\n",
      "Epoch:\t 14 Val Loss:\t 0.024139424718755097\n",
      "Epoch:\t 15 Val Loss:\t 0.024131601113219592\n",
      "Epoch:\t 16 Val Loss:\t 0.02413161600691228\n",
      "Epoch:\t 17 Val Loss:\t 0.024153137809590233\n",
      "Epoch:\t 18 Val Loss:\t 0.02413608218635094\n",
      "Epoch:\t 19 Val Loss:\t 0.024139443298901858\n",
      "Epoch:\t 20 Val Loss:\t 0.024138670472940542\n",
      "Epoch:\t 21 Val Loss:\t 0.024134831347688734\n",
      "Epoch:\t 22 Val Loss:\t 0.024135760042843287\n",
      "Epoch:\t 23 Val Loss:\t 0.024144013701327915\n",
      "Epoch:\t 24 Val Loss:\t 0.02414167429071813\n",
      "Epoch:\t 25 Val Loss:\t 0.024124023202080774\n",
      "Epoch:\t 26 Val Loss:\t 0.02413052985774773\n",
      "Epoch:\t 27 Val Loss:\t 0.02413036198218584\n",
      "Epoch:\t 28 Val Loss:\t 0.02413043903624572\n",
      "Epoch:\t 29 Val Loss:\t 0.024124947181621264\n",
      "Epoch:\t 30 Val Loss:\t 0.024121410096155326\n",
      "Epoch:\t 31 Val Loss:\t 0.024126133105531633\n",
      "Epoch:\t 32 Val Loss:\t 0.024127149071660917\n",
      "Epoch:\t 33 Val Loss:\t 0.024126648958160003\n",
      "Epoch:\t 34 Val Loss:\t 0.02412286624551393\n",
      "Epoch:\t 35 Val Loss:\t 0.024123243402029478\n",
      "Epoch:\t 36 Val Loss:\t 0.024125250785312084\n",
      "Epoch:\t 37 Val Loss:\t 0.024124473853166715\n",
      "Epoch:\t 38 Val Loss:\t 0.024127330185894788\n",
      "Epoch:\t 39 Val Loss:\t 0.024119471792062953\n",
      "Epoch:\t 40 Val Loss:\t 0.024126159768094516\n",
      "Epoch:\t 41 Val Loss:\t 0.024120714257037344\n",
      "Epoch:\t 42 Val Loss:\t 0.024123590236414694\n",
      "Epoch:\t 43 Val Loss:\t 0.024124629266781144\n",
      "Epoch:\t 44 Val Loss:\t 0.024130070117491194\n",
      "Epoch:\t 45 Val Loss:\t 0.02412392383511533\n",
      "Epoch:\t 46 Val Loss:\t 0.024125617908638004\n",
      "Epoch:\t 47 Val Loss:\t 0.024123184844469105\n",
      "Epoch:\t 48 Val Loss:\t 0.02412168730017464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:03:09,735] Trial 16 finished with value: 0.024119471792062953 and parameters: {'lr': 0.0001, 'weight_decay': 1e-05, 'scheduler_factor': 0.5, 'scheduler_patience': 10, 'batch_size': 64, 'dropout': 0.2, 'hidden_dims': 1024}. Best is trial 6 with value: 0.02411457940552779.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 49 Val Loss:\t 0.024125902103178005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:03:13,864] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.02473011161495708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:03:17,958] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.024823721114369805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:03:20,378] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.028270427131624084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:03:24,972] Trial 20 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.024670383872788432\n",
      "Epoch:\t 0 Val Loss:\t 0.02463708175816771\n",
      "Epoch:\t 1 Val Loss:\t 0.024375241880141552\n",
      "Epoch:\t 2 Val Loss:\t 0.02428739754828149\n",
      "Epoch:\t 3 Val Loss:\t 0.024233054970155838\n",
      "Epoch:\t 4 Val Loss:\t 0.024196761856699524\n",
      "Epoch:\t 5 Val Loss:\t 0.02417539472974771\n",
      "Epoch:\t 6 Val Loss:\t 0.024163165675668882\n",
      "Epoch:\t 7 Val Loss:\t 0.024153969983279754\n",
      "Epoch:\t 8 Val Loss:\t 0.02414533351312758\n",
      "Epoch:\t 9 Val Loss:\t 0.024148815240540692\n",
      "Epoch:\t 10 Val Loss:\t 0.024138425235616368\n",
      "Epoch:\t 11 Val Loss:\t 0.024138680040095457\n",
      "Epoch:\t 12 Val Loss:\t 0.024144537158388085\n",
      "Epoch:\t 13 Val Loss:\t 0.024135320637832188\n",
      "Epoch:\t 14 Val Loss:\t 0.02414604494200292\n",
      "Epoch:\t 15 Val Loss:\t 0.024145517883629633\n",
      "Epoch:\t 16 Val Loss:\t 0.0241391253287948\n",
      "Epoch:\t 17 Val Loss:\t 0.024137799636294293\n",
      "Epoch:\t 18 Val Loss:\t 0.024136140227090767\n",
      "Epoch:\t 19 Val Loss:\t 0.02413619854565898\n",
      "Epoch:\t 20 Val Loss:\t 0.02413857785750363\n",
      "Epoch:\t 21 Val Loss:\t 0.02413697687590849\n",
      "Epoch:\t 22 Val Loss:\t 0.024141021228209436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:05:04,443] Trial 21 finished with value: 0.024135320637832188 and parameters: {'lr': 0.0001, 'weight_decay': 1e-05, 'scheduler_factor': 0.5, 'scheduler_patience': 10, 'batch_size': 64, 'dropout': 0.2, 'hidden_dims': 512}. Best is trial 6 with value: 0.02411457940552779.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 23 Val Loss:\t 0.024153724638409105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:05:08,529] Trial 22 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.02484202610945692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:05:12,521] Trial 23 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.02544354677272015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:05:14,992] Trial 24 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.025188925732945323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:05:19,231] Trial 25 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.024664613266670427\n",
      "Epoch:\t 0 Val Loss:\t 0.024470905711576924\n",
      "Epoch:\t 1 Val Loss:\t 0.0242445279820407\n",
      "Epoch:\t 2 Val Loss:\t 0.02420778498180439\n",
      "Epoch:\t 3 Val Loss:\t 0.02418575092326858\n",
      "Epoch:\t 4 Val Loss:\t 0.024180156447103817\n",
      "Epoch:\t 5 Val Loss:\t 0.02418152512070012\n",
      "Epoch:\t 6 Val Loss:\t 0.024180447174065627\n",
      "Epoch:\t 7 Val Loss:\t 0.024183320369705052\n",
      "Epoch:\t 8 Val Loss:\t 0.02418225699170985\n",
      "Epoch:\t 9 Val Loss:\t 0.024182627203349384\n",
      "Epoch:\t 10 Val Loss:\t 0.024181027032182657\n",
      "Epoch:\t 11 Val Loss:\t 0.02417994096955056\n",
      "Epoch:\t 12 Val Loss:\t 0.02418455018517674\n",
      "Epoch:\t 13 Val Loss:\t 0.02417490656719588\n",
      "Epoch:\t 14 Val Loss:\t 0.024192472327925284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:10:28,017] Trial 26 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 15 Val Loss:\t 0.024177506800044563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:10:30,562] Trial 27 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.028354229046169584\n",
      "Epoch:\t 0 Val Loss:\t 0.024538058753229182\n",
      "Epoch:\t 1 Val Loss:\t 0.024251854141282385\n",
      "Epoch:\t 2 Val Loss:\t 0.02421971234256206\n",
      "Epoch:\t 3 Val Loss:\t 0.024225386134449634\n",
      "Epoch:\t 4 Val Loss:\t 0.024226505472156747\n",
      "Epoch:\t 5 Val Loss:\t 0.024224460281808087\n",
      "Epoch:\t 6 Val Loss:\t 0.02419848168312117\n",
      "Epoch:\t 7 Val Loss:\t 0.024204704549041098\n",
      "Epoch:\t 8 Val Loss:\t 0.02419290632164851\n",
      "Epoch:\t 9 Val Loss:\t 0.024208224306081712\n",
      "Epoch:\t 10 Val Loss:\t 0.02420508144415897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:11:20,236] Trial 28 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 11 Val Loss:\t 0.024194389333725932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:11:24,117] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.02711599234285456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:11:26,586] Trial 30 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.025007993324249505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:11:30,711] Trial 31 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.0246691732550131\n",
      "Epoch:\t 0 Val Loss:\t 0.024624922427064242\n",
      "Epoch:\t 1 Val Loss:\t 0.024371439912195862\n",
      "Epoch:\t 2 Val Loss:\t 0.0243070890504117\n",
      "Epoch:\t 3 Val Loss:\t 0.024239110044161127\n",
      "Epoch:\t 4 Val Loss:\t 0.02421575006614376\n",
      "Epoch:\t 5 Val Loss:\t 0.024175572913340215\n",
      "Epoch:\t 6 Val Loss:\t 0.024167350264088384\n",
      "Epoch:\t 7 Val Loss:\t 0.024146363298978533\n",
      "Epoch:\t 8 Val Loss:\t 0.024142087935361753\n",
      "Epoch:\t 9 Val Loss:\t 0.02413535736196502\n",
      "Epoch:\t 10 Val Loss:\t 0.024131231858382344\n",
      "Epoch:\t 11 Val Loss:\t 0.024136542996097396\n",
      "Epoch:\t 12 Val Loss:\t 0.0241297097442001\n",
      "Epoch:\t 13 Val Loss:\t 0.024145130293612586\n",
      "Epoch:\t 14 Val Loss:\t 0.02412514425007553\n",
      "Epoch:\t 15 Val Loss:\t 0.024137931392672257\n",
      "Epoch:\t 16 Val Loss:\t 0.024137518729390194\n",
      "Epoch:\t 17 Val Loss:\t 0.024142132586565796\n",
      "Epoch:\t 18 Val Loss:\t 0.024135043135072674\n",
      "Epoch:\t 19 Val Loss:\t 0.024130965939274097\n",
      "Epoch:\t 20 Val Loss:\t 0.024134222651087195\n",
      "Epoch:\t 21 Val Loss:\t 0.024136662731169697\n",
      "Epoch:\t 22 Val Loss:\t 0.02413758220869537\n",
      "Epoch:\t 23 Val Loss:\t 0.024128841419958934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:13:13,737] Trial 32 finished with value: 0.02412514425007553 and parameters: {'lr': 0.0001, 'weight_decay': 1e-05, 'scheduler_factor': 0.5, 'scheduler_patience': 10, 'batch_size': 64, 'dropout': 0.2, 'hidden_dims': 512}. Best is trial 6 with value: 0.02411457940552779.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 24 Val Loss:\t 0.024138560313985362\n",
      "Epoch:\t 0 Val Loss:\t 0.024614631408211605\n",
      "Epoch:\t 1 Val Loss:\t 0.024332889139879296\n",
      "Epoch:\t 2 Val Loss:\t 0.02430319592936238\n",
      "Epoch:\t 3 Val Loss:\t 0.0242276587183703\n",
      "Epoch:\t 4 Val Loss:\t 0.024198016266800827\n",
      "Epoch:\t 5 Val Loss:\t 0.024171456513865146\n",
      "Epoch:\t 6 Val Loss:\t 0.024162943184423562\n",
      "Epoch:\t 7 Val Loss:\t 0.02414568071645694\n",
      "Epoch:\t 8 Val Loss:\t 0.024151117674582178\n",
      "Epoch:\t 9 Val Loss:\t 0.02414223512615217\n",
      "Epoch:\t 10 Val Loss:\t 0.024136483982958215\n",
      "Epoch:\t 11 Val Loss:\t 0.024134443951852817\n",
      "Epoch:\t 12 Val Loss:\t 0.02414047001370355\n",
      "Epoch:\t 13 Val Loss:\t 0.024142285891074415\n",
      "Epoch:\t 14 Val Loss:\t 0.024142747250502836\n",
      "Epoch:\t 15 Val Loss:\t 0.024144455288636176\n",
      "Epoch:\t 16 Val Loss:\t 0.02413955894571452\n",
      "Epoch:\t 17 Val Loss:\t 0.024140039706825253\n",
      "Epoch:\t 18 Val Loss:\t 0.02414631319725953\n",
      "Epoch:\t 19 Val Loss:\t 0.02414236333050915\n",
      "Epoch:\t 20 Val Loss:\t 0.02414273936376155\n",
      "Epoch:\t 21 Val Loss:\t 0.024131333098448844\n",
      "Epoch:\t 22 Val Loss:\t 0.024139529404789806\n",
      "Epoch:\t 23 Val Loss:\t 0.02413643747209642\n",
      "Epoch:\t 24 Val Loss:\t 0.024142640350803244\n",
      "Epoch:\t 25 Val Loss:\t 0.02413856912532757\n",
      "Epoch:\t 26 Val Loss:\t 0.024137967737405036\n",
      "Epoch:\t 27 Val Loss:\t 0.024148656020976107\n",
      "Epoch:\t 28 Val Loss:\t 0.024133379621925646\n",
      "Epoch:\t 29 Val Loss:\t 0.02413652247264563\n",
      "Epoch:\t 30 Val Loss:\t 0.024142098604868007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:15:24,550] Trial 33 finished with value: 0.024131333098448844 and parameters: {'lr': 0.0001, 'weight_decay': 1e-05, 'scheduler_factor': 0.5, 'scheduler_patience': 10, 'batch_size': 64, 'dropout': 0.2, 'hidden_dims': 512}. Best is trial 6 with value: 0.02411457940552779.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 31 Val Loss:\t 0.02414190243412804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:15:42,351] Trial 34 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.026040905846969158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:15:45,210] Trial 35 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.04999453055389812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:15:49,734] Trial 36 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.027012830582218067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:15:52,628] Trial 37 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.02469017482504703\n",
      "Epoch:\t 0 Val Loss:\t 0.024502993037785255\n",
      "Epoch:\t 1 Val Loss:\t 0.024309221590901244\n",
      "Epoch:\t 2 Val Loss:\t 0.02423437953640579\n",
      "Epoch:\t 3 Val Loss:\t 0.02423520671665286\n",
      "Epoch:\t 4 Val Loss:\t 0.024233744078657107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:16:17,503] Trial 38 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 5 Val Loss:\t 0.024221365095833922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:16:37,791] Trial 39 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.028436800990827668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:16:42,050] Trial 40 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.024654437232920906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:16:46,245] Trial 41 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.024679813199432354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:16:50,194] Trial 42 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.02468758873617592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:16:54,363] Trial 43 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.024654336500712748\n",
      "Epoch:\t 0 Val Loss:\t 0.024512110534077418\n",
      "Epoch:\t 1 Val Loss:\t 0.024344278583844345\n",
      "Epoch:\t 2 Val Loss:\t 0.024242442775749135\n",
      "Epoch:\t 3 Val Loss:\t 0.024187685625407403\n",
      "Epoch:\t 4 Val Loss:\t 0.024153485148398574\n",
      "Epoch:\t 5 Val Loss:\t 0.024158547505482523\n",
      "Epoch:\t 6 Val Loss:\t 0.024154963155831388\n",
      "Epoch:\t 7 Val Loss:\t 0.024150196559174743\n",
      "Epoch:\t 8 Val Loss:\t 0.024145734518064645\n",
      "Epoch:\t 9 Val Loss:\t 0.024152725557227413\n",
      "Epoch:\t 10 Val Loss:\t 0.024139728192949222\n",
      "Epoch:\t 11 Val Loss:\t 0.02414220580177938\n",
      "Epoch:\t 12 Val Loss:\t 0.02415193696814274\n",
      "Epoch:\t 13 Val Loss:\t 0.02414811223163036\n",
      "Epoch:\t 14 Val Loss:\t 0.02414800114071142\n",
      "Epoch:\t 15 Val Loss:\t 0.024151861451506496\n",
      "Epoch:\t 16 Val Loss:\t 0.024145744878328396\n",
      "Epoch:\t 17 Val Loss:\t 0.024151066755633315\n",
      "Epoch:\t 18 Val Loss:\t 0.024150758316527625\n",
      "Epoch:\t 19 Val Loss:\t 0.02414296355419503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:19:08,925] Trial 44 finished with value: 0.024139728192949222 and parameters: {'lr': 0.0001, 'weight_decay': 1e-05, 'scheduler_factor': 0.5, 'scheduler_patience': 10, 'batch_size': 32, 'dropout': 0.2, 'hidden_dims': 512}. Best is trial 6 with value: 0.02411457940552779.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 20 Val Loss:\t 0.024149367255429346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:19:11,941] Trial 45 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.025170181768783405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:19:14,424] Trial 46 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.025550030615072925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:19:18,887] Trial 47 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.032623515659293466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:19:23,357] Trial 48 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.024761363481557552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:19:29,601] Trial 49 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.024728637077436895\n",
      "Training model with best parameters on train+validation ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401917/401917 [04:05<00:00, 1634.62it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401917/401917 [01:14<00:00, 5426.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting test set predictions and saving results ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 305/305 [00:01<00:00, 254.63it/s]\n"
     ]
    }
   ],
   "source": [
    "train_different_featno(\n",
    "        adata_path=\"./data/feature_number/sciplex_hvg_2000.h5ad\",\n",
    "        run_name=\"mlp_hvg_2000\",\n",
    "        res_savename=\"./results/feature_number/mlp_hvg_2000_res.pkl\",\n",
    "        input_dim=2000,\n",
    "        output_dim=2000,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09bad6fe-d888-4ffe-ba67-ffad0747fb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Datasets ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401917/401917 [03:14<00:00, 2069.95it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401917/401917 [01:15<00:00, 5341.00it/s]\n",
      "[I 2025-06-18 15:31:03,256] A new study created in RDB with name: mlp_hvg_3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing Hyperparameters with Optuna ...\n",
      "Epoch:\t 0 Val Loss:\t 0.025646917357514606\n",
      "Epoch:\t 1 Val Loss:\t 0.026184173877893634\n",
      "Epoch:\t 2 Val Loss:\t 0.025989308678223653\n",
      "Epoch:\t 3 Val Loss:\t 0.026145489739902904\n",
      "Epoch:\t 4 Val Loss:\t 0.026082264382039373\n",
      "Epoch:\t 5 Val Loss:\t 0.02608875860646965\n",
      "Epoch:\t 6 Val Loss:\t 0.026082637915641884\n",
      "Epoch:\t 7 Val Loss:\t 0.026029499558609333\n",
      "Epoch:\t 8 Val Loss:\t 0.026179664889365482\n",
      "Epoch:\t 9 Val Loss:\t 0.026181519707219367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:31:42,859] Trial 0 finished with value: 0.025646917357514606 and parameters: {'lr': 0.001, 'weight_decay': 0.001, 'scheduler_factor': 0.1, 'scheduler_patience': 10, 'batch_size': 128, 'dropout': 0.1, 'hidden_dims': 64}. Best is trial 0 with value: 0.025646917357514606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 10 Val Loss:\t 0.026314768258536035\n",
      "Epoch:\t 0 Val Loss:\t 0.03629389828088966\n",
      "Epoch:\t 1 Val Loss:\t 0.029759202703498185\n",
      "Epoch:\t 2 Val Loss:\t 0.027903734421854617\n",
      "Epoch:\t 3 Val Loss:\t 0.027107614221296893\n",
      "Epoch:\t 4 Val Loss:\t 0.02675149363983674\n",
      "Epoch:\t 5 Val Loss:\t 0.026530141843381035\n",
      "Epoch:\t 6 Val Loss:\t 0.02629367907163223\n",
      "Epoch:\t 7 Val Loss:\t 0.024768809311786648\n",
      "Epoch:\t 8 Val Loss:\t 0.024338848230060658\n",
      "Epoch:\t 9 Val Loss:\t 0.024151476621148672\n",
      "Epoch:\t 10 Val Loss:\t 0.024023176227783084\n",
      "Epoch:\t 11 Val Loss:\t 0.023940839460329228\n",
      "Epoch:\t 12 Val Loss:\t 0.023881704783085076\n",
      "Epoch:\t 13 Val Loss:\t 0.02382318044853939\n",
      "Epoch:\t 14 Val Loss:\t 0.023778495824988633\n",
      "Epoch:\t 15 Val Loss:\t 0.023743157679292932\n",
      "Epoch:\t 16 Val Loss:\t 0.023707002814607605\n",
      "Epoch:\t 17 Val Loss:\t 0.023672092352601492\n",
      "Epoch:\t 18 Val Loss:\t 0.023644195504223035\n",
      "Epoch:\t 19 Val Loss:\t 0.023629177972626456\n",
      "Epoch:\t 20 Val Loss:\t 0.023610033118839815\n",
      "Epoch:\t 21 Val Loss:\t 0.023590689483083713\n",
      "Epoch:\t 22 Val Loss:\t 0.023564119011738677\n",
      "Epoch:\t 23 Val Loss:\t 0.023563407319582928\n",
      "Epoch:\t 24 Val Loss:\t 0.023531606576594127\n",
      "Epoch:\t 25 Val Loss:\t 0.02353514039775183\n",
      "Epoch:\t 26 Val Loss:\t 0.023511901701474113\n",
      "Epoch:\t 27 Val Loss:\t 0.02350688367554996\n",
      "Epoch:\t 28 Val Loss:\t 0.023480757442078407\n",
      "Epoch:\t 29 Val Loss:\t 0.023462379069765282\n",
      "Epoch:\t 30 Val Loss:\t 0.023439286899576233\n",
      "Epoch:\t 31 Val Loss:\t 0.023439912287176998\n",
      "Epoch:\t 32 Val Loss:\t 0.023419408049805756\n",
      "Epoch:\t 33 Val Loss:\t 0.023423588819729935\n",
      "Epoch:\t 34 Val Loss:\t 0.02341542456454786\n",
      "Epoch:\t 35 Val Loss:\t 0.023397586383284864\n",
      "Epoch:\t 36 Val Loss:\t 0.023383493196830106\n",
      "Epoch:\t 37 Val Loss:\t 0.023366352016184106\n",
      "Epoch:\t 38 Val Loss:\t 0.023355158926302213\n",
      "Epoch:\t 39 Val Loss:\t 0.023350603650907995\n",
      "Epoch:\t 40 Val Loss:\t 0.023339491343526978\n",
      "Epoch:\t 41 Val Loss:\t 0.02333966122754517\n",
      "Epoch:\t 42 Val Loss:\t 0.023329659967033425\n",
      "Epoch:\t 43 Val Loss:\t 0.023326645266875577\n",
      "Epoch:\t 44 Val Loss:\t 0.023324781897031608\n",
      "Epoch:\t 45 Val Loss:\t 0.02331659088803641\n",
      "Epoch:\t 46 Val Loss:\t 0.023309122004405478\n",
      "Epoch:\t 47 Val Loss:\t 0.02330384360344847\n",
      "Epoch:\t 48 Val Loss:\t 0.02331345788894934\n",
      "Epoch:\t 49 Val Loss:\t 0.023291624741107703\n",
      "Epoch:\t 50 Val Loss:\t 0.023288729250239407\n",
      "Epoch:\t 51 Val Loss:\t 0.023288789310064346\n",
      "Epoch:\t 52 Val Loss:\t 0.023282251958630477\n",
      "Epoch:\t 53 Val Loss:\t 0.023277489755937523\n",
      "Epoch:\t 54 Val Loss:\t 0.023277099331140135\n",
      "Epoch:\t 55 Val Loss:\t 0.02327230514006216\n",
      "Epoch:\t 56 Val Loss:\t 0.023284977056397503\n",
      "Epoch:\t 57 Val Loss:\t 0.02327113430288252\n",
      "Epoch:\t 58 Val Loss:\t 0.02325932294657376\n",
      "Epoch:\t 59 Val Loss:\t 0.023258643907605642\n",
      "Epoch:\t 60 Val Loss:\t 0.02325777071632948\n",
      "Epoch:\t 61 Val Loss:\t 0.0232683249249144\n",
      "Epoch:\t 62 Val Loss:\t 0.023259647627783358\n",
      "Epoch:\t 63 Val Loss:\t 0.02326009524956202\n",
      "Epoch:\t 64 Val Loss:\t 0.023247699980950432\n",
      "Epoch:\t 65 Val Loss:\t 0.02325219548400192\n",
      "Epoch:\t 66 Val Loss:\t 0.023249763384509316\n",
      "Epoch:\t 67 Val Loss:\t 0.02325482504184798\n",
      "Epoch:\t 68 Val Loss:\t 0.02324844022967233\n",
      "Epoch:\t 69 Val Loss:\t 0.02324864098209277\n",
      "Epoch:\t 70 Val Loss:\t 0.02323617919129574\n",
      "Epoch:\t 71 Val Loss:\t 0.023232875864988737\n",
      "Epoch:\t 72 Val Loss:\t 0.023241004190883836\n",
      "Epoch:\t 73 Val Loss:\t 0.023239220106237572\n",
      "Epoch:\t 74 Val Loss:\t 0.023237752377795254\n",
      "Epoch:\t 75 Val Loss:\t 0.023223721904386662\n",
      "Epoch:\t 76 Val Loss:\t 0.023231727355594037\n",
      "Epoch:\t 77 Val Loss:\t 0.023231585974239077\n",
      "Epoch:\t 78 Val Loss:\t 0.023225967164399924\n",
      "Epoch:\t 79 Val Loss:\t 0.023226625390853912\n",
      "Epoch:\t 80 Val Loss:\t 0.023220543662786867\n",
      "Epoch:\t 81 Val Loss:\t 0.023224721647727143\n",
      "Epoch:\t 82 Val Loss:\t 0.023225754828842125\n",
      "Epoch:\t 83 Val Loss:\t 0.02321199967954128\n",
      "Epoch:\t 84 Val Loss:\t 0.02321638731687207\n",
      "Epoch:\t 85 Val Loss:\t 0.023216416364553658\n",
      "Epoch:\t 86 Val Loss:\t 0.02321589965720652\n",
      "Epoch:\t 87 Val Loss:\t 0.02321378987917371\n",
      "Epoch:\t 88 Val Loss:\t 0.023209251235823156\n",
      "Epoch:\t 89 Val Loss:\t 0.023208080290837686\n",
      "Epoch:\t 90 Val Loss:\t 0.023207812093893047\n",
      "Epoch:\t 91 Val Loss:\t 0.02320205897595913\n",
      "Epoch:\t 92 Val Loss:\t 0.023209627993237166\n",
      "Epoch:\t 93 Val Loss:\t 0.023195484275794872\n",
      "Epoch:\t 94 Val Loss:\t 0.023211045717742667\n",
      "Epoch:\t 95 Val Loss:\t 0.02319681328209267\n",
      "Epoch:\t 96 Val Loss:\t 0.023202832554649694\n",
      "Epoch:\t 97 Val Loss:\t 0.023189706500272276\n",
      "Epoch:\t 98 Val Loss:\t 0.023186587372201816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:37:01,413] Trial 1 finished with value: 0.023186587372201816 and parameters: {'lr': 1e-05, 'weight_decay': 1e-05, 'scheduler_factor': 0.1, 'scheduler_patience': 5, 'batch_size': 256, 'dropout': 0.1, 'hidden_dims': 256}. Best is trial 1 with value: 0.023186587372201816.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 99 Val Loss:\t 0.02318903874498088\n",
      "Epoch:\t 0 Val Loss:\t 0.024571472034456258\n",
      "Epoch:\t 1 Val Loss:\t 0.02396807988229571\n",
      "Epoch:\t 2 Val Loss:\t 0.02359627614494407\n",
      "Epoch:\t 3 Val Loss:\t 0.02340883161890564\n",
      "Epoch:\t 4 Val Loss:\t 0.02333082954128711\n",
      "Epoch:\t 5 Val Loss:\t 0.023312238913573577\n",
      "Epoch:\t 6 Val Loss:\t 0.023287994909678762\n",
      "Epoch:\t 7 Val Loss:\t 0.023289697678284316\n",
      "Epoch:\t 8 Val Loss:\t 0.023303924789158912\n",
      "Epoch:\t 9 Val Loss:\t 0.023309940828031367\n",
      "Epoch:\t 10 Val Loss:\t 0.023263762927768127\n",
      "Epoch:\t 11 Val Loss:\t 0.023285590157056314\n",
      "Epoch:\t 12 Val Loss:\t 0.02325644063349233\n",
      "Epoch:\t 13 Val Loss:\t 0.023259896659449244\n",
      "Epoch:\t 14 Val Loss:\t 0.023248007745268258\n",
      "Epoch:\t 15 Val Loss:\t 0.0232307579948374\n",
      "Epoch:\t 16 Val Loss:\t 0.023221154821316082\n",
      "Epoch:\t 17 Val Loss:\t 0.023214491804759728\n",
      "Epoch:\t 18 Val Loss:\t 0.02320963777541923\n",
      "Epoch:\t 19 Val Loss:\t 0.023191976117308027\n",
      "Epoch:\t 20 Val Loss:\t 0.02318487265842397\n",
      "Epoch:\t 21 Val Loss:\t 0.023193232230782318\n",
      "Epoch:\t 22 Val Loss:\t 0.023195910337792162\n",
      "Epoch:\t 23 Val Loss:\t 0.023173837616059026\n",
      "Epoch:\t 24 Val Loss:\t 0.023185261750943587\n",
      "Epoch:\t 25 Val Loss:\t 0.02316219075904325\n",
      "Epoch:\t 26 Val Loss:\t 0.02316649304478643\n",
      "Epoch:\t 27 Val Loss:\t 0.02316216013452597\n",
      "Epoch:\t 28 Val Loss:\t 0.023171377196357874\n",
      "Epoch:\t 29 Val Loss:\t 0.02314877626075025\n",
      "Epoch:\t 30 Val Loss:\t 0.023130398037369524\n",
      "Epoch:\t 31 Val Loss:\t 0.023140030603610685\n",
      "Epoch:\t 32 Val Loss:\t 0.02313026718879014\n",
      "Epoch:\t 33 Val Loss:\t 0.023137094871549125\n",
      "Epoch:\t 34 Val Loss:\t 0.023128535966261816\n",
      "Epoch:\t 35 Val Loss:\t 0.023131892763759886\n",
      "Epoch:\t 36 Val Loss:\t 0.023122882593070333\n",
      "Epoch:\t 37 Val Loss:\t 0.02311619555048441\n",
      "Epoch:\t 38 Val Loss:\t 0.023123568871669938\n",
      "Epoch:\t 39 Val Loss:\t 0.02312389932525005\n",
      "Epoch:\t 40 Val Loss:\t 0.023109557749897862\n",
      "Epoch:\t 41 Val Loss:\t 0.02311229586816523\n",
      "Epoch:\t 42 Val Loss:\t 0.02311213470002813\n",
      "Epoch:\t 43 Val Loss:\t 0.02310578893708666\n",
      "Epoch:\t 44 Val Loss:\t 0.023100326860242822\n",
      "Epoch:\t 45 Val Loss:\t 0.02309156255572317\n",
      "Epoch:\t 46 Val Loss:\t 0.0230901398924725\n",
      "Epoch:\t 47 Val Loss:\t 0.02309731687351846\n",
      "Epoch:\t 48 Val Loss:\t 0.02309353049563462\n",
      "Epoch:\t 49 Val Loss:\t 0.02309395038906969\n",
      "Epoch:\t 50 Val Loss:\t 0.023087458188733742\n",
      "Epoch:\t 51 Val Loss:\t 0.02308907059363626\n",
      "Epoch:\t 52 Val Loss:\t 0.023087298096924495\n",
      "Epoch:\t 53 Val Loss:\t 0.02309442892144427\n",
      "Epoch:\t 54 Val Loss:\t 0.023084558663145304\n",
      "Epoch:\t 55 Val Loss:\t 0.0230837141673408\n",
      "Epoch:\t 56 Val Loss:\t 0.023081666519372077\n",
      "Epoch:\t 57 Val Loss:\t 0.023081624417014144\n",
      "Epoch:\t 58 Val Loss:\t 0.02307791487996976\n",
      "Epoch:\t 59 Val Loss:\t 0.023074293894809857\n",
      "Epoch:\t 60 Val Loss:\t 0.023077931063754983\n",
      "Epoch:\t 61 Val Loss:\t 0.02308094637830223\n",
      "Epoch:\t 62 Val Loss:\t 0.02308042717867353\n",
      "Epoch:\t 63 Val Loss:\t 0.023079449188316996\n",
      "Epoch:\t 64 Val Loss:\t 0.023077394448543627\n",
      "Epoch:\t 65 Val Loss:\t 0.02307591900935047\n",
      "Epoch:\t 66 Val Loss:\t 0.023069429353333972\n",
      "Epoch:\t 67 Val Loss:\t 0.02307390258684874\n",
      "Epoch:\t 68 Val Loss:\t 0.023075532556823895\n",
      "Epoch:\t 69 Val Loss:\t 0.023076519615242607\n",
      "Epoch:\t 70 Val Loss:\t 0.023074285726677357\n",
      "Epoch:\t 71 Val Loss:\t 0.023071706217278637\n",
      "Epoch:\t 72 Val Loss:\t 0.02307561305119846\n",
      "Epoch:\t 73 Val Loss:\t 0.023076909275824148\n",
      "Epoch:\t 74 Val Loss:\t 0.02307921769710356\n",
      "Epoch:\t 75 Val Loss:\t 0.023076974076740624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:41:41,181] Trial 2 finished with value: 0.023069429353333972 and parameters: {'lr': 0.0001, 'weight_decay': 1e-06, 'scheduler_factor': 0.5, 'scheduler_patience': 5, 'batch_size': 128, 'dropout': 0.2, 'hidden_dims': 128}. Best is trial 2 with value: 0.023069429353333972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 76 Val Loss:\t 0.023072915079960087\n",
      "Epoch:\t 0 Val Loss:\t 0.02381470836788631\n",
      "Epoch:\t 1 Val Loss:\t 0.023525461140772107\n",
      "Epoch:\t 2 Val Loss:\t 0.023391806737855136\n",
      "Epoch:\t 3 Val Loss:\t 0.0233008254591283\n",
      "Epoch:\t 4 Val Loss:\t 0.02329317992217032\n",
      "Epoch:\t 5 Val Loss:\t 0.02329198986518928\n",
      "Epoch:\t 6 Val Loss:\t 0.02328547072516935\n",
      "Epoch:\t 7 Val Loss:\t 0.02330079959270805\n",
      "Epoch:\t 8 Val Loss:\t 0.023293844075408954\n",
      "Epoch:\t 9 Val Loss:\t 0.023245843844346362\n",
      "Epoch:\t 10 Val Loss:\t 0.023249512689177666\n",
      "Epoch:\t 11 Val Loss:\t 0.023246403330968397\n",
      "Epoch:\t 12 Val Loss:\t 0.02324411163364971\n",
      "Epoch:\t 13 Val Loss:\t 0.023247378241231943\n",
      "Epoch:\t 14 Val Loss:\t 0.023246450297408995\n",
      "Epoch:\t 15 Val Loss:\t 0.023243604313041462\n",
      "Epoch:\t 16 Val Loss:\t 0.023245956798016117\n",
      "Epoch:\t 17 Val Loss:\t 0.023247022390867483\n",
      "Epoch:\t 18 Val Loss:\t 0.023242420088962833\n",
      "Epoch:\t 19 Val Loss:\t 0.023242656776342473\n",
      "Epoch:\t 20 Val Loss:\t 0.023245562965822582\n",
      "Epoch:\t 21 Val Loss:\t 0.023247886879284474\n",
      "Epoch:\t 22 Val Loss:\t 0.02324933484465529\n",
      "Epoch:\t 23 Val Loss:\t 0.023242345185832396\n",
      "Epoch:\t 24 Val Loss:\t 0.0232458380846353\n",
      "Epoch:\t 25 Val Loss:\t 0.023248750886729744\n",
      "Epoch:\t 26 Val Loss:\t 0.02324530052405027\n",
      "Epoch:\t 27 Val Loss:\t 0.02324465821320139\n",
      "Epoch:\t 28 Val Loss:\t 0.02325006756623841\n",
      "Epoch:\t 29 Val Loss:\t 0.023245811120344816\n",
      "Epoch:\t 30 Val Loss:\t 0.023244416662331284\n",
      "Epoch:\t 31 Val Loss:\t 0.0232444491891643\n",
      "Epoch:\t 32 Val Loss:\t 0.023249618002566797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:44:22,257] Trial 3 finished with value: 0.023242345185832396 and parameters: {'lr': 0.001, 'weight_decay': 1e-06, 'scheduler_factor': 0.1, 'scheduler_patience': 1, 'batch_size': 64, 'dropout': 0.1, 'hidden_dims': 256}. Best is trial 2 with value: 0.023069429353333972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 33 Val Loss:\t 0.023247797712803175\n",
      "Epoch:\t 0 Val Loss:\t 0.08668770595643532\n",
      "Epoch:\t 1 Val Loss:\t 0.06790027841566845\n",
      "Epoch:\t 2 Val Loss:\t 0.0563919683006468\n",
      "Epoch:\t 3 Val Loss:\t 0.049284259129441184\n",
      "Epoch:\t 4 Val Loss:\t 0.044823187533437156\n",
      "Epoch:\t 5 Val Loss:\t 0.04192407384969258\n",
      "Epoch:\t 6 Val Loss:\t 0.03979305729246063\n",
      "Epoch:\t 7 Val Loss:\t 0.0379837074139145\n",
      "Epoch:\t 8 Val Loss:\t 0.03650473543767179\n",
      "Epoch:\t 9 Val Loss:\t 0.03525148806899164\n",
      "Epoch:\t 10 Val Loss:\t 0.034009563959357635\n",
      "Epoch:\t 11 Val Loss:\t 0.032849668613358446\n",
      "Epoch:\t 12 Val Loss:\t 0.03213688176286737\n",
      "Epoch:\t 13 Val Loss:\t 0.03137644507995482\n",
      "Epoch:\t 14 Val Loss:\t 0.030706201038692583\n",
      "Epoch:\t 15 Val Loss:\t 0.030050186820053174\n",
      "Epoch:\t 16 Val Loss:\t 0.029520559625440004\n",
      "Epoch:\t 17 Val Loss:\t 0.029133052988214055\n",
      "Epoch:\t 18 Val Loss:\t 0.02877434938667674\n",
      "Epoch:\t 19 Val Loss:\t 0.028439482799574232\n",
      "Epoch:\t 20 Val Loss:\t 0.028148351844107168\n",
      "Epoch:\t 21 Val Loss:\t 0.02781899387007923\n",
      "Epoch:\t 22 Val Loss:\t 0.02751117677728303\n",
      "Epoch:\t 23 Val Loss:\t 0.027324510122354876\n",
      "Epoch:\t 24 Val Loss:\t 0.0269412761359785\n",
      "Epoch:\t 25 Val Loss:\t 0.02666909818090558\n",
      "Epoch:\t 26 Val Loss:\t 0.02637971171370766\n",
      "Epoch:\t 27 Val Loss:\t 0.026131836225070884\n",
      "Epoch:\t 28 Val Loss:\t 0.025836459389419846\n",
      "Epoch:\t 29 Val Loss:\t 0.025543251853693355\n",
      "Epoch:\t 30 Val Loss:\t 0.025354037082262252\n",
      "Epoch:\t 31 Val Loss:\t 0.02514632350285306\n",
      "Epoch:\t 32 Val Loss:\t 0.024949272069033614\n",
      "Epoch:\t 33 Val Loss:\t 0.024785242095757068\n",
      "Epoch:\t 34 Val Loss:\t 0.024604833937499727\n",
      "Epoch:\t 35 Val Loss:\t 0.0244472273244234\n",
      "Epoch:\t 36 Val Loss:\t 0.024321125204380404\n",
      "Epoch:\t 37 Val Loss:\t 0.02420724674844053\n",
      "Epoch:\t 38 Val Loss:\t 0.02410244812851063\n",
      "Epoch:\t 39 Val Loss:\t 0.02400016872269097\n",
      "Epoch:\t 40 Val Loss:\t 0.023924068456596396\n",
      "Epoch:\t 41 Val Loss:\t 0.023852316339770824\n",
      "Epoch:\t 42 Val Loss:\t 0.023802833476165134\n",
      "Epoch:\t 43 Val Loss:\t 0.02373787368173871\n",
      "Epoch:\t 44 Val Loss:\t 0.023694643559439607\n",
      "Epoch:\t 45 Val Loss:\t 0.023662561993226767\n",
      "Epoch:\t 46 Val Loss:\t 0.023627072477034543\n",
      "Epoch:\t 47 Val Loss:\t 0.023589586250089337\n",
      "Epoch:\t 48 Val Loss:\t 0.023553968737586542\n",
      "Epoch:\t 49 Val Loss:\t 0.023537878610827567\n",
      "Epoch:\t 50 Val Loss:\t 0.023519665675527785\n",
      "Epoch:\t 51 Val Loss:\t 0.0235060245354763\n",
      "Epoch:\t 52 Val Loss:\t 0.02349685985194355\n",
      "Epoch:\t 53 Val Loss:\t 0.023486027697379286\n",
      "Epoch:\t 54 Val Loss:\t 0.023476568111973437\n",
      "Epoch:\t 55 Val Loss:\t 0.02346712647732437\n",
      "Epoch:\t 56 Val Loss:\t 0.02345146570970599\n",
      "Epoch:\t 57 Val Loss:\t 0.02345827560016757\n",
      "Epoch:\t 58 Val Loss:\t 0.023442462284004324\n",
      "Epoch:\t 59 Val Loss:\t 0.023430459051845928\n",
      "Epoch:\t 60 Val Loss:\t 0.023426157510562845\n",
      "Epoch:\t 61 Val Loss:\t 0.023420027165672177\n",
      "Epoch:\t 62 Val Loss:\t 0.023414774180463192\n",
      "Epoch:\t 63 Val Loss:\t 0.02340773725059978\n",
      "Epoch:\t 64 Val Loss:\t 0.02340068249854096\n",
      "Epoch:\t 65 Val Loss:\t 0.023411970770952216\n",
      "Epoch:\t 66 Val Loss:\t 0.023403474205976313\n",
      "Epoch:\t 67 Val Loss:\t 0.02338946881565007\n",
      "Epoch:\t 68 Val Loss:\t 0.023380298032926135\n",
      "Epoch:\t 69 Val Loss:\t 0.023405565011702226\n",
      "Epoch:\t 70 Val Loss:\t 0.02338475627558572\n",
      "Epoch:\t 71 Val Loss:\t 0.023372960915223936\n",
      "Epoch:\t 72 Val Loss:\t 0.02338143516732544\n",
      "Epoch:\t 73 Val Loss:\t 0.02336681072404354\n",
      "Epoch:\t 74 Val Loss:\t 0.023364816058313483\n",
      "Epoch:\t 75 Val Loss:\t 0.02336709261430879\n",
      "Epoch:\t 76 Val Loss:\t 0.02337137973578841\n",
      "Epoch:\t 77 Val Loss:\t 0.023360764571909536\n",
      "Epoch:\t 78 Val Loss:\t 0.02335893288912494\n",
      "Epoch:\t 79 Val Loss:\t 0.023364164183337845\n",
      "Epoch:\t 80 Val Loss:\t 0.02336555453582426\n",
      "Epoch:\t 81 Val Loss:\t 0.023360911873356104\n",
      "Epoch:\t 82 Val Loss:\t 0.023363744089586202\n",
      "Epoch:\t 83 Val Loss:\t 0.023346266017129486\n",
      "Epoch:\t 84 Val Loss:\t 0.02334600125542613\n",
      "Epoch:\t 85 Val Loss:\t 0.02335239759082779\n",
      "Epoch:\t 86 Val Loss:\t 0.023354646820054774\n",
      "Epoch:\t 87 Val Loss:\t 0.023342501733864676\n",
      "Epoch:\t 88 Val Loss:\t 0.023342139932235783\n",
      "Epoch:\t 89 Val Loss:\t 0.023347055877336147\n",
      "Epoch:\t 90 Val Loss:\t 0.023352675334240996\n",
      "Epoch:\t 91 Val Loss:\t 0.023349192615353277\n",
      "Epoch:\t 92 Val Loss:\t 0.023348845478691413\n",
      "Epoch:\t 93 Val Loss:\t 0.023354390680933458\n",
      "Epoch:\t 94 Val Loss:\t 0.023360195980791486\n",
      "Epoch:\t 95 Val Loss:\t 0.023351595272126206\n",
      "Epoch:\t 96 Val Loss:\t 0.023350702138261847\n",
      "Epoch:\t 97 Val Loss:\t 0.02334471843706184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 15:50:16,800] Trial 4 finished with value: 0.023342139932235783 and parameters: {'lr': 1e-06, 'weight_decay': 0.0001, 'scheduler_factor': 0.5, 'scheduler_patience': 5, 'batch_size': 128, 'dropout': 0.1, 'hidden_dims': 128}. Best is trial 2 with value: 0.023069429353333972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 98 Val Loss:\t 0.02334617714533645\n",
      "Epoch:\t 0 Val Loss:\t 0.02332042397842023\n",
      "Epoch:\t 1 Val Loss:\t 0.02319811713405773\n",
      "Epoch:\t 2 Val Loss:\t 0.023141391366717213\n",
      "Epoch:\t 3 Val Loss:\t 0.023127845780145092\n",
      "Epoch:\t 4 Val Loss:\t 0.023123897030461447\n",
      "Epoch:\t 5 Val Loss:\t 0.0231151068655905\n",
      "Epoch:\t 6 Val Loss:\t 0.023114779600965023\n",
      "Epoch:\t 7 Val Loss:\t 0.0231153956556402\n",
      "Epoch:\t 8 Val Loss:\t 0.02311951062485107\n",
      "Epoch:\t 9 Val Loss:\t 0.023114277156821128\n",
      "Epoch:\t 10 Val Loss:\t 0.023116620985984777\n",
      "Epoch:\t 11 Val Loss:\t 0.023115808135441552\n",
      "Epoch:\t 12 Val Loss:\t 0.02311773106147539\n",
      "Epoch:\t 13 Val Loss:\t 0.02311059151014992\n",
      "Epoch:\t 14 Val Loss:\t 0.023112227168420086\n",
      "Epoch:\t 15 Val Loss:\t 0.023116362600043742\n",
      "Epoch:\t 16 Val Loss:\t 0.02312077567906107\n",
      "Epoch:\t 17 Val Loss:\t 0.023116114718025577\n",
      "Epoch:\t 18 Val Loss:\t 0.02312391497432869\n",
      "Epoch:\t 19 Val Loss:\t 0.023109762234106865\n",
      "Epoch:\t 20 Val Loss:\t 0.023115453473772786\n",
      "Epoch:\t 21 Val Loss:\t 0.023112829432579623\n",
      "Epoch:\t 22 Val Loss:\t 0.02312299544452588\n",
      "Epoch:\t 23 Val Loss:\t 0.023126083366465374\n",
      "Epoch:\t 24 Val Loss:\t 0.02311984203256513\n",
      "Epoch:\t 25 Val Loss:\t 0.023116060523859273\n",
      "Epoch:\t 26 Val Loss:\t 0.023107823156689182\n",
      "Epoch:\t 27 Val Loss:\t 0.023122252132672688\n",
      "Epoch:\t 28 Val Loss:\t 0.02309683958795112\n",
      "Epoch:\t 29 Val Loss:\t 0.023113290129176806\n",
      "Epoch:\t 30 Val Loss:\t 0.02311186398209885\n",
      "Epoch:\t 31 Val Loss:\t 0.023113322617798488\n",
      "Epoch:\t 32 Val Loss:\t 0.023103517488031786\n",
      "Epoch:\t 33 Val Loss:\t 0.023100759886299244\n",
      "Epoch:\t 34 Val Loss:\t 0.02311080723662811\n",
      "Epoch:\t 35 Val Loss:\t 0.02311942463024534\n",
      "Epoch:\t 36 Val Loss:\t 0.023117063063221283\n",
      "Epoch:\t 37 Val Loss:\t 0.023119549298156267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:02:04,996] Trial 5 finished with value: 0.02309683958795112 and parameters: {'lr': 0.0001, 'weight_decay': 1e-06, 'scheduler_factor': 0.1, 'scheduler_patience': 10, 'batch_size': 16, 'dropout': 0.05, 'hidden_dims': 64}. Best is trial 2 with value: 0.023069429353333972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 38 Val Loss:\t 0.023116039542697385\n",
      "Epoch:\t 0 Val Loss:\t 0.023330534132657656\n",
      "Epoch:\t 1 Val Loss:\t 0.023313606130282043\n",
      "Epoch:\t 2 Val Loss:\t 0.023300424293750954\n",
      "Epoch:\t 3 Val Loss:\t 0.02330954476016882\n",
      "Epoch:\t 4 Val Loss:\t 0.023313107353955524\n",
      "Epoch:\t 5 Val Loss:\t 0.023316859370842054\n",
      "Epoch:\t 6 Val Loss:\t 0.02330391027557303\n",
      "Epoch:\t 7 Val Loss:\t 0.023296845502490105\n",
      "Epoch:\t 8 Val Loss:\t 0.0233089175077905\n",
      "Epoch:\t 9 Val Loss:\t 0.02330289796096269\n",
      "Epoch:\t 10 Val Loss:\t 0.02329646991228077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:05:35,823] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 11 Val Loss:\t 0.023311118262406998\n",
      "Epoch:\t 0 Val Loss:\t 0.023726079179224126\n",
      "Epoch:\t 1 Val Loss:\t 0.023458895350028135\n",
      "Epoch:\t 2 Val Loss:\t 0.02317249327860698\n",
      "Epoch:\t 3 Val Loss:\t 0.0231281787978265\n",
      "Epoch:\t 4 Val Loss:\t 0.023121198524304765\n",
      "Epoch:\t 5 Val Loss:\t 0.023134465385713655\n",
      "Epoch:\t 6 Val Loss:\t 0.023118237199220723\n",
      "Epoch:\t 7 Val Loss:\t 0.02312359818684792\n",
      "Epoch:\t 8 Val Loss:\t 0.023117123746158246\n",
      "Epoch:\t 9 Val Loss:\t 0.023116446113986576\n",
      "Epoch:\t 10 Val Loss:\t 0.023126388443092664\n",
      "Epoch:\t 11 Val Loss:\t 0.023120267039728547\n",
      "Epoch:\t 12 Val Loss:\t 0.023125233013698\n",
      "Epoch:\t 13 Val Loss:\t 0.02312376822880609\n",
      "Epoch:\t 14 Val Loss:\t 0.023117836044433123\n",
      "Epoch:\t 15 Val Loss:\t 0.023122716675659936\n",
      "Epoch:\t 16 Val Loss:\t 0.023115708175785316\n",
      "Epoch:\t 17 Val Loss:\t 0.02311993445790483\n",
      "Epoch:\t 18 Val Loss:\t 0.023112549473772306\n",
      "Epoch:\t 19 Val Loss:\t 0.0231099804889463\n",
      "Epoch:\t 20 Val Loss:\t 0.023116853671943497\n",
      "Epoch:\t 21 Val Loss:\t 0.02311928215845374\n",
      "Epoch:\t 22 Val Loss:\t 0.023116813422757423\n",
      "Epoch:\t 23 Val Loss:\t 0.023113828743686657\n",
      "Epoch:\t 24 Val Loss:\t 0.023111009216290678\n",
      "Epoch:\t 25 Val Loss:\t 0.02312203637494114\n",
      "Epoch:\t 26 Val Loss:\t 0.02311461268437052\n",
      "Epoch:\t 27 Val Loss:\t 0.023112021836793735\n",
      "Epoch:\t 28 Val Loss:\t 0.02311067167736724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:10:32,093] Trial 7 finished with value: 0.0231099804889463 and parameters: {'lr': 0.0001, 'weight_decay': 1e-05, 'scheduler_factor': 0.5, 'scheduler_patience': 20, 'batch_size': 32, 'dropout': 0.15, 'hidden_dims': 1024}. Best is trial 2 with value: 0.023069429353333972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 29 Val Loss:\t 0.023113458550242123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:10:36,617] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.08166681893271452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:10:39,757] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.1147824376821518\n",
      "Epoch:\t 0 Val Loss:\t 0.02337479896329188\n",
      "Epoch:\t 1 Val Loss:\t 0.02334431592333183\n",
      "Epoch:\t 2 Val Loss:\t 0.023456947546135365\n",
      "Epoch:\t 3 Val Loss:\t 0.02364614967071417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:10:57,438] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 4 Val Loss:\t 0.02376021472901632\n",
      "Epoch:\t 0 Val Loss:\t 0.023400500099348402\n",
      "Epoch:\t 1 Val Loss:\t 0.023316485713999417\n",
      "Epoch:\t 2 Val Loss:\t 0.02321441310503229\n",
      "Epoch:\t 3 Val Loss:\t 0.023177981147875865\n",
      "Epoch:\t 4 Val Loss:\t 0.023152192789211084\n",
      "Epoch:\t 5 Val Loss:\t 0.023141166979554862\n",
      "Epoch:\t 6 Val Loss:\t 0.02312655526561731\n",
      "Epoch:\t 7 Val Loss:\t 0.023113376904891788\n",
      "Epoch:\t 8 Val Loss:\t 0.02312024530121115\n",
      "Epoch:\t 9 Val Loss:\t 0.02312202806646302\n",
      "Epoch:\t 10 Val Loss:\t 0.02310722204142828\n",
      "Epoch:\t 11 Val Loss:\t 0.023109819373014012\n",
      "Epoch:\t 12 Val Loss:\t 0.023110900927380554\n",
      "Epoch:\t 13 Val Loss:\t 0.023113237157616293\n",
      "Epoch:\t 14 Val Loss:\t 0.02311671467039281\n",
      "Epoch:\t 15 Val Loss:\t 0.02311156708034335\n",
      "Epoch:\t 16 Val Loss:\t 0.023124308894854693\n",
      "Epoch:\t 17 Val Loss:\t 0.023101631978549475\n",
      "Epoch:\t 18 Val Loss:\t 0.0231120145557427\n",
      "Epoch:\t 19 Val Loss:\t 0.023106026299002234\n",
      "Epoch:\t 20 Val Loss:\t 0.023110052627613765\n",
      "Epoch:\t 21 Val Loss:\t 0.023097280646162864\n",
      "Epoch:\t 22 Val Loss:\t 0.0231060535428466\n",
      "Epoch:\t 23 Val Loss:\t 0.023115758022039298\n",
      "Epoch:\t 24 Val Loss:\t 0.023103117035185736\n",
      "Epoch:\t 25 Val Loss:\t 0.02310729285814443\n",
      "Epoch:\t 26 Val Loss:\t 0.023112953484709244\n",
      "Epoch:\t 27 Val Loss:\t 0.02310600345053019\n",
      "Epoch:\t 28 Val Loss:\t 0.023112215390016514\n",
      "Epoch:\t 29 Val Loss:\t 0.023108693008801664\n",
      "Epoch:\t 30 Val Loss:\t 0.023112320147478622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:21:04,623] Trial 11 finished with value: 0.023097280646162864 and parameters: {'lr': 0.0001, 'weight_decay': 1e-06, 'scheduler_factor': 0.3, 'scheduler_patience': 20, 'batch_size': 16, 'dropout': 0.05, 'hidden_dims': 128}. Best is trial 2 with value: 0.023069429353333972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 31 Val Loss:\t 0.023111329485231796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:21:24,725] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.024282438783719613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:21:34,441] Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.024194663060168344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:21:51,201] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.02491885523883351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:21:54,732] Trial 15 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.025704259504332395\n",
      "Epoch:\t 0 Val Loss:\t 0.023170723629646277\n",
      "Epoch:\t 1 Val Loss:\t 0.023172885021282518\n",
      "Epoch:\t 2 Val Loss:\t 0.023155553521302198\n",
      "Epoch:\t 3 Val Loss:\t 0.02317519088323687\n",
      "Epoch:\t 4 Val Loss:\t 0.023149040320328735\n",
      "Epoch:\t 5 Val Loss:\t 0.023154615243011236\n",
      "Epoch:\t 6 Val Loss:\t 0.02314608249301287\n",
      "Epoch:\t 7 Val Loss:\t 0.023195283775923368\n",
      "Epoch:\t 8 Val Loss:\t 0.02317034275566014\n",
      "Epoch:\t 9 Val Loss:\t 0.023132821870622534\n",
      "Epoch:\t 10 Val Loss:\t 0.02314898300396461\n",
      "Epoch:\t 11 Val Loss:\t 0.023146954575746483\n",
      "Epoch:\t 12 Val Loss:\t 0.023134079150313652\n",
      "Epoch:\t 13 Val Loss:\t 0.023113761030389823\n",
      "Epoch:\t 14 Val Loss:\t 0.023128700803310736\n",
      "Epoch:\t 15 Val Loss:\t 0.02313414611821004\n",
      "Epoch:\t 16 Val Loss:\t 0.023137321020378555\n",
      "Epoch:\t 17 Val Loss:\t 0.02312979822057691\n",
      "Epoch:\t 18 Val Loss:\t 0.023106225139264223\n",
      "Epoch:\t 19 Val Loss:\t 0.02313420873887701\n",
      "Epoch:\t 20 Val Loss:\t 0.02313140266302669\n",
      "Epoch:\t 21 Val Loss:\t 0.02309710028717726\n",
      "Epoch:\t 22 Val Loss:\t 0.023115488997263307\n",
      "Epoch:\t 23 Val Loss:\t 0.023107089835047973\n",
      "Epoch:\t 24 Val Loss:\t 0.023099153535487214\n",
      "Epoch:\t 25 Val Loss:\t 0.023098847070274837\n",
      "Epoch:\t 26 Val Loss:\t 0.023096936791456014\n",
      "Epoch:\t 27 Val Loss:\t 0.02311226562246982\n",
      "Epoch:\t 28 Val Loss:\t 0.023097222775408963\n",
      "Epoch:\t 29 Val Loss:\t 0.023106769747633513\n",
      "Epoch:\t 30 Val Loss:\t 0.02309337803510644\n",
      "Epoch:\t 31 Val Loss:\t 0.023099692850563083\n",
      "Epoch:\t 32 Val Loss:\t 0.023085658972367473\n",
      "Epoch:\t 33 Val Loss:\t 0.0231033687371006\n",
      "Epoch:\t 34 Val Loss:\t 0.023095056393891544\n",
      "Epoch:\t 35 Val Loss:\t 0.023102468962121873\n",
      "Epoch:\t 36 Val Loss:\t 0.023091676676889574\n",
      "Epoch:\t 37 Val Loss:\t 0.023081576283159044\n",
      "Epoch:\t 38 Val Loss:\t 0.02308428044813629\n",
      "Epoch:\t 39 Val Loss:\t 0.02310140948594094\n",
      "Epoch:\t 40 Val Loss:\t 0.023090231906532335\n",
      "Epoch:\t 41 Val Loss:\t 0.023099642811987592\n",
      "Epoch:\t 42 Val Loss:\t 0.023096427892617833\n",
      "Epoch:\t 43 Val Loss:\t 0.023103824008851078\n",
      "Epoch:\t 44 Val Loss:\t 0.023090690781349853\n",
      "Epoch:\t 45 Val Loss:\t 0.023090326430268947\n",
      "Epoch:\t 46 Val Loss:\t 0.023087455273612043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:35:53,009] Trial 16 finished with value: 0.023081576283159044 and parameters: {'lr': 0.0001, 'weight_decay': 0.0001, 'scheduler_factor': 0.8, 'scheduler_patience': 1, 'batch_size': 16, 'dropout': 0.05, 'hidden_dims': 128}. Best is trial 2 with value: 0.023069429353333972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 47 Val Loss:\t 0.02309368692127235\n",
      "Epoch:\t 0 Val Loss:\t 0.023344489218096096\n",
      "Epoch:\t 1 Val Loss:\t 0.023194425902292013\n",
      "Epoch:\t 2 Val Loss:\t 0.023192242849289318\n",
      "Epoch:\t 3 Val Loss:\t 0.023130201840740338\n",
      "Epoch:\t 4 Val Loss:\t 0.023110504942328743\n",
      "Epoch:\t 5 Val Loss:\t 0.023118540381543325\n",
      "Epoch:\t 6 Val Loss:\t 0.023122264661289523\n",
      "Epoch:\t 7 Val Loss:\t 0.02312290488202633\n",
      "Epoch:\t 8 Val Loss:\t 0.023114801332187115\n",
      "Epoch:\t 9 Val Loss:\t 0.02310541103837674\n",
      "Epoch:\t 10 Val Loss:\t 0.023115203836947727\n",
      "Epoch:\t 11 Val Loss:\t 0.023113789246155973\n",
      "Epoch:\t 12 Val Loss:\t 0.02310640819334869\n",
      "Epoch:\t 13 Val Loss:\t 0.02311922846897169\n",
      "Epoch:\t 14 Val Loss:\t 0.023113543631129243\n",
      "Epoch:\t 15 Val Loss:\t 0.02309908896959708\n",
      "Epoch:\t 16 Val Loss:\t 0.023103145245659984\n",
      "Epoch:\t 17 Val Loss:\t 0.02309208471824327\n",
      "Epoch:\t 18 Val Loss:\t 0.02309676811972074\n",
      "Epoch:\t 19 Val Loss:\t 0.023092990863715475\n",
      "Epoch:\t 20 Val Loss:\t 0.023096553882640782\n",
      "Epoch:\t 21 Val Loss:\t 0.023107221275328823\n",
      "Epoch:\t 22 Val Loss:\t 0.023099052102378247\n",
      "Epoch:\t 23 Val Loss:\t 0.02309268011590451\n",
      "Epoch:\t 24 Val Loss:\t 0.02310211014415154\n",
      "Epoch:\t 25 Val Loss:\t 0.02309592774684988\n",
      "Epoch:\t 26 Val Loss:\t 0.02309233687495152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:37:35,308] Trial 17 finished with value: 0.02309208471824327 and parameters: {'lr': 0.0001, 'weight_decay': 0.0001, 'scheduler_factor': 0.8, 'scheduler_patience': 1, 'batch_size': 128, 'dropout': 0.2, 'hidden_dims': 128}. Best is trial 2 with value: 0.023069429353333972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 27 Val Loss:\t 0.02309648356853385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:37:40,035] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.030085006706362834\n",
      "Epoch:\t 0 Val Loss:\t 0.023175483757633723\n",
      "Epoch:\t 1 Val Loss:\t 0.02313933778509408\n",
      "Epoch:\t 2 Val Loss:\t 0.02313953782123829\n",
      "Epoch:\t 3 Val Loss:\t 0.02316405187194835\n",
      "Epoch:\t 4 Val Loss:\t 0.023130358461447374\n",
      "Epoch:\t 5 Val Loss:\t 0.023153085316828113\n",
      "Epoch:\t 6 Val Loss:\t 0.02313178684114514\n",
      "Epoch:\t 7 Val Loss:\t 0.02313841189517227\n",
      "Epoch:\t 8 Val Loss:\t 0.023130586257723268\n",
      "Epoch:\t 9 Val Loss:\t 0.023155174873963385\n",
      "Epoch:\t 10 Val Loss:\t 0.023117560932117857\n",
      "Epoch:\t 11 Val Loss:\t 0.02312787941737261\n",
      "Epoch:\t 12 Val Loss:\t 0.023115341718829348\n",
      "Epoch:\t 13 Val Loss:\t 0.023123229085234457\n",
      "Epoch:\t 14 Val Loss:\t 0.02313669198276643\n",
      "Epoch:\t 15 Val Loss:\t 0.023108623650499836\n",
      "Epoch:\t 16 Val Loss:\t 0.023120496956583015\n",
      "Epoch:\t 17 Val Loss:\t 0.02310362473160088\n",
      "Epoch:\t 18 Val Loss:\t 0.023109258996520585\n",
      "Epoch:\t 19 Val Loss:\t 0.02310998531465301\n",
      "Epoch:\t 20 Val Loss:\t 0.023106544991891704\n",
      "Epoch:\t 21 Val Loss:\t 0.023107872896628055\n",
      "Epoch:\t 22 Val Loss:\t 0.023098989666060717\n",
      "Epoch:\t 23 Val Loss:\t 0.023112078057322093\n",
      "Epoch:\t 24 Val Loss:\t 0.023103899809574793\n",
      "Epoch:\t 25 Val Loss:\t 0.023097956390353388\n",
      "Epoch:\t 26 Val Loss:\t 0.02309861003994225\n",
      "Epoch:\t 27 Val Loss:\t 0.023102424083975608\n",
      "Epoch:\t 28 Val Loss:\t 0.023098789778853466\n",
      "Epoch:\t 29 Val Loss:\t 0.02308638910156393\n",
      "Epoch:\t 30 Val Loss:\t 0.023099632557474062\n",
      "Epoch:\t 31 Val Loss:\t 0.023090925227051865\n",
      "Epoch:\t 32 Val Loss:\t 0.02310195707217725\n",
      "Epoch:\t 33 Val Loss:\t 0.023096026198748117\n",
      "Epoch:\t 34 Val Loss:\t 0.02309030876504276\n",
      "Epoch:\t 35 Val Loss:\t 0.023095695157059448\n",
      "Epoch:\t 36 Val Loss:\t 0.02309097093539331\n",
      "Epoch:\t 37 Val Loss:\t 0.02308532547108635\n",
      "Epoch:\t 38 Val Loss:\t 0.023090721718324925\n",
      "Epoch:\t 39 Val Loss:\t 0.023098448841629142\n",
      "Epoch:\t 40 Val Loss:\t 0.023091815187332627\n",
      "Epoch:\t 41 Val Loss:\t 0.023081877861985702\n",
      "Epoch:\t 42 Val Loss:\t 0.023100889922830766\n",
      "Epoch:\t 43 Val Loss:\t 0.023090878314523396\n",
      "Epoch:\t 44 Val Loss:\t 0.02309672262347891\n",
      "Epoch:\t 45 Val Loss:\t 0.023111045706964924\n",
      "Epoch:\t 46 Val Loss:\t 0.02308885892685167\n",
      "Epoch:\t 47 Val Loss:\t 0.02308560907467453\n",
      "Epoch:\t 48 Val Loss:\t 0.023084421794794367\n",
      "Epoch:\t 49 Val Loss:\t 0.023084182195171325\n",
      "Epoch:\t 50 Val Loss:\t 0.02307985652245596\n",
      "Epoch:\t 51 Val Loss:\t 0.02308573535604324\n",
      "Epoch:\t 52 Val Loss:\t 0.023089305067319193\n",
      "Epoch:\t 53 Val Loss:\t 0.023090241289509084\n",
      "Epoch:\t 54 Val Loss:\t 0.02308950169247114\n",
      "Epoch:\t 55 Val Loss:\t 0.02309421207270546\n",
      "Epoch:\t 56 Val Loss:\t 0.02308880425541697\n",
      "Epoch:\t 57 Val Loss:\t 0.023077620110495058\n",
      "Epoch:\t 58 Val Loss:\t 0.023090919592083696\n",
      "Epoch:\t 59 Val Loss:\t 0.023096784502865078\n",
      "Epoch:\t 60 Val Loss:\t 0.023101196710565285\n",
      "Epoch:\t 61 Val Loss:\t 0.023083545956648664\n",
      "Epoch:\t 62 Val Loss:\t 0.023089844428883764\n",
      "Epoch:\t 63 Val Loss:\t 0.02308376844457252\n",
      "Epoch:\t 64 Val Loss:\t 0.023088601271888776\n",
      "Epoch:\t 65 Val Loss:\t 0.023078231464974387\n",
      "Epoch:\t 66 Val Loss:\t 0.023087211731888487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:45:59,482] Trial 19 finished with value: 0.023077620110495058 and parameters: {'lr': 0.0001, 'weight_decay': 0.0001, 'scheduler_factor': 0.8, 'scheduler_patience': 1, 'batch_size': 32, 'dropout': 0.2, 'hidden_dims': 128}. Best is trial 2 with value: 0.023069429353333972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 67 Val Loss:\t 0.023084267252358143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:46:06,862] Trial 20 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.024493846800439582\n",
      "Epoch:\t 0 Val Loss:\t 0.023292171878587148\n",
      "Epoch:\t 1 Val Loss:\t 0.02317094625998475\n",
      "Epoch:\t 2 Val Loss:\t 0.02316029645159154\n",
      "Epoch:\t 3 Val Loss:\t 0.023156277087324845\n",
      "Epoch:\t 4 Val Loss:\t 0.023150811985672596\n",
      "Epoch:\t 5 Val Loss:\t 0.023156318374217034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:46:59,191] Trial 21 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 6 Val Loss:\t 0.023151122328483747\n",
      "Epoch:\t 0 Val Loss:\t 0.023233337617499794\n",
      "Epoch:\t 1 Val Loss:\t 0.02316343397992049\n",
      "Epoch:\t 2 Val Loss:\t 0.02319455691249313\n",
      "Epoch:\t 3 Val Loss:\t 0.02314719521031829\n",
      "Epoch:\t 4 Val Loss:\t 0.023149409415741604\n",
      "Epoch:\t 5 Val Loss:\t 0.023149484713638355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:47:51,318] Trial 22 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 6 Val Loss:\t 0.023148169637263898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:47:54,394] Trial 23 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.025849191034721792\n",
      "Epoch:\t 0 Val Loss:\t 0.02335281227603196\n",
      "Epoch:\t 1 Val Loss:\t 0.023185540765021623\n",
      "Epoch:\t 2 Val Loss:\t 0.023133951826783475\n",
      "Epoch:\t 3 Val Loss:\t 0.023119391885438087\n",
      "Epoch:\t 4 Val Loss:\t 0.023098064209805445\n",
      "Epoch:\t 5 Val Loss:\t 0.023115108351717983\n",
      "Epoch:\t 6 Val Loss:\t 0.02312234788236132\n",
      "Epoch:\t 7 Val Loss:\t 0.023107584682480097\n",
      "Epoch:\t 8 Val Loss:\t 0.023123035198421387\n",
      "Epoch:\t 9 Val Loss:\t 0.023097170492930166\n",
      "Epoch:\t 10 Val Loss:\t 0.02312427077496224\n",
      "Epoch:\t 11 Val Loss:\t 0.023127688734790677\n",
      "Epoch:\t 12 Val Loss:\t 0.023105575052803057\n",
      "Epoch:\t 13 Val Loss:\t 0.023094018278449154\n",
      "Epoch:\t 14 Val Loss:\t 0.02310920176342919\n",
      "Epoch:\t 15 Val Loss:\t 0.02309793641979105\n",
      "Epoch:\t 16 Val Loss:\t 0.023112633554070568\n",
      "Epoch:\t 17 Val Loss:\t 0.02309833764790723\n",
      "Epoch:\t 18 Val Loss:\t 0.023109530189925172\n",
      "Epoch:\t 19 Val Loss:\t 0.02310726261229806\n",
      "Epoch:\t 20 Val Loss:\t 0.023099169706145412\n",
      "Epoch:\t 21 Val Loss:\t 0.023090993169318424\n",
      "Epoch:\t 22 Val Loss:\t 0.023106594386108424\n",
      "Epoch:\t 23 Val Loss:\t 0.023099019950073373\n",
      "Epoch:\t 24 Val Loss:\t 0.023095474167342745\n",
      "Epoch:\t 25 Val Loss:\t 0.023095066092585485\n",
      "Epoch:\t 26 Val Loss:\t 0.023091617929801512\n",
      "Epoch:\t 27 Val Loss:\t 0.023098732208770314\n",
      "Epoch:\t 28 Val Loss:\t 0.02309074735098532\n",
      "Epoch:\t 29 Val Loss:\t 0.02308823580272125\n",
      "Epoch:\t 30 Val Loss:\t 0.023090635308245403\n",
      "Epoch:\t 31 Val Loss:\t 0.023093978340706128\n",
      "Epoch:\t 32 Val Loss:\t 0.02309804337987165\n",
      "Epoch:\t 33 Val Loss:\t 0.02308869513161301\n",
      "Epoch:\t 34 Val Loss:\t 0.0230979293758232\n",
      "Epoch:\t 35 Val Loss:\t 0.023093558731302023\n",
      "Epoch:\t 36 Val Loss:\t 0.02308447299641744\n",
      "Epoch:\t 37 Val Loss:\t 0.023088848269148393\n",
      "Epoch:\t 38 Val Loss:\t 0.023088542376771975\n",
      "Epoch:\t 39 Val Loss:\t 0.023082907094857857\n",
      "Epoch:\t 40 Val Loss:\t 0.023085489268168016\n",
      "Epoch:\t 41 Val Loss:\t 0.023088834835978803\n",
      "Epoch:\t 42 Val Loss:\t 0.023084634358891513\n",
      "Epoch:\t 43 Val Loss:\t 0.023089131023465725\n",
      "Epoch:\t 44 Val Loss:\t 0.023088227810986926\n",
      "Epoch:\t 45 Val Loss:\t 0.02308686925800903\n",
      "Epoch:\t 46 Val Loss:\t 0.02308485022840205\n",
      "Epoch:\t 47 Val Loss:\t 0.02308740091613265\n",
      "Epoch:\t 48 Val Loss:\t 0.02309001237452987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:50:44,803] Trial 24 finished with value: 0.023082907094857857 and parameters: {'lr': 0.0001, 'weight_decay': 0.0001, 'scheduler_factor': 0.8, 'scheduler_patience': 1, 'batch_size': 128, 'dropout': 0.2, 'hidden_dims': 128}. Best is trial 2 with value: 0.023069429353333972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 49 Val Loss:\t 0.02308690312645887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:50:53,620] Trial 25 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.023767772661839316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:51:07,827] Trial 26 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.02798924176796802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:51:20,768] Trial 27 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.023833411171557645\n",
      "Epoch:\t 0 Val Loss:\t 0.023362744956805497\n",
      "Epoch:\t 1 Val Loss:\t 0.023334903902335013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:51:40,547] Trial 28 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 2 Val Loss:\t 0.023286741251547734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:51:43,967] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.02584458723138079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:51:47,386] Trial 30 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.02365973914104901\n",
      "Epoch:\t 0 Val Loss:\t 0.02330719996512797\n",
      "Epoch:\t 1 Val Loss:\t 0.023248564972158037\n",
      "Epoch:\t 2 Val Loss:\t 0.02313290684099756\n",
      "Epoch:\t 3 Val Loss:\t 0.023118156455397415\n",
      "Epoch:\t 4 Val Loss:\t 0.023119149846211672\n",
      "Epoch:\t 5 Val Loss:\t 0.023124509405817114\n",
      "Epoch:\t 6 Val Loss:\t 0.023113987335328306\n",
      "Epoch:\t 7 Val Loss:\t 0.02311030523268503\n",
      "Epoch:\t 8 Val Loss:\t 0.023118312806967366\n",
      "Epoch:\t 9 Val Loss:\t 0.023101789909706454\n",
      "Epoch:\t 10 Val Loss:\t 0.02311734588783874\n",
      "Epoch:\t 11 Val Loss:\t 0.02310710470902212\n",
      "Epoch:\t 12 Val Loss:\t 0.02313632708802269\n",
      "Epoch:\t 13 Val Loss:\t 0.02309948295342884\n",
      "Epoch:\t 14 Val Loss:\t 0.023109757785429733\n",
      "Epoch:\t 15 Val Loss:\t 0.023115856614842844\n",
      "Epoch:\t 16 Val Loss:\t 0.023109577530412\n",
      "Epoch:\t 17 Val Loss:\t 0.02311415882425362\n",
      "Epoch:\t 18 Val Loss:\t 0.023104361663565016\n",
      "Epoch:\t 19 Val Loss:\t 0.023108955125890996\n",
      "Epoch:\t 20 Val Loss:\t 0.023091044384585528\n",
      "Epoch:\t 21 Val Loss:\t 0.023102135626213507\n",
      "Epoch:\t 22 Val Loss:\t 0.02309084859755889\n",
      "Epoch:\t 23 Val Loss:\t 0.023100992494276208\n",
      "Epoch:\t 24 Val Loss:\t 0.023093450348076812\n",
      "Epoch:\t 25 Val Loss:\t 0.023094008450977876\n",
      "Epoch:\t 26 Val Loss:\t 0.023098480019174264\n",
      "Epoch:\t 27 Val Loss:\t 0.023087788752936437\n",
      "Epoch:\t 28 Val Loss:\t 0.02309983062825463\n",
      "Epoch:\t 29 Val Loss:\t 0.023094870359375234\n",
      "Epoch:\t 30 Val Loss:\t 0.02308817800989503\n",
      "Epoch:\t 31 Val Loss:\t 0.02309579566348326\n",
      "Epoch:\t 32 Val Loss:\t 0.02308604463540245\n",
      "Epoch:\t 33 Val Loss:\t 0.023095269975989437\n",
      "Epoch:\t 34 Val Loss:\t 0.023087524855285164\n",
      "Epoch:\t 35 Val Loss:\t 0.02308190366728635\n",
      "Epoch:\t 36 Val Loss:\t 0.02309665267458888\n",
      "Epoch:\t 37 Val Loss:\t 0.023092235425071578\n",
      "Epoch:\t 38 Val Loss:\t 0.023090342956671363\n",
      "Epoch:\t 39 Val Loss:\t 0.023089243161879228\n",
      "Epoch:\t 40 Val Loss:\t 0.023085117378955286\n",
      "Epoch:\t 41 Val Loss:\t 0.023083029712518948\n",
      "Epoch:\t 42 Val Loss:\t 0.023091565031277236\n",
      "Epoch:\t 43 Val Loss:\t 0.02309156915122108\n",
      "Epoch:\t 44 Val Loss:\t 0.023094369083595124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:54:23,970] Trial 31 finished with value: 0.02308190366728635 and parameters: {'lr': 0.0001, 'weight_decay': 0.0001, 'scheduler_factor': 0.8, 'scheduler_patience': 1, 'batch_size': 128, 'dropout': 0.2, 'hidden_dims': 128}. Best is trial 2 with value: 0.023069429353333972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 45 Val Loss:\t 0.02308832924591787\n",
      "Epoch:\t 0 Val Loss:\t 0.023348068088938873\n",
      "Epoch:\t 1 Val Loss:\t 0.023162167677790356\n",
      "Epoch:\t 2 Val Loss:\t 0.02315517578327828\n",
      "Epoch:\t 3 Val Loss:\t 0.02311938719444252\n",
      "Epoch:\t 4 Val Loss:\t 0.023116943526588513\n",
      "Epoch:\t 5 Val Loss:\t 0.023170517285146644\n",
      "Epoch:\t 6 Val Loss:\t 0.02312683007331568\n",
      "Epoch:\t 7 Val Loss:\t 0.023110332670075937\n",
      "Epoch:\t 8 Val Loss:\t 0.023140045110118333\n",
      "Epoch:\t 9 Val Loss:\t 0.023115827126449412\n",
      "Epoch:\t 10 Val Loss:\t 0.023118971570441276\n",
      "Epoch:\t 11 Val Loss:\t 0.023127765473976946\n",
      "Epoch:\t 12 Val Loss:\t 0.023116113692761234\n",
      "Epoch:\t 13 Val Loss:\t 0.02311568401072228\n",
      "Epoch:\t 14 Val Loss:\t 0.023098604051010566\n",
      "Epoch:\t 15 Val Loss:\t 0.023100099838779788\n",
      "Epoch:\t 16 Val Loss:\t 0.02310174001892057\n",
      "Epoch:\t 17 Val Loss:\t 0.02310698361914862\n",
      "Epoch:\t 18 Val Loss:\t 0.023103363450204004\n",
      "Epoch:\t 19 Val Loss:\t 0.023093584195425194\n",
      "Epoch:\t 20 Val Loss:\t 0.02310090663022157\n",
      "Epoch:\t 21 Val Loss:\t 0.023095308813486207\n",
      "Epoch:\t 22 Val Loss:\t 0.02309971038748422\n",
      "Epoch:\t 23 Val Loss:\t 0.023093288976633337\n",
      "Epoch:\t 24 Val Loss:\t 0.023092944336454136\n",
      "Epoch:\t 25 Val Loss:\t 0.023094291647785547\n",
      "Epoch:\t 26 Val Loss:\t 0.023096088251251472\n",
      "Epoch:\t 27 Val Loss:\t 0.023096859192006276\n",
      "Epoch:\t 28 Val Loss:\t 0.02310616433632412\n",
      "Epoch:\t 29 Val Loss:\t 0.02308492034518221\n",
      "Epoch:\t 30 Val Loss:\t 0.023092955326957456\n",
      "Epoch:\t 31 Val Loss:\t 0.023094438829640133\n",
      "Epoch:\t 32 Val Loss:\t 0.023092356754129045\n",
      "Epoch:\t 33 Val Loss:\t 0.023097666091080844\n",
      "Epoch:\t 34 Val Loss:\t 0.023086307301256284\n",
      "Epoch:\t 35 Val Loss:\t 0.02308525972630392\n",
      "Epoch:\t 36 Val Loss:\t 0.023085897737578825\n",
      "Epoch:\t 37 Val Loss:\t 0.023086464633480505\n",
      "Epoch:\t 38 Val Loss:\t 0.023091011126054807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:56:41,813] Trial 32 finished with value: 0.02308492034518221 and parameters: {'lr': 0.0001, 'weight_decay': 0.0001, 'scheduler_factor': 0.8, 'scheduler_patience': 1, 'batch_size': 128, 'dropout': 0.2, 'hidden_dims': 128}. Best is trial 2 with value: 0.023069429353333972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 39 Val Loss:\t 0.02308926805495068\n",
      "Epoch:\t 0 Val Loss:\t 0.023302536454787224\n",
      "Epoch:\t 1 Val Loss:\t 0.023217757069543123\n",
      "Epoch:\t 2 Val Loss:\t 0.023138276586850227\n",
      "Epoch:\t 3 Val Loss:\t 0.023129305268606442\n",
      "Epoch:\t 4 Val Loss:\t 0.02314668699178133\n",
      "Epoch:\t 5 Val Loss:\t 0.023125173981461442\n",
      "Epoch:\t 6 Val Loss:\t 0.023145396749744637\n",
      "Epoch:\t 7 Val Loss:\t 0.023154735571165146\n",
      "Epoch:\t 8 Val Loss:\t 0.0231278282209011\n",
      "Epoch:\t 9 Val Loss:\t 0.0231206968522378\n",
      "Epoch:\t 10 Val Loss:\t 0.023131219015410393\n",
      "Epoch:\t 11 Val Loss:\t 0.023123054240455024\n",
      "Epoch:\t 12 Val Loss:\t 0.02312371014568052\n",
      "Epoch:\t 13 Val Loss:\t 0.02310290535011988\n",
      "Epoch:\t 14 Val Loss:\t 0.02311728574503004\n",
      "Epoch:\t 15 Val Loss:\t 0.023113404216774013\n",
      "Epoch:\t 16 Val Loss:\t 0.023101417102625244\n",
      "Epoch:\t 17 Val Loss:\t 0.02310700747774941\n",
      "Epoch:\t 18 Val Loss:\t 0.023108771537246713\n",
      "Epoch:\t 19 Val Loss:\t 0.023109535009482124\n",
      "Epoch:\t 20 Val Loss:\t 0.023106727228884138\n",
      "Epoch:\t 21 Val Loss:\t 0.02309758656839115\n",
      "Epoch:\t 22 Val Loss:\t 0.02307981787545436\n",
      "Epoch:\t 23 Val Loss:\t 0.02309587449552925\n",
      "Epoch:\t 24 Val Loss:\t 0.023097034274670705\n",
      "Epoch:\t 25 Val Loss:\t 0.023096959849589326\n",
      "Epoch:\t 26 Val Loss:\t 0.02309304570261969\n",
      "Epoch:\t 27 Val Loss:\t 0.023094025549641774\n",
      "Epoch:\t 28 Val Loss:\t 0.02309467282929543\n",
      "Epoch:\t 29 Val Loss:\t 0.023090714496077542\n",
      "Epoch:\t 30 Val Loss:\t 0.023088330250490535\n",
      "Epoch:\t 31 Val Loss:\t 0.023092145402205697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:58:37,622] Trial 33 finished with value: 0.02307981787545436 and parameters: {'lr': 0.0001, 'weight_decay': 0.0001, 'scheduler_factor': 0.8, 'scheduler_patience': 1, 'batch_size': 128, 'dropout': 0.2, 'hidden_dims': 256}. Best is trial 2 with value: 0.023069429353333972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 32 Val Loss:\t 0.023091779654041338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:58:40,903] Trial 34 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.02356376994245497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:58:45,443] Trial 35 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.026169857843730483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:58:48,930] Trial 36 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.023366446464799382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:58:52,427] Trial 37 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.02406628591936817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:59:04,799] Trial 38 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.032998749092475035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:59:07,922] Trial 39 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.024537497975674855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 16:59:12,543] Trial 40 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.023484504721168527\n",
      "Epoch:\t 0 Val Loss:\t 0.023311659789391544\n",
      "Epoch:\t 1 Val Loss:\t 0.02316804017040454\n",
      "Epoch:\t 2 Val Loss:\t 0.023128734710200258\n",
      "Epoch:\t 3 Val Loss:\t 0.023109745500343188\n",
      "Epoch:\t 4 Val Loss:\t 0.023112957729071522\n",
      "Epoch:\t 5 Val Loss:\t 0.023130195690722565\n",
      "Epoch:\t 6 Val Loss:\t 0.02311599368220539\n",
      "Epoch:\t 7 Val Loss:\t 0.023116003889381218\n",
      "Epoch:\t 8 Val Loss:\t 0.023113029660660037\n",
      "Epoch:\t 9 Val Loss:\t 0.023117681684190733\n",
      "Epoch:\t 10 Val Loss:\t 0.02312385193094683\n",
      "Epoch:\t 11 Val Loss:\t 0.02311625550792554\n",
      "Epoch:\t 12 Val Loss:\t 0.023114660171788922\n",
      "Epoch:\t 13 Val Loss:\t 0.02309803140572426\n",
      "Epoch:\t 14 Val Loss:\t 0.02309896486301579\n",
      "Epoch:\t 15 Val Loss:\t 0.02311554905116845\n",
      "Epoch:\t 16 Val Loss:\t 0.023092098842056565\n",
      "Epoch:\t 17 Val Loss:\t 0.023102788700098784\n",
      "Epoch:\t 18 Val Loss:\t 0.023088817510090134\n",
      "Epoch:\t 19 Val Loss:\t 0.023107363368544496\n",
      "Epoch:\t 20 Val Loss:\t 0.023094600616665753\n",
      "Epoch:\t 21 Val Loss:\t 0.023092872838386562\n",
      "Epoch:\t 22 Val Loss:\t 0.023111368348615702\n",
      "Epoch:\t 23 Val Loss:\t 0.02310279667090451\n",
      "Epoch:\t 24 Val Loss:\t 0.023094275538745317\n",
      "Epoch:\t 25 Val Loss:\t 0.02310352564982197\n",
      "Epoch:\t 26 Val Loss:\t 0.0230900485421356\n",
      "Epoch:\t 27 Val Loss:\t 0.023095795089441738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 17:00:52,122] Trial 41 finished with value: 0.023088817510090134 and parameters: {'lr': 0.0001, 'weight_decay': 0.0001, 'scheduler_factor': 0.8, 'scheduler_patience': 1, 'batch_size': 128, 'dropout': 0.2, 'hidden_dims': 128}. Best is trial 2 with value: 0.023069429353333972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 28 Val Loss:\t 0.02309710295634706\n",
      "Epoch:\t 0 Val Loss:\t 0.02333616739494747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 17:00:59,029] Trial 42 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 1 Val Loss:\t 0.02324934613503767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 17:01:02,506] Trial 43 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.024016351622931455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 17:01:06,128] Trial 44 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.024644699838628357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 17:01:18,657] Trial 45 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03427276579411993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 17:01:22,106] Trial 46 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.024122193775604664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 17:01:28,840] Trial 47 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.023397124304113264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 17:01:32,301] Trial 48 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.02431721855582816\n",
      "Epoch:\t 0 Val Loss:\t 0.023293868195772338\n",
      "Epoch:\t 1 Val Loss:\t 0.02322397847381665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 17:02:31,199] Trial 49 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 2 Val Loss:\t 0.023206865547463356\n",
      "Training model with best parameters on train+validation ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401917/401917 [04:09<00:00, 1609.42it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401917/401917 [01:14<00:00, 5414.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting test set predictions and saving results ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 611/611 [00:01<00:00, 320.62it/s]\n"
     ]
    }
   ],
   "source": [
    "train_different_featno(\n",
    "        adata_path=\"./data/feature_number/sciplex_hvg_3500.h5ad\",\n",
    "        run_name=\"mlp_hvg_3500\",\n",
    "        res_savename=\"./results/feature_number/mlp_hvg_3500_res.pkl\",\n",
    "        input_dim=3500,\n",
    "        output_dim=3500,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fee851d4-8e0f-43c2-be1c-d61858727dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Datasets ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401917/401917 [03:17<00:00, 2032.67it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401917/401917 [01:15<00:00, 5337.67it/s]\n",
      "[I 2025-06-18 17:16:37,520] A new study created in RDB with name: mlp_hvg_5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing Hyperparameters with Optuna ...\n",
      "Epoch:\t 0 Val Loss:\t 0.02296767731787116\n",
      "Epoch:\t 1 Val Loss:\t 0.02188237255792526\n",
      "Epoch:\t 2 Val Loss:\t 0.021895705904943382\n",
      "Epoch:\t 3 Val Loss:\t 0.022021996761729095\n",
      "Epoch:\t 4 Val Loss:\t 0.022132778336620407\n",
      "Epoch:\t 5 Val Loss:\t 0.02242249176744671\n",
      "Epoch:\t 6 Val Loss:\t 0.022655840681632233\n",
      "Epoch:\t 7 Val Loss:\t 0.0230172270268106\n",
      "Epoch:\t 8 Val Loss:\t 0.023123503330244512\n",
      "Epoch:\t 9 Val Loss:\t 0.02326185471854409\n",
      "Epoch:\t 10 Val Loss:\t 0.02337831982869619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 17:17:24,663] Trial 0 finished with value: 0.02188237255792526 and parameters: {'lr': 0.0001, 'weight_decay': 0.001, 'scheduler_factor': 0.3, 'scheduler_patience': 5, 'batch_size': 256, 'dropout': 0.2, 'hidden_dims': 128}. Best is trial 0 with value: 0.02188237255792526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 11 Val Loss:\t 0.023621364541567408\n",
      "Epoch:\t 0 Val Loss:\t 0.024941836358007903\n",
      "Epoch:\t 1 Val Loss:\t 0.0244705852623443\n",
      "Epoch:\t 2 Val Loss:\t 0.024180058876369346\n",
      "Epoch:\t 3 Val Loss:\t 0.023962947537186172\n",
      "Epoch:\t 4 Val Loss:\t 0.023799372670313287\n",
      "Epoch:\t 5 Val Loss:\t 0.023665618256482338\n",
      "Epoch:\t 6 Val Loss:\t 0.023531535380237972\n",
      "Epoch:\t 7 Val Loss:\t 0.02342274274223226\n",
      "Epoch:\t 8 Val Loss:\t 0.023304003465116813\n",
      "Epoch:\t 9 Val Loss:\t 0.023165874701367245\n",
      "Epoch:\t 10 Val Loss:\t 0.023082382780518603\n",
      "Epoch:\t 11 Val Loss:\t 0.022965563638641478\n",
      "Epoch:\t 12 Val Loss:\t 0.022896690627601444\n",
      "Epoch:\t 13 Val Loss:\t 0.022869622171002767\n",
      "Epoch:\t 14 Val Loss:\t 0.02279739906894578\n",
      "Epoch:\t 15 Val Loss:\t 0.02276680412648335\n",
      "Epoch:\t 16 Val Loss:\t 0.02274485231878953\n",
      "Epoch:\t 17 Val Loss:\t 0.02269380954132484\n",
      "Epoch:\t 18 Val Loss:\t 0.02269761633886272\n",
      "Epoch:\t 19 Val Loss:\t 0.022683977135805108\n",
      "Epoch:\t 20 Val Loss:\t 0.022705161103210334\n",
      "Epoch:\t 21 Val Loss:\t 0.022627197219828785\n",
      "Epoch:\t 22 Val Loss:\t 0.022658965231089786\n",
      "Epoch:\t 23 Val Loss:\t 0.022691849906328172\n",
      "Epoch:\t 24 Val Loss:\t 0.02268422117702733\n",
      "Epoch:\t 25 Val Loss:\t 0.022689748068954598\n",
      "Epoch:\t 26 Val Loss:\t 0.022653917666503005\n",
      "Epoch:\t 27 Val Loss:\t 0.022617481299046224\n",
      "Epoch:\t 28 Val Loss:\t 0.02264861943731295\n",
      "Epoch:\t 29 Val Loss:\t 0.022675743625665195\n",
      "Epoch:\t 30 Val Loss:\t 0.02262388379056476\n",
      "Epoch:\t 31 Val Loss:\t 0.022680684770553544\n",
      "Epoch:\t 32 Val Loss:\t 0.02263521239630978\n",
      "Epoch:\t 33 Val Loss:\t 0.022681001081735798\n",
      "Epoch:\t 34 Val Loss:\t 0.022678294695840644\n",
      "Epoch:\t 35 Val Loss:\t 0.022608293118516993\n",
      "Epoch:\t 36 Val Loss:\t 0.022682746120119675\n",
      "Epoch:\t 37 Val Loss:\t 0.022713867890919302\n",
      "Epoch:\t 38 Val Loss:\t 0.02267654494747618\n",
      "Epoch:\t 39 Val Loss:\t 0.02269708760011067\n",
      "Epoch:\t 40 Val Loss:\t 0.022657947310443762\n",
      "Epoch:\t 41 Val Loss:\t 0.02269716570525167\n",
      "Epoch:\t 42 Val Loss:\t 0.022736534462658383\n",
      "Epoch:\t 43 Val Loss:\t 0.022606738106138814\n",
      "Epoch:\t 44 Val Loss:\t 0.022628650291851026\n",
      "Epoch:\t 45 Val Loss:\t 0.022716279844715193\n",
      "Epoch:\t 46 Val Loss:\t 0.022691604789914468\n",
      "Epoch:\t 47 Val Loss:\t 0.022682536792542254\n",
      "Epoch:\t 48 Val Loss:\t 0.022634896247283272\n",
      "Epoch:\t 49 Val Loss:\t 0.02267852049482159\n",
      "Epoch:\t 50 Val Loss:\t 0.022679009250520264\n",
      "Epoch:\t 51 Val Loss:\t 0.02259242396739759\n",
      "Epoch:\t 52 Val Loss:\t 0.022641216075013144\n",
      "Epoch:\t 53 Val Loss:\t 0.02267083367812379\n",
      "Epoch:\t 54 Val Loss:\t 0.02262488960644312\n",
      "Epoch:\t 55 Val Loss:\t 0.02267018782672424\n",
      "Epoch:\t 56 Val Loss:\t 0.022603992257058992\n",
      "Epoch:\t 57 Val Loss:\t 0.022618776197190504\n",
      "Epoch:\t 58 Val Loss:\t 0.022693963060829138\n",
      "Epoch:\t 59 Val Loss:\t 0.022654838324305208\n",
      "Epoch:\t 60 Val Loss:\t 0.02269863274916514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 17:46:16,020] Trial 1 finished with value: 0.02259242396739759 and parameters: {'lr': 1e-06, 'weight_decay': 1e-06, 'scheduler_factor': 0.5, 'scheduler_patience': 5, 'batch_size': 16, 'dropout': 0.15, 'hidden_dims': 1024}. Best is trial 0 with value: 0.02188237255792526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 61 Val Loss:\t 0.022628333229602185\n",
      "Epoch:\t 0 Val Loss:\t 0.02219414884497025\n",
      "Epoch:\t 1 Val Loss:\t 0.021850959884977053\n",
      "Epoch:\t 2 Val Loss:\t 0.021826628825528348\n",
      "Epoch:\t 3 Val Loss:\t 0.02191362922380348\n",
      "Epoch:\t 4 Val Loss:\t 0.021959498014398112\n",
      "Epoch:\t 5 Val Loss:\t 0.022060039293819774\n",
      "Epoch:\t 6 Val Loss:\t 0.022005184110858757\n",
      "Epoch:\t 7 Val Loss:\t 0.021996985874577372\n",
      "Epoch:\t 8 Val Loss:\t 0.0219417892366588\n",
      "Epoch:\t 9 Val Loss:\t 0.02194705655525825\n",
      "Epoch:\t 10 Val Loss:\t 0.021919312561024168\n",
      "Epoch:\t 11 Val Loss:\t 0.021890166520564733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 17:48:55,759] Trial 2 finished with value: 0.021826628825528348 and parameters: {'lr': 1e-05, 'weight_decay': 0.0001, 'scheduler_factor': 0.1, 'scheduler_patience': 5, 'batch_size': 32, 'dropout': 0.05, 'hidden_dims': 1024}. Best is trial 2 with value: 0.021826628825528348.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 12 Val Loss:\t 0.021909794531658082\n",
      "Epoch:\t 0 Val Loss:\t 0.02403851928276101\n",
      "Epoch:\t 1 Val Loss:\t 0.02337002514429498\n",
      "Epoch:\t 2 Val Loss:\t 0.02298610092381413\n",
      "Epoch:\t 3 Val Loss:\t 0.02272551339029979\n",
      "Epoch:\t 4 Val Loss:\t 0.02255257459456044\n",
      "Epoch:\t 5 Val Loss:\t 0.02241103835463715\n",
      "Epoch:\t 6 Val Loss:\t 0.022334927166804647\n",
      "Epoch:\t 7 Val Loss:\t 0.022251854523609768\n",
      "Epoch:\t 8 Val Loss:\t 0.022194679644120256\n",
      "Epoch:\t 9 Val Loss:\t 0.022150589156160385\n",
      "Epoch:\t 10 Val Loss:\t 0.022104948929497558\n",
      "Epoch:\t 11 Val Loss:\t 0.022078951381230623\n",
      "Epoch:\t 12 Val Loss:\t 0.022067241257065565\n",
      "Epoch:\t 13 Val Loss:\t 0.02202859479652936\n",
      "Epoch:\t 14 Val Loss:\t 0.0220035147579629\n",
      "Epoch:\t 15 Val Loss:\t 0.021997222990802166\n",
      "Epoch:\t 16 Val Loss:\t 0.02199314378297635\n",
      "Epoch:\t 17 Val Loss:\t 0.021969475195912067\n",
      "Epoch:\t 18 Val Loss:\t 0.021945298310028415\n",
      "Epoch:\t 19 Val Loss:\t 0.02193745904950422\n",
      "Epoch:\t 20 Val Loss:\t 0.021924464848269237\n",
      "Epoch:\t 21 Val Loss:\t 0.021899654008268737\n",
      "Epoch:\t 22 Val Loss:\t 0.02189060530205217\n",
      "Epoch:\t 23 Val Loss:\t 0.021874007907954685\n",
      "Epoch:\t 24 Val Loss:\t 0.021860606295697953\n",
      "Epoch:\t 25 Val Loss:\t 0.0218461107247379\n",
      "Epoch:\t 26 Val Loss:\t 0.021847413592698296\n",
      "Epoch:\t 27 Val Loss:\t 0.021825142234659502\n",
      "Epoch:\t 28 Val Loss:\t 0.021835715116792467\n",
      "Epoch:\t 29 Val Loss:\t 0.0218069502309467\n",
      "Epoch:\t 30 Val Loss:\t 0.02180431599027655\n",
      "Epoch:\t 31 Val Loss:\t 0.021799158642777088\n",
      "Epoch:\t 32 Val Loss:\t 0.021795743083757726\n",
      "Epoch:\t 33 Val Loss:\t 0.021791373297309034\n",
      "Epoch:\t 34 Val Loss:\t 0.02178255601653031\n",
      "Epoch:\t 35 Val Loss:\t 0.02177009519255372\n",
      "Epoch:\t 36 Val Loss:\t 0.02178127518339295\n",
      "Epoch:\t 37 Val Loss:\t 0.02175689987048961\n",
      "Epoch:\t 38 Val Loss:\t 0.02175094425247722\n",
      "Epoch:\t 39 Val Loss:\t 0.02174463200518924\n",
      "Epoch:\t 40 Val Loss:\t 0.02174291517555618\n",
      "Epoch:\t 41 Val Loss:\t 0.021753052109030238\n",
      "Epoch:\t 42 Val Loss:\t 0.021740083990806944\n",
      "Epoch:\t 43 Val Loss:\t 0.02174207405224562\n",
      "Epoch:\t 44 Val Loss:\t 0.021744102700037904\n",
      "Epoch:\t 45 Val Loss:\t 0.021739101725036986\n",
      "Epoch:\t 46 Val Loss:\t 0.021744204936235138\n",
      "Epoch:\t 47 Val Loss:\t 0.02173274407764212\n",
      "Epoch:\t 48 Val Loss:\t 0.02174437994116478\n",
      "Epoch:\t 49 Val Loss:\t 0.021729003416783927\n",
      "Epoch:\t 50 Val Loss:\t 0.021742251191892173\n",
      "Epoch:\t 51 Val Loss:\t 0.02173071811468988\n",
      "Epoch:\t 52 Val Loss:\t 0.021734825973765234\n",
      "Epoch:\t 53 Val Loss:\t 0.021735290187989538\n",
      "Epoch:\t 54 Val Loss:\t 0.021730487944967864\n",
      "Epoch:\t 55 Val Loss:\t 0.021733824719778035\n",
      "Epoch:\t 56 Val Loss:\t 0.02172669172765355\n",
      "Epoch:\t 57 Val Loss:\t 0.02173042724904624\n",
      "Epoch:\t 58 Val Loss:\t 0.02173349273243073\n",
      "Epoch:\t 59 Val Loss:\t 0.021736344636491177\n",
      "Epoch:\t 60 Val Loss:\t 0.021735964794411512\n",
      "Epoch:\t 61 Val Loss:\t 0.021732218638301663\n",
      "Epoch:\t 62 Val Loss:\t 0.021738475834409653\n",
      "Epoch:\t 63 Val Loss:\t 0.021737889101187645\n",
      "Epoch:\t 64 Val Loss:\t 0.02173189649038483\n",
      "Epoch:\t 65 Val Loss:\t 0.021740476309320324\n",
      "Epoch:\t 66 Val Loss:\t 0.021726521844250623\n",
      "Epoch:\t 67 Val Loss:\t 0.021733620531414522\n",
      "Epoch:\t 68 Val Loss:\t 0.021741513838546042\n",
      "Epoch:\t 69 Val Loss:\t 0.02173409810406343\n",
      "Epoch:\t 70 Val Loss:\t 0.021733758223645185\n",
      "Epoch:\t 71 Val Loss:\t 0.021732920368185586\n",
      "Epoch:\t 72 Val Loss:\t 0.021735175789287537\n",
      "Epoch:\t 73 Val Loss:\t 0.021733587171230615\n",
      "Epoch:\t 74 Val Loss:\t 0.021732759322630267\n",
      "Epoch:\t 75 Val Loss:\t 0.021729792780683856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 17:54:11,155] Trial 3 finished with value: 0.021726521844250623 and parameters: {'lr': 1e-05, 'weight_decay': 1e-06, 'scheduler_factor': 0.3, 'scheduler_patience': 5, 'batch_size': 128, 'dropout': 0.1, 'hidden_dims': 1024}. Best is trial 3 with value: 0.021726521844250623.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 76 Val Loss:\t 0.021736924448327116\n",
      "Epoch:\t 0 Val Loss:\t 0.021654095503697426\n",
      "Epoch:\t 1 Val Loss:\t 0.0216718078747894\n",
      "Epoch:\t 2 Val Loss:\t 0.02166805255195398\n",
      "Epoch:\t 3 Val Loss:\t 0.021705288565560674\n",
      "Epoch:\t 4 Val Loss:\t 0.021674452041594214\n",
      "Epoch:\t 5 Val Loss:\t 0.02165104422485082\n",
      "Epoch:\t 6 Val Loss:\t 0.02165835960372015\n",
      "Epoch:\t 7 Val Loss:\t 0.021652421595627386\n",
      "Epoch:\t 8 Val Loss:\t 0.021680982053925674\n",
      "Epoch:\t 9 Val Loss:\t 0.02164287937515046\n",
      "Epoch:\t 10 Val Loss:\t 0.021687348494321156\n",
      "Epoch:\t 11 Val Loss:\t 0.021686796092967926\n",
      "Epoch:\t 12 Val Loss:\t 0.02165872874530705\n",
      "Epoch:\t 13 Val Loss:\t 0.021673106951683903\n",
      "Epoch:\t 14 Val Loss:\t 0.02168741990867434\n",
      "Epoch:\t 15 Val Loss:\t 0.02168752999010572\n",
      "Epoch:\t 16 Val Loss:\t 0.021570803161058725\n",
      "Epoch:\t 17 Val Loss:\t 0.02159809052382101\n",
      "Epoch:\t 18 Val Loss:\t 0.021553643594942926\n",
      "Epoch:\t 19 Val Loss:\t 0.021562416510085423\n",
      "Epoch:\t 20 Val Loss:\t 0.02157026395070132\n",
      "Epoch:\t 21 Val Loss:\t 0.021570652953526948\n",
      "Epoch:\t 22 Val Loss:\t 0.021586076776537427\n",
      "Epoch:\t 23 Val Loss:\t 0.021570182116896534\n",
      "Epoch:\t 24 Val Loss:\t 0.021571932267846112\n",
      "Epoch:\t 25 Val Loss:\t 0.02152689585812019\n",
      "Epoch:\t 26 Val Loss:\t 0.02153640211130796\n",
      "Epoch:\t 27 Val Loss:\t 0.021533534878544976\n",
      "Epoch:\t 28 Val Loss:\t 0.021541610662115327\n",
      "Epoch:\t 29 Val Loss:\t 0.021548153079125318\n",
      "Epoch:\t 30 Val Loss:\t 0.021530572094776657\n",
      "Epoch:\t 31 Val Loss:\t 0.021524296496452145\n",
      "Epoch:\t 32 Val Loss:\t 0.021535961393918692\n",
      "Epoch:\t 33 Val Loss:\t 0.0215270450969569\n",
      "Epoch:\t 34 Val Loss:\t 0.02153419924490333\n",
      "Epoch:\t 35 Val Loss:\t 0.021519405010902288\n",
      "Epoch:\t 36 Val Loss:\t 0.021540494731374767\n",
      "Epoch:\t 37 Val Loss:\t 0.021534528807523164\n",
      "Epoch:\t 38 Val Loss:\t 0.021535009821431403\n",
      "Epoch:\t 39 Val Loss:\t 0.021539728338105146\n",
      "Epoch:\t 40 Val Loss:\t 0.02152600460184998\n",
      "Epoch:\t 41 Val Loss:\t 0.0215307886489513\n",
      "Epoch:\t 42 Val Loss:\t 0.02151961185121804\n",
      "Epoch:\t 43 Val Loss:\t 0.021515640057922367\n",
      "Epoch:\t 44 Val Loss:\t 0.021525945906104283\n",
      "Epoch:\t 45 Val Loss:\t 0.02151706416225644\n",
      "Epoch:\t 46 Val Loss:\t 0.021515676760702224\n",
      "Epoch:\t 47 Val Loss:\t 0.02151773620940996\n",
      "Epoch:\t 48 Val Loss:\t 0.021516650900196877\n",
      "Epoch:\t 49 Val Loss:\t 0.021512556055719168\n",
      "Epoch:\t 50 Val Loss:\t 0.021526705243446853\n",
      "Epoch:\t 51 Val Loss:\t 0.021516028340206293\n",
      "Epoch:\t 52 Val Loss:\t 0.021522818082408385\n",
      "Epoch:\t 53 Val Loss:\t 0.02151421873709172\n",
      "Epoch:\t 54 Val Loss:\t 0.02152398240305543\n",
      "Epoch:\t 55 Val Loss:\t 0.021518285815300565\n",
      "Epoch:\t 56 Val Loss:\t 0.02151690016277912\n",
      "Epoch:\t 57 Val Loss:\t 0.021515622998125865\n",
      "Epoch:\t 58 Val Loss:\t 0.02151636816680814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 17:58:06,272] Trial 4 finished with value: 0.021512556055719168 and parameters: {'lr': 0.001, 'weight_decay': 0.0001, 'scheduler_factor': 0.3, 'scheduler_patience': 5, 'batch_size': 128, 'dropout': 0.1, 'hidden_dims': 64}. Best is trial 4 with value: 0.021512556055719168.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 59 Val Loss:\t 0.02151826558631649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 17:58:10,286] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.04336186060098928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 17:58:15,421] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.025026168807169964\n",
      "Epoch:\t 0 Val Loss:\t 0.022217286781282847\n",
      "Epoch:\t 1 Val Loss:\t 0.02183910640990567\n",
      "Epoch:\t 2 Val Loss:\t 0.02178838512522424\n",
      "Epoch:\t 3 Val Loss:\t 0.021922387626163945\n",
      "Epoch:\t 4 Val Loss:\t 0.021958997856847986\n",
      "Epoch:\t 5 Val Loss:\t 0.02200372163616942\n",
      "Epoch:\t 6 Val Loss:\t 0.021948471159220696\n",
      "Epoch:\t 7 Val Loss:\t 0.02195195197491703\n",
      "Epoch:\t 8 Val Loss:\t 0.02199310453044986\n",
      "Epoch:\t 9 Val Loss:\t 0.021852954748069833\n",
      "Epoch:\t 10 Val Loss:\t 0.021664115846276522\n",
      "Epoch:\t 11 Val Loss:\t 0.021563776264075407\n",
      "Epoch:\t 12 Val Loss:\t 0.021523054170315872\n",
      "Epoch:\t 13 Val Loss:\t 0.02152638487435713\n",
      "Epoch:\t 14 Val Loss:\t 0.021532184254370614\n",
      "Epoch:\t 15 Val Loss:\t 0.021525469558959256\n",
      "Epoch:\t 16 Val Loss:\t 0.021521246266777146\n",
      "Epoch:\t 17 Val Loss:\t 0.021521724630632476\n",
      "Epoch:\t 18 Val Loss:\t 0.02153764351948588\n",
      "Epoch:\t 19 Val Loss:\t 0.021538297120175645\n",
      "Epoch:\t 20 Val Loss:\t 0.021539954795970588\n",
      "Epoch:\t 21 Val Loss:\t 0.02152344776440658\n",
      "Epoch:\t 22 Val Loss:\t 0.021522614103415327\n",
      "Epoch:\t 23 Val Loss:\t 0.021525565436658615\n",
      "Epoch:\t 24 Val Loss:\t 0.021509743031704116\n",
      "Epoch:\t 25 Val Loss:\t 0.021511065380979993\n",
      "Epoch:\t 26 Val Loss:\t 0.021506422932422112\n",
      "Epoch:\t 27 Val Loss:\t 0.02150700159281313\n",
      "Epoch:\t 28 Val Loss:\t 0.021504428090606043\n",
      "Epoch:\t 29 Val Loss:\t 0.02150673216473841\n",
      "Epoch:\t 30 Val Loss:\t 0.021504281908423007\n",
      "Epoch:\t 31 Val Loss:\t 0.021510155506820262\n",
      "Epoch:\t 32 Val Loss:\t 0.021508508006890935\n",
      "Epoch:\t 33 Val Loss:\t 0.021509555996375117\n",
      "Epoch:\t 34 Val Loss:\t 0.021509457231762414\n",
      "Epoch:\t 35 Val Loss:\t 0.021506687815493357\n",
      "Epoch:\t 36 Val Loss:\t 0.02150385275124787\n",
      "Epoch:\t 37 Val Loss:\t 0.021512235840689203\n",
      "Epoch:\t 38 Val Loss:\t 0.021505024357659663\n",
      "Epoch:\t 39 Val Loss:\t 0.021516998040532778\n",
      "Epoch:\t 40 Val Loss:\t 0.02151501513420341\n",
      "Epoch:\t 41 Val Loss:\t 0.02150545551857812\n",
      "Epoch:\t 42 Val Loss:\t 0.02150949790051024\n",
      "Epoch:\t 43 Val Loss:\t 0.02150553972917592\n",
      "Epoch:\t 44 Val Loss:\t 0.021513325537747156\n",
      "Epoch:\t 45 Val Loss:\t 0.02150440848020012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:07:36,430] Trial 7 finished with value: 0.02150385275124787 and parameters: {'lr': 1e-05, 'weight_decay': 0.0001, 'scheduler_factor': 0.1, 'scheduler_patience': 10, 'batch_size': 32, 'dropout': 0.1, 'hidden_dims': 1024}. Best is trial 7 with value: 0.02150385275124787.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 46 Val Loss:\t 0.02151000973524037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:07:49,528] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.035764350271271554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:07:54,477] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.02739547396641831\n",
      "Epoch:\t 0 Val Loss:\t 0.021697345982960803\n",
      "Epoch:\t 1 Val Loss:\t 0.021627451968425977\n",
      "Epoch:\t 2 Val Loss:\t 0.021618027023911357\n",
      "Epoch:\t 3 Val Loss:\t 0.021617311707330132\n",
      "Epoch:\t 4 Val Loss:\t 0.021602929040849327\n",
      "Epoch:\t 5 Val Loss:\t 0.021600856534942595\n",
      "Epoch:\t 6 Val Loss:\t 0.021606406239505282\n",
      "Epoch:\t 7 Val Loss:\t 0.02152772158354461\n",
      "Epoch:\t 8 Val Loss:\t 0.021522910255781992\n",
      "Epoch:\t 9 Val Loss:\t 0.021520947055417097\n",
      "Epoch:\t 10 Val Loss:\t 0.02152038139994732\n",
      "Epoch:\t 11 Val Loss:\t 0.021530850575807576\n",
      "Epoch:\t 12 Val Loss:\t 0.021527383027818495\n",
      "Epoch:\t 13 Val Loss:\t 0.021516536276989087\n",
      "Epoch:\t 14 Val Loss:\t 0.021510681371113102\n",
      "Epoch:\t 15 Val Loss:\t 0.021510878575588754\n",
      "Epoch:\t 16 Val Loss:\t 0.0215123491029522\n",
      "Epoch:\t 17 Val Loss:\t 0.021512225848475175\n",
      "Epoch:\t 18 Val Loss:\t 0.021511214404536752\n",
      "Epoch:\t 19 Val Loss:\t 0.02150885486501252\n",
      "Epoch:\t 20 Val Loss:\t 0.021521569733211177\n",
      "Epoch:\t 21 Val Loss:\t 0.021508002442444017\n",
      "Epoch:\t 22 Val Loss:\t 0.021522491469322322\n",
      "Epoch:\t 23 Val Loss:\t 0.021509550037777016\n",
      "Epoch:\t 24 Val Loss:\t 0.021506136030944173\n",
      "Epoch:\t 25 Val Loss:\t 0.02151178832694082\n",
      "Epoch:\t 26 Val Loss:\t 0.021512997178790086\n",
      "Epoch:\t 27 Val Loss:\t 0.02152093337934636\n",
      "Epoch:\t 28 Val Loss:\t 0.021509372781894968\n",
      "Epoch:\t 29 Val Loss:\t 0.021509897843645306\n",
      "Epoch:\t 30 Val Loss:\t 0.021517413474977733\n",
      "Epoch:\t 31 Val Loss:\t 0.021527154431613033\n",
      "Epoch:\t 32 Val Loss:\t 0.021517898552567662\n",
      "Epoch:\t 33 Val Loss:\t 0.02151911869898946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:12:52,190] Trial 10 finished with value: 0.021506136030944173 and parameters: {'lr': 0.0001, 'weight_decay': 0.0001, 'scheduler_factor': 0.1, 'scheduler_patience': 1, 'batch_size': 32, 'dropout': 0.2, 'hidden_dims': 512}. Best is trial 7 with value: 0.02150385275124787.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 34 Val Loss:\t 0.02151176398153415\n",
      "Epoch:\t 0 Val Loss:\t 0.0218156777755292\n",
      "Epoch:\t 1 Val Loss:\t 0.021634153232262105\n",
      "Epoch:\t 2 Val Loss:\t 0.021614351525962472\n",
      "Epoch:\t 3 Val Loss:\t 0.021608904725638683\n",
      "Epoch:\t 4 Val Loss:\t 0.02160484697109831\n",
      "Epoch:\t 5 Val Loss:\t 0.021604255196043032\n",
      "Epoch:\t 6 Val Loss:\t 0.021590351948294347\n",
      "Epoch:\t 7 Val Loss:\t 0.021608668703115536\n",
      "Epoch:\t 8 Val Loss:\t 0.021595538604280394\n",
      "Epoch:\t 9 Val Loss:\t 0.021519561522156897\n",
      "Epoch:\t 10 Val Loss:\t 0.021524903767243895\n",
      "Epoch:\t 11 Val Loss:\t 0.0215170341295625\n",
      "Epoch:\t 12 Val Loss:\t 0.021531513247467233\n",
      "Epoch:\t 13 Val Loss:\t 0.021521921557764372\n",
      "Epoch:\t 14 Val Loss:\t 0.021514433651849\n",
      "Epoch:\t 15 Val Loss:\t 0.021506658043779568\n",
      "Epoch:\t 16 Val Loss:\t 0.021516084167098472\n",
      "Epoch:\t 17 Val Loss:\t 0.021513962320878894\n",
      "Epoch:\t 18 Val Loss:\t 0.021511484637020347\n",
      "Epoch:\t 19 Val Loss:\t 0.02151317753733877\n",
      "Epoch:\t 20 Val Loss:\t 0.021513908363520382\n",
      "Epoch:\t 21 Val Loss:\t 0.02151491571374551\n",
      "Epoch:\t 22 Val Loss:\t 0.021521125992532364\n",
      "Epoch:\t 23 Val Loss:\t 0.02151641509568464\n",
      "Epoch:\t 24 Val Loss:\t 0.0215147274663907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:16:08,355] Trial 11 finished with value: 0.021506658043779568 and parameters: {'lr': 0.0001, 'weight_decay': 0.0001, 'scheduler_factor': 0.1, 'scheduler_patience': 1, 'batch_size': 32, 'dropout': 0.2, 'hidden_dims': 512}. Best is trial 7 with value: 0.02150385275124787.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 25 Val Loss:\t 0.02151870805964262\n",
      "Epoch:\t 0 Val Loss:\t 0.021801717578618224\n",
      "Epoch:\t 1 Val Loss:\t 0.02162358822872142\n",
      "Epoch:\t 2 Val Loss:\t 0.021593310954963755\n",
      "Epoch:\t 3 Val Loss:\t 0.021629716208827997\n",
      "Epoch:\t 4 Val Loss:\t 0.021603577779997923\n",
      "Epoch:\t 5 Val Loss:\t 0.021588780041149478\n",
      "Epoch:\t 6 Val Loss:\t 0.02159215324709494\n",
      "Epoch:\t 7 Val Loss:\t 0.021589208482382053\n",
      "Epoch:\t 8 Val Loss:\t 0.02159305390993316\n",
      "Epoch:\t 9 Val Loss:\t 0.02157691695945774\n",
      "Epoch:\t 10 Val Loss:\t 0.021592491651271174\n",
      "Epoch:\t 11 Val Loss:\t 0.02157286931620631\n",
      "Epoch:\t 12 Val Loss:\t 0.021605394952715875\n",
      "Epoch:\t 13 Val Loss:\t 0.021584331517467997\n",
      "Epoch:\t 14 Val Loss:\t 0.021568800839698147\n",
      "Epoch:\t 15 Val Loss:\t 0.021574783926542274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:18:28,945] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 16 Val Loss:\t 0.021588793347677392\n",
      "Epoch:\t 0 Val Loss:\t 0.021946077865505505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:18:46,476] Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 1 Val Loss:\t 0.021874733588365253\n",
      "Epoch:\t 0 Val Loss:\t 0.02159257049155319\n",
      "Epoch:\t 1 Val Loss:\t 0.02152865741043566\n",
      "Epoch:\t 2 Val Loss:\t 0.021524919110363375\n",
      "Epoch:\t 3 Val Loss:\t 0.021513110749005436\n",
      "Epoch:\t 4 Val Loss:\t 0.021504695368613415\n",
      "Epoch:\t 5 Val Loss:\t 0.02149558985952982\n",
      "Epoch:\t 6 Val Loss:\t 0.021501876245101612\n",
      "Epoch:\t 7 Val Loss:\t 0.02149843836654881\n",
      "Epoch:\t 8 Val Loss:\t 0.021491869666309418\n",
      "Epoch:\t 9 Val Loss:\t 0.021495312217152666\n",
      "Epoch:\t 10 Val Loss:\t 0.02149607712414138\n",
      "Epoch:\t 11 Val Loss:\t 0.02149547294215234\n",
      "Epoch:\t 12 Val Loss:\t 0.02149513981721265\n",
      "Epoch:\t 13 Val Loss:\t 0.02149104709832188\n",
      "Epoch:\t 14 Val Loss:\t 0.021489730338101278\n",
      "Epoch:\t 15 Val Loss:\t 0.02148439470447137\n",
      "Epoch:\t 16 Val Loss:\t 0.02148678165548789\n",
      "Epoch:\t 17 Val Loss:\t 0.02148634105592309\n",
      "Epoch:\t 18 Val Loss:\t 0.021484052926257165\n",
      "Epoch:\t 19 Val Loss:\t 0.021482893302364792\n",
      "Epoch:\t 20 Val Loss:\t 0.021483237784960585\n",
      "Epoch:\t 21 Val Loss:\t 0.021481251300411498\n",
      "Epoch:\t 22 Val Loss:\t 0.021484249423002314\n",
      "Epoch:\t 23 Val Loss:\t 0.021485987949168277\n",
      "Epoch:\t 24 Val Loss:\t 0.02148410737895237\n",
      "Epoch:\t 25 Val Loss:\t 0.02148303119596355\n",
      "Epoch:\t 26 Val Loss:\t 0.021482116084374146\n",
      "Epoch:\t 27 Val Loss:\t 0.02148580689856667\n",
      "Epoch:\t 28 Val Loss:\t 0.021479589097157033\n",
      "Epoch:\t 29 Val Loss:\t 0.02148716445668845\n",
      "Epoch:\t 30 Val Loss:\t 0.021481618801792543\n",
      "Epoch:\t 31 Val Loss:\t 0.021486759409756365\n",
      "Epoch:\t 32 Val Loss:\t 0.021481409280342544\n",
      "Epoch:\t 33 Val Loss:\t 0.02147992592760341\n",
      "Epoch:\t 34 Val Loss:\t 0.021480631244131822\n",
      "Epoch:\t 35 Val Loss:\t 0.02147636453514706\n",
      "Epoch:\t 36 Val Loss:\t 0.02148173982594797\n",
      "Epoch:\t 37 Val Loss:\t 0.021478086052264624\n",
      "Epoch:\t 38 Val Loss:\t 0.021479166379732215\n",
      "Epoch:\t 39 Val Loss:\t 0.02148059795168275\n",
      "Epoch:\t 40 Val Loss:\t 0.021481466304159952\n",
      "Epoch:\t 41 Val Loss:\t 0.021483909957603606\n",
      "Epoch:\t 42 Val Loss:\t 0.021482551313623158\n",
      "Epoch:\t 43 Val Loss:\t 0.02147987292321746\n",
      "Epoch:\t 44 Val Loss:\t 0.021480862207651018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:24:33,897] Trial 14 finished with value: 0.02147636453514706 and parameters: {'lr': 0.0001, 'weight_decay': 1e-05, 'scheduler_factor': 0.8, 'scheduler_patience': 1, 'batch_size': 32, 'dropout': 0.1, 'hidden_dims': 64}. Best is trial 14 with value: 0.02147636453514706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 45 Val Loss:\t 0.02147936573726142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:24:37,908] Trial 15 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.026733194432937063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:24:45,344] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.05712279453425704\n",
      "Epoch:\t 0 Val Loss:\t 0.021881521474905984\n",
      "Epoch:\t 1 Val Loss:\t 0.02174233532882107\n",
      "Epoch:\t 2 Val Loss:\t 0.02170442237307827\n",
      "Epoch:\t 3 Val Loss:\t 0.021675476871565253\n",
      "Epoch:\t 4 Val Loss:\t 0.021681047256714953\n",
      "Epoch:\t 5 Val Loss:\t 0.021654951612731975\n",
      "Epoch:\t 6 Val Loss:\t 0.02165642046520789\n",
      "Epoch:\t 7 Val Loss:\t 0.021672116663822072\n",
      "Epoch:\t 8 Val Loss:\t 0.021643345554420847\n",
      "Epoch:\t 9 Val Loss:\t 0.021640259942752805\n",
      "Epoch:\t 10 Val Loss:\t 0.021637778430579898\n",
      "Epoch:\t 11 Val Loss:\t 0.021624857717322442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:26:23,266] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 12 Val Loss:\t 0.021624294800575605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:26:30,804] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.026781622310708426\n",
      "Epoch:\t 0 Val Loss:\t 0.022070780917763138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:26:44,366] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 1 Val Loss:\t 0.02204186754613374\n",
      "Epoch:\t 0 Val Loss:\t 0.021871066704673082\n",
      "Epoch:\t 1 Val Loss:\t 0.021596678570539887\n",
      "Epoch:\t 2 Val Loss:\t 0.021590928165673123\n",
      "Epoch:\t 3 Val Loss:\t 0.021592136140874706\n",
      "Epoch:\t 4 Val Loss:\t 0.021581328422670087\n",
      "Epoch:\t 5 Val Loss:\t 0.021586741063280315\n",
      "Epoch:\t 6 Val Loss:\t 0.02158232564261462\n",
      "Epoch:\t 7 Val Loss:\t 0.021547138676580257\n",
      "Epoch:\t 8 Val Loss:\t 0.02154540757593973\n",
      "Epoch:\t 9 Val Loss:\t 0.021548070081445644\n",
      "Epoch:\t 10 Val Loss:\t 0.02154148195966693\n",
      "Epoch:\t 11 Val Loss:\t 0.021542387838344598\n",
      "Epoch:\t 12 Val Loss:\t 0.021547144934411126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:33:47,178] Trial 20 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 13 Val Loss:\t 0.021543083309774957\n",
      "Epoch:\t 0 Val Loss:\t 0.021848146643168583\n",
      "Epoch:\t 1 Val Loss:\t 0.021636230831140864\n",
      "Epoch:\t 2 Val Loss:\t 0.021611979770994855\n",
      "Epoch:\t 3 Val Loss:\t 0.021599785964525414\n",
      "Epoch:\t 4 Val Loss:\t 0.021599069761414687\n",
      "Epoch:\t 5 Val Loss:\t 0.02160954237178356\n",
      "Epoch:\t 6 Val Loss:\t 0.02153568530906895\n",
      "Epoch:\t 7 Val Loss:\t 0.02152364001476872\n",
      "Epoch:\t 8 Val Loss:\t 0.021522255539744795\n",
      "Epoch:\t 9 Val Loss:\t 0.021517502783400144\n",
      "Epoch:\t 10 Val Loss:\t 0.021529001190526812\n",
      "Epoch:\t 11 Val Loss:\t 0.02152142935695653\n",
      "Epoch:\t 12 Val Loss:\t 0.021509642728449466\n",
      "Epoch:\t 13 Val Loss:\t 0.021515859222274746\n",
      "Epoch:\t 14 Val Loss:\t 0.021511994566925183\n",
      "Epoch:\t 15 Val Loss:\t 0.021512145895085377\n",
      "Epoch:\t 16 Val Loss:\t 0.021525667751122093\n",
      "Epoch:\t 17 Val Loss:\t 0.021512028565238376\n",
      "Epoch:\t 18 Val Loss:\t 0.021517944838366432\n",
      "Epoch:\t 19 Val Loss:\t 0.021506165140467083\n",
      "Epoch:\t 20 Val Loss:\t 0.02150583457694443\n",
      "Epoch:\t 21 Val Loss:\t 0.021514314460103403\n",
      "Epoch:\t 22 Val Loss:\t 0.02152819991529824\n",
      "Epoch:\t 23 Val Loss:\t 0.02151725029382474\n",
      "Epoch:\t 24 Val Loss:\t 0.02151839229798986\n",
      "Epoch:\t 25 Val Loss:\t 0.02151615536418969\n",
      "Epoch:\t 26 Val Loss:\t 0.021512923751377273\n",
      "Epoch:\t 27 Val Loss:\t 0.02151068848201292\n",
      "Epoch:\t 28 Val Loss:\t 0.021516810921963326\n",
      "Epoch:\t 29 Val Loss:\t 0.021510269734747185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:38:13,831] Trial 21 finished with value: 0.02150583457694443 and parameters: {'lr': 0.0001, 'weight_decay': 0.0001, 'scheduler_factor': 0.1, 'scheduler_patience': 1, 'batch_size': 32, 'dropout': 0.2, 'hidden_dims': 512}. Best is trial 14 with value: 0.02147636453514706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 30 Val Loss:\t 0.021507585041583302\n",
      "Epoch:\t 0 Val Loss:\t 0.021589378271259382\n",
      "Epoch:\t 1 Val Loss:\t 0.02156668342537954\n",
      "Epoch:\t 2 Val Loss:\t 0.0215688453158569\n",
      "Epoch:\t 3 Val Loss:\t 0.021592435664040052\n",
      "Epoch:\t 4 Val Loss:\t 0.021530174108628997\n",
      "Epoch:\t 5 Val Loss:\t 0.021526138014524042\n",
      "Epoch:\t 6 Val Loss:\t 0.02151980382541497\n",
      "Epoch:\t 7 Val Loss:\t 0.021524126628760944\n",
      "Epoch:\t 8 Val Loss:\t 0.021531204956925225\n",
      "Epoch:\t 9 Val Loss:\t 0.021534561647292606\n",
      "Epoch:\t 10 Val Loss:\t 0.021523225955097734\n",
      "Epoch:\t 11 Val Loss:\t 0.021521143126254808\n",
      "Epoch:\t 12 Val Loss:\t 0.021514149134482196\n",
      "Epoch:\t 13 Val Loss:\t 0.021520578808604716\n",
      "Epoch:\t 14 Val Loss:\t 0.02151306539602234\n",
      "Epoch:\t 15 Val Loss:\t 0.02152528083978411\n",
      "Epoch:\t 16 Val Loss:\t 0.02152212042219653\n",
      "Epoch:\t 17 Val Loss:\t 0.021525070313102974\n",
      "Epoch:\t 18 Val Loss:\t 0.02152213294857848\n",
      "Epoch:\t 19 Val Loss:\t 0.02152166521635825\n",
      "Epoch:\t 20 Val Loss:\t 0.021517914369373857\n",
      "Epoch:\t 21 Val Loss:\t 0.02151814692901944\n",
      "Epoch:\t 22 Val Loss:\t 0.02151713456980929\n",
      "Epoch:\t 23 Val Loss:\t 0.021522972757418553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:41:21,780] Trial 22 finished with value: 0.02151306539602234 and parameters: {'lr': 0.0001, 'weight_decay': 0.0001, 'scheduler_factor': 0.1, 'scheduler_patience': 1, 'batch_size': 32, 'dropout': 0.2, 'hidden_dims': 64}. Best is trial 14 with value: 0.02147636453514706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 24 Val Loss:\t 0.02151995940182455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:41:30,735] Trial 23 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.02192307153645761\n",
      "Epoch:\t 0 Val Loss:\t 0.021824397721666233\n",
      "Epoch:\t 1 Val Loss:\t 0.021608126831878804\n",
      "Epoch:\t 2 Val Loss:\t 0.021552122811939554\n",
      "Epoch:\t 3 Val Loss:\t 0.02155024925444479\n",
      "Epoch:\t 4 Val Loss:\t 0.02151956297816571\n",
      "Epoch:\t 5 Val Loss:\t 0.02153360420820031\n",
      "Epoch:\t 6 Val Loss:\t 0.021523665343306457\n",
      "Epoch:\t 7 Val Loss:\t 0.021553485297936336\n",
      "Epoch:\t 8 Val Loss:\t 0.021538410233962576\n",
      "Epoch:\t 9 Val Loss:\t 0.021522151893214398\n",
      "Epoch:\t 10 Val Loss:\t 0.02152304554364114\n",
      "Epoch:\t 11 Val Loss:\t 0.021531408329245744\n",
      "Epoch:\t 12 Val Loss:\t 0.021539407617553255\n",
      "Epoch:\t 13 Val Loss:\t 0.02153783396389515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:42:25,134] Trial 24 finished with value: 0.02151956297816571 and parameters: {'lr': 0.0001, 'weight_decay': 0.0001, 'scheduler_factor': 0.1, 'scheduler_patience': 10, 'batch_size': 256, 'dropout': 0.1, 'hidden_dims': 256}. Best is trial 14 with value: 0.02147636453514706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 14 Val Loss:\t 0.021543288549522113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:42:37,139] Trial 25 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.022260065915021963\n",
      "Epoch:\t 0 Val Loss:\t 0.021672908262627754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:42:51,483] Trial 26 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 1 Val Loss:\t 0.021672614812403023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:42:59,732] Trial 27 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.033483165855666915\n",
      "Epoch:\t 0 Val Loss:\t 0.021563837430505214\n",
      "Epoch:\t 1 Val Loss:\t 0.021582895783494732\n",
      "Epoch:\t 2 Val Loss:\t 0.021570414297267766\n",
      "Epoch:\t 3 Val Loss:\t 0.021557909528349708\n",
      "Epoch:\t 4 Val Loss:\t 0.021557525095561584\n",
      "Epoch:\t 5 Val Loss:\t 0.021564883466265006\n",
      "Epoch:\t 6 Val Loss:\t 0.021556053253521543\n",
      "Epoch:\t 7 Val Loss:\t 0.021562621428935464\n",
      "Epoch:\t 8 Val Loss:\t 0.02159116966407261\n",
      "Epoch:\t 9 Val Loss:\t 0.021545731691356172\n",
      "Epoch:\t 10 Val Loss:\t 0.021554059141832508\n",
      "Epoch:\t 11 Val Loss:\t 0.02156742084435447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:44:34,976] Trial 28 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 12 Val Loss:\t 0.021577763663444348\n",
      "Epoch:\t 0 Val Loss:\t 0.021734137255758335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:44:42,270] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 1 Val Loss:\t 0.02171899841864776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:44:47,598] Trial 30 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.023835073076576927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:44:56,851] Trial 31 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.021885181839516262\n",
      "Epoch:\t 0 Val Loss:\t 0.021752741786918207\n",
      "Epoch:\t 1 Val Loss:\t 0.021602368901272814\n",
      "Epoch:\t 2 Val Loss:\t 0.02159589485513543\n",
      "Epoch:\t 3 Val Loss:\t 0.02160707606499145\n",
      "Epoch:\t 4 Val Loss:\t 0.021620514094904213\n",
      "Epoch:\t 5 Val Loss:\t 0.02152210356283164\n",
      "Epoch:\t 6 Val Loss:\t 0.021535974209064352\n",
      "Epoch:\t 7 Val Loss:\t 0.021518705434022185\n",
      "Epoch:\t 8 Val Loss:\t 0.021520208008214085\n",
      "Epoch:\t 9 Val Loss:\t 0.02152376903560692\n",
      "Epoch:\t 10 Val Loss:\t 0.02151168674559058\n",
      "Epoch:\t 11 Val Loss:\t 0.021514224856420006\n",
      "Epoch:\t 12 Val Loss:\t 0.021516463565145562\n",
      "Epoch:\t 13 Val Loss:\t 0.02150903467148662\n",
      "Epoch:\t 14 Val Loss:\t 0.021507491666696712\n",
      "Epoch:\t 15 Val Loss:\t 0.02151030726723358\n",
      "Epoch:\t 16 Val Loss:\t 0.0215127152597946\n",
      "Epoch:\t 17 Val Loss:\t 0.021512858009335393\n",
      "Epoch:\t 18 Val Loss:\t 0.021514630509178363\n",
      "Epoch:\t 19 Val Loss:\t 0.021521788752658335\n",
      "Epoch:\t 20 Val Loss:\t 0.02151159500789069\n",
      "Epoch:\t 21 Val Loss:\t 0.021523386577073342\n",
      "Epoch:\t 22 Val Loss:\t 0.02150849981535831\n",
      "Epoch:\t 23 Val Loss:\t 0.021512650508426115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:48:34,612] Trial 32 finished with value: 0.021507491666696712 and parameters: {'lr': 0.0001, 'weight_decay': 0.0001, 'scheduler_factor': 0.1, 'scheduler_patience': 1, 'batch_size': 32, 'dropout': 0.2, 'hidden_dims': 512}. Best is trial 14 with value: 0.02147636453514706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 24 Val Loss:\t 0.021520956920717427\n",
      "Epoch:\t 0 Val Loss:\t 0.021665860956079065\n",
      "Epoch:\t 1 Val Loss:\t 0.021622148727200606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:49:39,085] Trial 33 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 2 Val Loss:\t 0.021638738852239842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:49:52,018] Trial 34 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.021876955971509994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:49:56,354] Trial 35 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.05116554473438577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:50:08,508] Trial 36 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.022222027534204637\n",
      "Epoch:\t 0 Val Loss:\t 0.02158329016970019\n",
      "Epoch:\t 1 Val Loss:\t 0.021544454245563494\n",
      "Epoch:\t 2 Val Loss:\t 0.021547045878599583\n",
      "Epoch:\t 3 Val Loss:\t 0.021537498100085206\n",
      "Epoch:\t 4 Val Loss:\t 0.021533179696332394\n",
      "Epoch:\t 5 Val Loss:\t 0.021538505199130618\n",
      "Epoch:\t 6 Val Loss:\t 0.021562910592407707\n",
      "Epoch:\t 7 Val Loss:\t 0.021528476305054816\n",
      "Epoch:\t 8 Val Loss:\t 0.021521303500758895\n",
      "Epoch:\t 9 Val Loss:\t 0.02152351900803622\n",
      "Epoch:\t 10 Val Loss:\t 0.021511258443826467\n",
      "Epoch:\t 11 Val Loss:\t 0.02151583671797049\n",
      "Epoch:\t 12 Val Loss:\t 0.021511015044241234\n",
      "Epoch:\t 13 Val Loss:\t 0.021510623828963904\n",
      "Epoch:\t 14 Val Loss:\t 0.021505915322139215\n",
      "Epoch:\t 15 Val Loss:\t 0.02151105184269468\n",
      "Epoch:\t 16 Val Loss:\t 0.021510743486723393\n",
      "Epoch:\t 17 Val Loss:\t 0.02150807296184533\n",
      "Epoch:\t 18 Val Loss:\t 0.02150578148973983\n",
      "Epoch:\t 19 Val Loss:\t 0.02150378575067172\n",
      "Epoch:\t 20 Val Loss:\t 0.021504918209024455\n",
      "Epoch:\t 21 Val Loss:\t 0.02150577531879346\n",
      "Epoch:\t 22 Val Loss:\t 0.02150501480944945\n",
      "Epoch:\t 23 Val Loss:\t 0.021504681464733128\n",
      "Epoch:\t 24 Val Loss:\t 0.021506740922410263\n",
      "Epoch:\t 25 Val Loss:\t 0.021507255670227363\n",
      "Epoch:\t 26 Val Loss:\t 0.021511412065709383\n",
      "Epoch:\t 27 Val Loss:\t 0.021508129648445697\n",
      "Epoch:\t 28 Val Loss:\t 0.021502792889051988\n",
      "Epoch:\t 29 Val Loss:\t 0.02150971951025925\n",
      "Epoch:\t 30 Val Loss:\t 0.021505744057448872\n",
      "Epoch:\t 31 Val Loss:\t 0.021507245322530955\n",
      "Epoch:\t 32 Val Loss:\t 0.021509830928131052\n",
      "Epoch:\t 33 Val Loss:\t 0.021509396764382505\n",
      "Epoch:\t 34 Val Loss:\t 0.021505753499236\n",
      "Epoch:\t 35 Val Loss:\t 0.021508261056117604\n",
      "Epoch:\t 36 Val Loss:\t 0.0215041208683392\n",
      "Epoch:\t 37 Val Loss:\t 0.021502468914367606\n",
      "Epoch:\t 38 Val Loss:\t 0.021506862885305244\n",
      "Epoch:\t 39 Val Loss:\t 0.021505693287661908\n",
      "Epoch:\t 40 Val Loss:\t 0.02151073052594214\n",
      "Epoch:\t 41 Val Loss:\t 0.021509601715144912\n",
      "Epoch:\t 42 Val Loss:\t 0.021508482854400744\n",
      "Epoch:\t 43 Val Loss:\t 0.021504779078700187\n",
      "Epoch:\t 44 Val Loss:\t 0.02150794178139819\n",
      "Epoch:\t 45 Val Loss:\t 0.021506032650844817\n",
      "Epoch:\t 46 Val Loss:\t 0.021506179354331467\n",
      "Epoch:\t 47 Val Loss:\t 0.021502226997722976\n",
      "Epoch:\t 48 Val Loss:\t 0.021508696385887996\n",
      "Epoch:\t 49 Val Loss:\t 0.021502505808494637\n",
      "Epoch:\t 50 Val Loss:\t 0.02151055721921867\n",
      "Epoch:\t 51 Val Loss:\t 0.021502741527284704\n",
      "Epoch:\t 52 Val Loss:\t 0.021499393911461193\n",
      "Epoch:\t 53 Val Loss:\t 0.021508515523940945\n",
      "Epoch:\t 54 Val Loss:\t 0.02150760983291828\n",
      "Epoch:\t 55 Val Loss:\t 0.021507422312687527\n",
      "Epoch:\t 56 Val Loss:\t 0.02150553250819875\n",
      "Epoch:\t 57 Val Loss:\t 0.02150596927307295\n",
      "Epoch:\t 58 Val Loss:\t 0.021503592214964173\n",
      "Epoch:\t 59 Val Loss:\t 0.02150825114493194\n",
      "Epoch:\t 60 Val Loss:\t 0.02150786616936637\n",
      "Epoch:\t 61 Val Loss:\t 0.02150790316813639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:54:23,138] Trial 37 finished with value: 0.021499393911461193 and parameters: {'lr': 0.0001, 'weight_decay': 0.0001, 'scheduler_factor': 0.3, 'scheduler_patience': 1, 'batch_size': 128, 'dropout': 0.05, 'hidden_dims': 128}. Best is trial 14 with value: 0.02147636453514706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 62 Val Loss:\t 0.021506470841853424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:54:27,339] Trial 38 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03278957308235655\n",
      "Epoch:\t 0 Val Loss:\t 0.02167378341776123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:54:35,206] Trial 39 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 1 Val Loss:\t 0.021722005258641694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:54:39,192] Trial 40 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.02194166730903986\n",
      "Epoch:\t 0 Val Loss:\t 0.021564936076992013\n",
      "Epoch:\t 1 Val Loss:\t 0.021551219931838027\n",
      "Epoch:\t 2 Val Loss:\t 0.021567060180116043\n",
      "Epoch:\t 3 Val Loss:\t 0.021537541452179367\n",
      "Epoch:\t 4 Val Loss:\t 0.02153961386764796\n",
      "Epoch:\t 5 Val Loss:\t 0.02153936575015896\n",
      "Epoch:\t 6 Val Loss:\t 0.021518234175481918\n",
      "Epoch:\t 7 Val Loss:\t 0.021521479229220035\n",
      "Epoch:\t 8 Val Loss:\t 0.021525960068784978\n",
      "Epoch:\t 9 Val Loss:\t 0.021511882011379515\n",
      "Epoch:\t 10 Val Loss:\t 0.02151942526978436\n",
      "Epoch:\t 11 Val Loss:\t 0.021505097241214154\n",
      "Epoch:\t 12 Val Loss:\t 0.021505589284493108\n",
      "Epoch:\t 13 Val Loss:\t 0.02151139947566328\n",
      "Epoch:\t 14 Val Loss:\t 0.021507102679192158\n",
      "Epoch:\t 15 Val Loss:\t 0.02150667840869048\n",
      "Epoch:\t 16 Val Loss:\t 0.021503367166768872\n",
      "Epoch:\t 17 Val Loss:\t 0.02150533093292009\n",
      "Epoch:\t 18 Val Loss:\t 0.021502279154776954\n",
      "Epoch:\t 19 Val Loss:\t 0.02150581401576965\n",
      "Epoch:\t 20 Val Loss:\t 0.02150650117038054\n",
      "Epoch:\t 21 Val Loss:\t 0.021507108631883157\n",
      "Epoch:\t 22 Val Loss:\t 0.021509514185771895\n",
      "Epoch:\t 23 Val Loss:\t 0.021503017159899395\n",
      "Epoch:\t 24 Val Loss:\t 0.021506025618836164\n",
      "Epoch:\t 25 Val Loss:\t 0.02150746143421526\n",
      "Epoch:\t 26 Val Loss:\t 0.021509035231835578\n",
      "Epoch:\t 27 Val Loss:\t 0.021502504645462595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:56:44,359] Trial 41 finished with value: 0.021502279154776954 and parameters: {'lr': 0.0001, 'weight_decay': 0.0001, 'scheduler_factor': 0.3, 'scheduler_patience': 1, 'batch_size': 128, 'dropout': 0.05, 'hidden_dims': 128}. Best is trial 14 with value: 0.02147636453514706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 28 Val Loss:\t 0.02150752256365783\n",
      "Epoch:\t 0 Val Loss:\t 0.02159004984647753\n",
      "Epoch:\t 1 Val Loss:\t 0.021540566265319937\n",
      "Epoch:\t 2 Val Loss:\t 0.021539102558100397\n",
      "Epoch:\t 3 Val Loss:\t 0.021538751187882302\n",
      "Epoch:\t 4 Val Loss:\t 0.021499579171403452\n",
      "Epoch:\t 5 Val Loss:\t 0.021524484776091996\n",
      "Epoch:\t 6 Val Loss:\t 0.021521570498832347\n",
      "Epoch:\t 7 Val Loss:\t 0.021503998232739314\n",
      "Epoch:\t 8 Val Loss:\t 0.021510712646940548\n",
      "Epoch:\t 9 Val Loss:\t 0.021492990334764914\n",
      "Epoch:\t 10 Val Loss:\t 0.021503695611203653\n",
      "Epoch:\t 11 Val Loss:\t 0.021497235646886964\n",
      "Epoch:\t 12 Val Loss:\t 0.02150023060986835\n",
      "Epoch:\t 13 Val Loss:\t 0.021497685498114\n",
      "Epoch:\t 14 Val Loss:\t 0.021499978835854448\n",
      "Epoch:\t 15 Val Loss:\t 0.021506613945621356\n",
      "Epoch:\t 16 Val Loss:\t 0.021501542315676355\n",
      "Epoch:\t 17 Val Loss:\t 0.021505332813504037\n",
      "Epoch:\t 18 Val Loss:\t 0.021501897148082382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 18:58:13,056] Trial 42 finished with value: 0.021492990334764914 and parameters: {'lr': 0.0001, 'weight_decay': 0.0001, 'scheduler_factor': 0.3, 'scheduler_patience': 1, 'batch_size': 128, 'dropout': 0.05, 'hidden_dims': 128}. Best is trial 14 with value: 0.02147636453514706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 19 Val Loss:\t 0.02149756100584856\n",
      "Epoch:\t 0 Val Loss:\t 0.02158922812696636\n",
      "Epoch:\t 1 Val Loss:\t 0.021521540639703768\n",
      "Epoch:\t 2 Val Loss:\t 0.021512864788405202\n",
      "Epoch:\t 3 Val Loss:\t 0.021549426363018695\n",
      "Epoch:\t 4 Val Loss:\t 0.02151902647237525\n",
      "Epoch:\t 5 Val Loss:\t 0.021514159565967885\n",
      "Epoch:\t 6 Val Loss:\t 0.021513864759768377\n",
      "Epoch:\t 7 Val Loss:\t 0.021505601701130837\n",
      "Epoch:\t 8 Val Loss:\t 0.021511578161036223\n",
      "Epoch:\t 9 Val Loss:\t 0.021502536376205722\n",
      "Epoch:\t 10 Val Loss:\t 0.02150431364762745\n",
      "Epoch:\t 11 Val Loss:\t 0.02150768788462657\n",
      "Epoch:\t 12 Val Loss:\t 0.021501343021614786\n",
      "Epoch:\t 13 Val Loss:\t 0.021501119441411087\n",
      "Epoch:\t 14 Val Loss:\t 0.021500160454220794\n",
      "Epoch:\t 15 Val Loss:\t 0.021495156381787495\n",
      "Epoch:\t 16 Val Loss:\t 0.021503993389263964\n",
      "Epoch:\t 17 Val Loss:\t 0.02150010499343826\n",
      "Epoch:\t 18 Val Loss:\t 0.021505181212725648\n",
      "Epoch:\t 19 Val Loss:\t 0.02149999500469067\n",
      "Epoch:\t 20 Val Loss:\t 0.021494137233849703\n",
      "Epoch:\t 21 Val Loss:\t 0.021501223758508842\n",
      "Epoch:\t 22 Val Loss:\t 0.021501319701177926\n",
      "Epoch:\t 23 Val Loss:\t 0.02150081128575637\n",
      "Epoch:\t 24 Val Loss:\t 0.021501656621694565\n",
      "Epoch:\t 25 Val Loss:\t 0.02150329766588743\n",
      "Epoch:\t 26 Val Loss:\t 0.02150378936533943\n",
      "Epoch:\t 27 Val Loss:\t 0.021502650658305537\n",
      "Epoch:\t 28 Val Loss:\t 0.021499819446648104\n",
      "Epoch:\t 29 Val Loss:\t 0.021499278206216773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 19:00:31,978] Trial 43 finished with value: 0.021494137233849703 and parameters: {'lr': 0.0001, 'weight_decay': 0.0001, 'scheduler_factor': 0.3, 'scheduler_patience': 1, 'batch_size': 128, 'dropout': 0.05, 'hidden_dims': 128}. Best is trial 14 with value: 0.02147636453514706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 30 Val Loss:\t 0.021506418334992894\n",
      "Epoch:\t 0 Val Loss:\t 0.021600154594758923\n",
      "Epoch:\t 1 Val Loss:\t 0.02151441956791028\n",
      "Epoch:\t 2 Val Loss:\t 0.021538074258386036\n",
      "Epoch:\t 3 Val Loss:\t 0.021563800742452063\n",
      "Epoch:\t 4 Val Loss:\t 0.021502076823078992\n",
      "Epoch:\t 5 Val Loss:\t 0.02150563649641855\n",
      "Epoch:\t 6 Val Loss:\t 0.02150454776986453\n",
      "Epoch:\t 7 Val Loss:\t 0.021503073445866615\n",
      "Epoch:\t 8 Val Loss:\t 0.02150570270852044\n",
      "Epoch:\t 9 Val Loss:\t 0.021502229900818383\n",
      "Epoch:\t 10 Val Loss:\t 0.021498005565130308\n",
      "Epoch:\t 11 Val Loss:\t 0.021501527208218987\n",
      "Epoch:\t 12 Val Loss:\t 0.02150363110029774\n",
      "Epoch:\t 13 Val Loss:\t 0.02150144187036908\n",
      "Epoch:\t 14 Val Loss:\t 0.021504814202865857\n",
      "Epoch:\t 15 Val Loss:\t 0.02149908377655915\n",
      "Epoch:\t 16 Val Loss:\t 0.021499865256357536\n",
      "Epoch:\t 17 Val Loss:\t 0.021502545644584474\n",
      "Epoch:\t 18 Val Loss:\t 0.021508053205249587\n",
      "Epoch:\t 19 Val Loss:\t 0.021496366347704996\n",
      "Epoch:\t 20 Val Loss:\t 0.021500562988879403\n",
      "Epoch:\t 21 Val Loss:\t 0.021500769700633773\n",
      "Epoch:\t 22 Val Loss:\t 0.021502087705949528\n",
      "Epoch:\t 23 Val Loss:\t 0.02150195400211153\n",
      "Epoch:\t 24 Val Loss:\t 0.021501249440887382\n",
      "Epoch:\t 25 Val Loss:\t 0.021502263252032895\n",
      "Epoch:\t 26 Val Loss:\t 0.021498185500239485\n",
      "Epoch:\t 27 Val Loss:\t 0.021503139807458483\n",
      "Epoch:\t 28 Val Loss:\t 0.021501026802470558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 19:02:47,368] Trial 44 finished with value: 0.021496366347704996 and parameters: {'lr': 0.0001, 'weight_decay': 0.0001, 'scheduler_factor': 0.3, 'scheduler_patience': 1, 'batch_size': 128, 'dropout': 0.05, 'hidden_dims': 128}. Best is trial 14 with value: 0.02147636453514706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 29 Val Loss:\t 0.021498888754921206\n",
      "Epoch:\t 0 Val Loss:\t 0.0216093584715746\n",
      "Epoch:\t 1 Val Loss:\t 0.021520055707896883\n",
      "Epoch:\t 2 Val Loss:\t 0.021561691103978486\n",
      "Epoch:\t 3 Val Loss:\t 0.021539655348127573\n",
      "Epoch:\t 4 Val Loss:\t 0.021512507432608314\n",
      "Epoch:\t 5 Val Loss:\t 0.021493760937672364\n",
      "Epoch:\t 6 Val Loss:\t 0.02151087306762775\n",
      "Epoch:\t 7 Val Loss:\t 0.021508047683089733\n",
      "Epoch:\t 8 Val Loss:\t 0.021506442352053057\n",
      "Epoch:\t 9 Val Loss:\t 0.021508558403646773\n",
      "Epoch:\t 10 Val Loss:\t 0.0214985976172058\n",
      "Epoch:\t 11 Val Loss:\t 0.021507828246748274\n",
      "Epoch:\t 12 Val Loss:\t 0.021495341722454344\n",
      "Epoch:\t 13 Val Loss:\t 0.021500832887058466\n",
      "Epoch:\t 14 Val Loss:\t 0.0214988776508055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 19:04:01,632] Trial 45 finished with value: 0.021493760937672364 and parameters: {'lr': 0.0001, 'weight_decay': 0.0001, 'scheduler_factor': 0.3, 'scheduler_patience': 1, 'batch_size': 128, 'dropout': 0.05, 'hidden_dims': 128}. Best is trial 14 with value: 0.02147636453514706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 15 Val Loss:\t 0.02150283389415347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 19:04:06,326] Trial 46 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.022721912547419773\n",
      "Epoch:\t 0 Val Loss:\t 0.02160415936554416\n",
      "Epoch:\t 1 Val Loss:\t 0.021557554483031\n",
      "Epoch:\t 2 Val Loss:\t 0.021555301755738488\n",
      "Epoch:\t 3 Val Loss:\t 0.021524957143499803\n",
      "Epoch:\t 4 Val Loss:\t 0.021552105991836535\n",
      "Epoch:\t 5 Val Loss:\t 0.021540123114233797\n",
      "Epoch:\t 6 Val Loss:\t 0.02151773976428168\n",
      "Epoch:\t 7 Val Loss:\t 0.0215167985335112\n",
      "Epoch:\t 8 Val Loss:\t 0.021518544229659375\n",
      "Epoch:\t 9 Val Loss:\t 0.021519797562620038\n",
      "Epoch:\t 10 Val Loss:\t 0.02151388329652588\n",
      "Epoch:\t 11 Val Loss:\t 0.021507133563822\n",
      "Epoch:\t 12 Val Loss:\t 0.02151423433188642\n",
      "Epoch:\t 13 Val Loss:\t 0.021509898213570994\n",
      "Epoch:\t 14 Val Loss:\t 0.021504911804873718\n",
      "Epoch:\t 15 Val Loss:\t 0.02150743996147455\n",
      "Epoch:\t 16 Val Loss:\t 0.02150745876133442\n",
      "Epoch:\t 17 Val Loss:\t 0.021512035708007422\n",
      "Epoch:\t 18 Val Loss:\t 0.02150597432284447\n",
      "Epoch:\t 19 Val Loss:\t 0.02150292673341057\n",
      "Epoch:\t 20 Val Loss:\t 0.021509704316097698\n",
      "Epoch:\t 21 Val Loss:\t 0.021503459091147297\n",
      "Epoch:\t 22 Val Loss:\t 0.0215077842368982\n",
      "Epoch:\t 23 Val Loss:\t 0.02150264930392632\n",
      "Epoch:\t 24 Val Loss:\t 0.0215055715191039\n",
      "Epoch:\t 25 Val Loss:\t 0.02150219911485193\n",
      "Epoch:\t 26 Val Loss:\t 0.021500783594232502\n",
      "Epoch:\t 27 Val Loss:\t 0.021508011270320433\n",
      "Epoch:\t 28 Val Loss:\t 0.021501274710673583\n",
      "Epoch:\t 29 Val Loss:\t 0.021508419886231422\n",
      "Epoch:\t 30 Val Loss:\t 0.021508484089187978\n",
      "Epoch:\t 31 Val Loss:\t 0.02150435367506446\n",
      "Epoch:\t 32 Val Loss:\t 0.021510166563033867\n",
      "Epoch:\t 33 Val Loss:\t 0.02150785026961211\n",
      "Epoch:\t 34 Val Loss:\t 0.021503058987195765\n",
      "Epoch:\t 35 Val Loss:\t 0.021509928682618692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 19:06:52,757] Trial 47 finished with value: 0.021500783594232502 and parameters: {'lr': 0.0001, 'weight_decay': 0.0001, 'scheduler_factor': 0.3, 'scheduler_patience': 1, 'batch_size': 128, 'dropout': 0.05, 'hidden_dims': 128}. Best is trial 14 with value: 0.02147636453514706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 36 Val Loss:\t 0.021505116160666006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 19:06:57,140] Trial 48 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.022352145207420973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 19:07:01,457] Trial 49 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.021690086140200186\n",
      "Training model with best parameters on train+validation ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401917/401917 [04:13<00:00, 1582.79it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401917/401917 [01:15<00:00, 5347.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting test set predictions and saving results ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2446/2446 [00:02<00:00, 877.80it/s]\n"
     ]
    }
   ],
   "source": [
    "train_different_featno(\n",
    "        adata_path=\"./data/feature_number/sciplex_hvg_5000.h5ad\",\n",
    "        run_name=\"mlp_hvg_5000\",\n",
    "        res_savename=\"./results/feature_number/mlp_hvg_5000_res.pkl\",\n",
    "        input_dim=5000,\n",
    "        output_dim=5000,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3877c129-6a13-43a3-ad8a-5a2e7fd3efb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Datasets ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401917/401917 [03:18<00:00, 2020.02it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401917/401917 [01:16<00:00, 5271.65it/s]\n",
      "[I 2025-06-18 19:22:17,019] A new study created in RDB with name: mlp_hvg_7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing Hyperparameters with Optuna ...\n",
      "Epoch:\t 0 Val Loss:\t 0.02088645996275466\n",
      "Epoch:\t 1 Val Loss:\t 0.020866021021127258\n",
      "Epoch:\t 2 Val Loss:\t 0.020872459998994355\n",
      "Epoch:\t 3 Val Loss:\t 0.02083933925839446\n",
      "Epoch:\t 4 Val Loss:\t 0.020887886335992294\n",
      "Epoch:\t 5 Val Loss:\t 0.020851061553280988\n",
      "Epoch:\t 6 Val Loss:\t 0.020850931494111432\n",
      "Epoch:\t 7 Val Loss:\t 0.02085218541033042\n",
      "Epoch:\t 8 Val Loss:\t 0.020896688382083632\n",
      "Epoch:\t 9 Val Loss:\t 0.020879512661898202\n",
      "Epoch:\t 10 Val Loss:\t 0.020828098224961514\n",
      "Epoch:\t 11 Val Loss:\t 0.020826108970884043\n",
      "Epoch:\t 12 Val Loss:\t 0.020834843340370692\n",
      "Epoch:\t 13 Val Loss:\t 0.020816574640836298\n",
      "Epoch:\t 14 Val Loss:\t 0.02081862756763377\n",
      "Epoch:\t 15 Val Loss:\t 0.020827999456812303\n",
      "Epoch:\t 16 Val Loss:\t 0.020833977297145482\n",
      "Epoch:\t 17 Val Loss:\t 0.020851721022031013\n",
      "Epoch:\t 18 Val Loss:\t 0.020828569339458782\n",
      "Epoch:\t 19 Val Loss:\t 0.020814223126162153\n",
      "Epoch:\t 20 Val Loss:\t 0.020843503525937054\n",
      "Epoch:\t 21 Val Loss:\t 0.02083831219395585\n",
      "Epoch:\t 22 Val Loss:\t 0.020846799112844445\n",
      "Epoch:\t 23 Val Loss:\t 0.020824748373166266\n",
      "Epoch:\t 24 Val Loss:\t 0.020846018247101833\n",
      "Epoch:\t 25 Val Loss:\t 0.0208401272123397\n",
      "Epoch:\t 26 Val Loss:\t 0.020776564389709075\n",
      "Epoch:\t 27 Val Loss:\t 0.020810140311931458\n",
      "Epoch:\t 28 Val Loss:\t 0.020804579255337755\n",
      "Epoch:\t 29 Val Loss:\t 0.02078530899833263\n",
      "Epoch:\t 30 Val Loss:\t 0.02081544918779368\n",
      "Epoch:\t 31 Val Loss:\t 0.020771172896708285\n",
      "Epoch:\t 32 Val Loss:\t 0.02080196400041082\n",
      "Epoch:\t 33 Val Loss:\t 0.020827592294375825\n",
      "Epoch:\t 34 Val Loss:\t 0.020792052790745003\n",
      "Epoch:\t 35 Val Loss:\t 0.020765070873252005\n",
      "Epoch:\t 36 Val Loss:\t 0.020828978131663116\n",
      "Epoch:\t 37 Val Loss:\t 0.020830931085246022\n",
      "Epoch:\t 38 Val Loss:\t 0.020786745533268012\n",
      "Epoch:\t 39 Val Loss:\t 0.020784896145330488\n",
      "Epoch:\t 40 Val Loss:\t 0.020772147845895598\n",
      "Epoch:\t 41 Val Loss:\t 0.0208025358634473\n",
      "Epoch:\t 42 Val Loss:\t 0.020755032048322016\n",
      "Epoch:\t 43 Val Loss:\t 0.02076937270633827\n",
      "Epoch:\t 44 Val Loss:\t 0.020766572079779305\n",
      "Epoch:\t 45 Val Loss:\t 0.020762828674501035\n",
      "Epoch:\t 46 Val Loss:\t 0.020771305073978927\n",
      "Epoch:\t 47 Val Loss:\t 0.02075666025787759\n",
      "Epoch:\t 48 Val Loss:\t 0.02077472215099251\n",
      "Epoch:\t 49 Val Loss:\t 0.02076838039267794\n",
      "Epoch:\t 50 Val Loss:\t 0.020729766765273876\n",
      "Epoch:\t 51 Val Loss:\t 0.020757898565346683\n",
      "Epoch:\t 52 Val Loss:\t 0.0207555879254892\n",
      "Epoch:\t 53 Val Loss:\t 0.02074559283913215\n",
      "Epoch:\t 54 Val Loss:\t 0.020753285660257477\n",
      "Epoch:\t 55 Val Loss:\t 0.020772903367945676\n",
      "Epoch:\t 56 Val Loss:\t 0.020736446924712132\n",
      "Epoch:\t 57 Val Loss:\t 0.020730479622449696\n",
      "Epoch:\t 58 Val Loss:\t 0.020723211270201138\n",
      "Epoch:\t 59 Val Loss:\t 0.02072443445650717\n",
      "Epoch:\t 60 Val Loss:\t 0.020733134069804128\n",
      "Epoch:\t 61 Val Loss:\t 0.020716188937885398\n",
      "Epoch:\t 62 Val Loss:\t 0.020715718806772213\n",
      "Epoch:\t 63 Val Loss:\t 0.020743121262031445\n",
      "Epoch:\t 64 Val Loss:\t 0.020716975810108146\n",
      "Epoch:\t 65 Val Loss:\t 0.020714546691874863\n",
      "Epoch:\t 66 Val Loss:\t 0.02072443762535509\n",
      "Epoch:\t 67 Val Loss:\t 0.020731244623986473\n",
      "Epoch:\t 68 Val Loss:\t 0.020703834299042156\n",
      "Epoch:\t 69 Val Loss:\t 0.020722171648302302\n",
      "Epoch:\t 70 Val Loss:\t 0.020698064799356906\n",
      "Epoch:\t 71 Val Loss:\t 0.020701417831382695\n",
      "Epoch:\t 72 Val Loss:\t 0.020711832528288617\n",
      "Epoch:\t 73 Val Loss:\t 0.02071238838884837\n",
      "Epoch:\t 74 Val Loss:\t 0.020718983825735796\n",
      "Epoch:\t 75 Val Loss:\t 0.02069108204087987\n",
      "Epoch:\t 76 Val Loss:\t 0.020713573146482325\n",
      "Epoch:\t 77 Val Loss:\t 0.020720598987445302\n",
      "Epoch:\t 78 Val Loss:\t 0.02069286510581197\n",
      "Epoch:\t 79 Val Loss:\t 0.02070042363455117\n",
      "Epoch:\t 80 Val Loss:\t 0.02071175126885453\n",
      "Epoch:\t 81 Val Loss:\t 0.020709710686606233\n",
      "Epoch:\t 82 Val Loss:\t 0.020697175790474604\n",
      "Epoch:\t 83 Val Loss:\t 0.02068579332047278\n",
      "Epoch:\t 84 Val Loss:\t 0.020700251587120393\n",
      "Epoch:\t 85 Val Loss:\t 0.02067433247811819\n",
      "Epoch:\t 86 Val Loss:\t 0.020704977625417068\n",
      "Epoch:\t 87 Val Loss:\t 0.02069885262286847\n",
      "Epoch:\t 88 Val Loss:\t 0.020717692192538637\n",
      "Epoch:\t 89 Val Loss:\t 0.02070488749574657\n",
      "Epoch:\t 90 Val Loss:\t 0.0206804044258825\n",
      "Epoch:\t 91 Val Loss:\t 0.020691060586872582\n",
      "Epoch:\t 92 Val Loss:\t 0.020693864317529127\n",
      "Epoch:\t 93 Val Loss:\t 0.020689722024049124\n",
      "Epoch:\t 94 Val Loss:\t 0.020698566310312222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 19:51:25,400] Trial 0 finished with value: 0.02067433247811819 and parameters: {'lr': 0.001, 'weight_decay': 0.0001, 'scheduler_factor': 0.8, 'scheduler_patience': 5, 'batch_size': 16, 'dropout': 0.05, 'hidden_dims': 256}. Best is trial 0 with value: 0.02067433247811819.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 95 Val Loss:\t 0.020692942961281643\n",
      "Epoch:\t 0 Val Loss:\t 0.05387844639565132\n",
      "Epoch:\t 1 Val Loss:\t 0.03807862046781343\n",
      "Epoch:\t 2 Val Loss:\t 0.03326879905104231\n",
      "Epoch:\t 3 Val Loss:\t 0.03054581244351677\n",
      "Epoch:\t 4 Val Loss:\t 0.02822815340987859\n",
      "Epoch:\t 5 Val Loss:\t 0.024919703269895725\n",
      "Epoch:\t 6 Val Loss:\t 0.023182766047587938\n",
      "Epoch:\t 7 Val Loss:\t 0.02232133684016688\n",
      "Epoch:\t 8 Val Loss:\t 0.021957882703323925\n",
      "Epoch:\t 9 Val Loss:\t 0.02188368699847577\n",
      "Epoch:\t 10 Val Loss:\t 0.02180577780617738\n",
      "Epoch:\t 11 Val Loss:\t 0.021760190746210856\n",
      "Epoch:\t 12 Val Loss:\t 0.021806222849427175\n",
      "Epoch:\t 13 Val Loss:\t 0.021758909950578078\n",
      "Epoch:\t 14 Val Loss:\t 0.021819832864637498\n",
      "Epoch:\t 15 Val Loss:\t 0.021807307949947632\n",
      "Epoch:\t 16 Val Loss:\t 0.02181028573324281\n",
      "Epoch:\t 17 Val Loss:\t 0.021867996165120238\n",
      "Epoch:\t 18 Val Loss:\t 0.02180664544950098\n",
      "Epoch:\t 19 Val Loss:\t 0.021783800371904825\n",
      "Epoch:\t 20 Val Loss:\t 0.02183736597664208\n",
      "Epoch:\t 21 Val Loss:\t 0.02185337124174068\n",
      "Epoch:\t 22 Val Loss:\t 0.0218496636305235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 19:58:24,603] Trial 1 finished with value: 0.021758909950578078 and parameters: {'lr': 1e-06, 'weight_decay': 0.001, 'scheduler_factor': 0.5, 'scheduler_patience': 1, 'batch_size': 16, 'dropout': 0.2, 'hidden_dims': 64}. Best is trial 0 with value: 0.02067433247811819.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 23 Val Loss:\t 0.02181384288147017\n",
      "Epoch:\t 0 Val Loss:\t 0.02258134448979985\n",
      "Epoch:\t 1 Val Loss:\t 0.022199451881546733\n",
      "Epoch:\t 2 Val Loss:\t 0.02118932524189628\n",
      "Epoch:\t 3 Val Loss:\t 0.021034205635619717\n",
      "Epoch:\t 4 Val Loss:\t 0.021022926614214253\n",
      "Epoch:\t 5 Val Loss:\t 0.021010493917903043\n",
      "Epoch:\t 6 Val Loss:\t 0.02099843759242066\n",
      "Epoch:\t 7 Val Loss:\t 0.020985182685405612\n",
      "Epoch:\t 8 Val Loss:\t 0.020986203078864667\n",
      "Epoch:\t 9 Val Loss:\t 0.020982013332695604\n",
      "Epoch:\t 10 Val Loss:\t 0.020986300571235354\n",
      "Epoch:\t 11 Val Loss:\t 0.020983962083732786\n",
      "Epoch:\t 12 Val Loss:\t 0.020982104139260608\n",
      "Epoch:\t 13 Val Loss:\t 0.020980551163721963\n",
      "Epoch:\t 14 Val Loss:\t 0.020979436289193444\n",
      "Epoch:\t 15 Val Loss:\t 0.02097849017748521\n",
      "Epoch:\t 16 Val Loss:\t 0.020982408918494115\n",
      "Epoch:\t 17 Val Loss:\t 0.020980421564248244\n",
      "Epoch:\t 18 Val Loss:\t 0.020979771321847043\n",
      "Epoch:\t 19 Val Loss:\t 0.020976606714625118\n",
      "Epoch:\t 20 Val Loss:\t 0.0209741254591808\n",
      "Epoch:\t 21 Val Loss:\t 0.020976010239485175\n",
      "Epoch:\t 22 Val Loss:\t 0.020972451472949197\n",
      "Epoch:\t 23 Val Loss:\t 0.020975151549615472\n",
      "Epoch:\t 24 Val Loss:\t 0.020972403565476968\n",
      "Epoch:\t 25 Val Loss:\t 0.020975032598736197\n",
      "Epoch:\t 26 Val Loss:\t 0.02097394720986545\n",
      "Epoch:\t 27 Val Loss:\t 0.020948267024258373\n",
      "Epoch:\t 28 Val Loss:\t 0.02095411055435299\n",
      "Epoch:\t 29 Val Loss:\t 0.020949905823375477\n",
      "Epoch:\t 30 Val Loss:\t 0.020950197021879478\n",
      "Epoch:\t 31 Val Loss:\t 0.02095427623865551\n",
      "Epoch:\t 32 Val Loss:\t 0.02095334643517481\n",
      "Epoch:\t 33 Val Loss:\t 0.020954290409396913\n",
      "Epoch:\t 34 Val Loss:\t 0.02094303117952972\n",
      "Epoch:\t 35 Val Loss:\t 0.020942226603459912\n",
      "Epoch:\t 36 Val Loss:\t 0.020944730516854724\n",
      "Epoch:\t 37 Val Loss:\t 0.020947150629142236\n",
      "Epoch:\t 38 Val Loss:\t 0.020946051674478994\n",
      "Epoch:\t 39 Val Loss:\t 0.020947699075820166\n",
      "Epoch:\t 40 Val Loss:\t 0.020946796075310244\n",
      "Epoch:\t 41 Val Loss:\t 0.02094480729607362\n",
      "Epoch:\t 42 Val Loss:\t 0.020942978359274896\n",
      "Epoch:\t 43 Val Loss:\t 0.020945199591248822\n",
      "Epoch:\t 44 Val Loss:\t 0.020943453000692624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 20:05:59,866] Trial 2 finished with value: 0.020942226603459912 and parameters: {'lr': 0.001, 'weight_decay': 1e-06, 'scheduler_factor': 0.3, 'scheduler_patience': 5, 'batch_size': 64, 'dropout': 0.1, 'hidden_dims': 1024}. Best is trial 0 with value: 0.02067433247811819.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 45 Val Loss:\t 0.02094708399065944\n",
      "Epoch:\t 0 Val Loss:\t 0.02234572464962283\n",
      "Epoch:\t 1 Val Loss:\t 0.02169863555378809\n",
      "Epoch:\t 2 Val Loss:\t 0.02140820049316826\n",
      "Epoch:\t 3 Val Loss:\t 0.021290277418697285\n",
      "Epoch:\t 4 Val Loss:\t 0.021203196987897934\n",
      "Epoch:\t 5 Val Loss:\t 0.021127638504103215\n",
      "Epoch:\t 6 Val Loss:\t 0.02105433799266696\n",
      "Epoch:\t 7 Val Loss:\t 0.02100933290652199\n",
      "Epoch:\t 8 Val Loss:\t 0.020938209500275775\n",
      "Epoch:\t 9 Val Loss:\t 0.020909377844828762\n",
      "Epoch:\t 10 Val Loss:\t 0.02090270424369939\n",
      "Epoch:\t 11 Val Loss:\t 0.020907704148792432\n",
      "Epoch:\t 12 Val Loss:\t 0.02089355334691808\n",
      "Epoch:\t 13 Val Loss:\t 0.02090907330421324\n",
      "Epoch:\t 14 Val Loss:\t 0.020878778675753988\n",
      "Epoch:\t 15 Val Loss:\t 0.020906580060362098\n",
      "Epoch:\t 16 Val Loss:\t 0.020881911665051878\n",
      "Epoch:\t 17 Val Loss:\t 0.02089671831585482\n",
      "Epoch:\t 18 Val Loss:\t 0.02089151792407394\n",
      "Epoch:\t 19 Val Loss:\t 0.020891007804918385\n",
      "Epoch:\t 20 Val Loss:\t 0.020883734955756603\n",
      "Epoch:\t 21 Val Loss:\t 0.0209034329926024\n",
      "Epoch:\t 22 Val Loss:\t 0.020891322529238306\n",
      "Epoch:\t 23 Val Loss:\t 0.020871305616501575\n",
      "Epoch:\t 24 Val Loss:\t 0.020852313558001795\n",
      "Epoch:\t 25 Val Loss:\t 0.02086337494154373\n",
      "Epoch:\t 26 Val Loss:\t 0.020857811138735624\n",
      "Epoch:\t 27 Val Loss:\t 0.02086290031119076\n",
      "Epoch:\t 28 Val Loss:\t 0.020867341317102044\n",
      "Epoch:\t 29 Val Loss:\t 0.020845774209541167\n",
      "Epoch:\t 30 Val Loss:\t 0.020849829406397256\n",
      "Epoch:\t 31 Val Loss:\t 0.02085284323493142\n",
      "Epoch:\t 32 Val Loss:\t 0.02084387319912772\n",
      "Epoch:\t 33 Val Loss:\t 0.02084373325549947\n",
      "Epoch:\t 34 Val Loss:\t 0.020829751112970536\n",
      "Epoch:\t 35 Val Loss:\t 0.02083895320823054\n",
      "Epoch:\t 36 Val Loss:\t 0.02083411498857524\n",
      "Epoch:\t 37 Val Loss:\t 0.0208331888866329\n",
      "Epoch:\t 38 Val Loss:\t 0.02081492199695003\n",
      "Epoch:\t 39 Val Loss:\t 0.020821856025733308\n",
      "Epoch:\t 40 Val Loss:\t 0.02081525489941747\n",
      "Epoch:\t 41 Val Loss:\t 0.020815809529073134\n",
      "Epoch:\t 42 Val Loss:\t 0.02081284948880364\n",
      "Epoch:\t 43 Val Loss:\t 0.020795286927588717\n",
      "Epoch:\t 44 Val Loss:\t 0.020795584684667103\n",
      "Epoch:\t 45 Val Loss:\t 0.02078713583377356\n",
      "Epoch:\t 46 Val Loss:\t 0.020787462800039437\n",
      "Epoch:\t 47 Val Loss:\t 0.020803662625427\n",
      "Epoch:\t 48 Val Loss:\t 0.02078746217890887\n",
      "Epoch:\t 49 Val Loss:\t 0.02077627840950219\n",
      "Epoch:\t 50 Val Loss:\t 0.02078671043063094\n",
      "Epoch:\t 51 Val Loss:\t 0.020766986930418112\n",
      "Epoch:\t 52 Val Loss:\t 0.020772005595595302\n",
      "Epoch:\t 53 Val Loss:\t 0.020752762178545128\n",
      "Epoch:\t 54 Val Loss:\t 0.020764021931929076\n",
      "Epoch:\t 55 Val Loss:\t 0.0207687137988144\n",
      "Epoch:\t 56 Val Loss:\t 0.02076945947315208\n",
      "Epoch:\t 57 Val Loss:\t 0.020748884881844742\n",
      "Epoch:\t 58 Val Loss:\t 0.020773472586172615\n",
      "Epoch:\t 59 Val Loss:\t 0.020747719181772463\n",
      "Epoch:\t 60 Val Loss:\t 0.02075332133827324\n",
      "Epoch:\t 61 Val Loss:\t 0.020745198049382838\n",
      "Epoch:\t 62 Val Loss:\t 0.020746341160310055\n",
      "Epoch:\t 63 Val Loss:\t 0.020753284548605252\n",
      "Epoch:\t 64 Val Loss:\t 0.020741529708619946\n",
      "Epoch:\t 65 Val Loss:\t 0.020728823470552722\n",
      "Epoch:\t 66 Val Loss:\t 0.020731014290260887\n",
      "Epoch:\t 67 Val Loss:\t 0.020723808828913018\n",
      "Epoch:\t 68 Val Loss:\t 0.020714974761725905\n",
      "Epoch:\t 69 Val Loss:\t 0.020725352773610838\n",
      "Epoch:\t 70 Val Loss:\t 0.020725639641493977\n",
      "Epoch:\t 71 Val Loss:\t 0.02072462633080437\n",
      "Epoch:\t 72 Val Loss:\t 0.02071887009472909\n",
      "Epoch:\t 73 Val Loss:\t 0.0207159621592514\n",
      "Epoch:\t 74 Val Loss:\t 0.020718965980267238\n",
      "Epoch:\t 75 Val Loss:\t 0.02071537303855878\n",
      "Epoch:\t 76 Val Loss:\t 0.020705036500203826\n",
      "Epoch:\t 77 Val Loss:\t 0.020709449816905784\n",
      "Epoch:\t 78 Val Loss:\t 0.020709434725000767\n",
      "Epoch:\t 79 Val Loss:\t 0.02070679746844427\n",
      "Epoch:\t 80 Val Loss:\t 0.020709728025541992\n",
      "Epoch:\t 81 Val Loss:\t 0.020693210297019662\n",
      "Epoch:\t 82 Val Loss:\t 0.02069759611973543\n",
      "Epoch:\t 83 Val Loss:\t 0.020701485332138912\n",
      "Epoch:\t 84 Val Loss:\t 0.02069226352867478\n",
      "Epoch:\t 85 Val Loss:\t 0.020692534805583453\n",
      "Epoch:\t 86 Val Loss:\t 0.02069194128546483\n",
      "Epoch:\t 87 Val Loss:\t 0.02069001075343223\n",
      "Epoch:\t 88 Val Loss:\t 0.020702835899928888\n",
      "Epoch:\t 89 Val Loss:\t 0.02069394814003565\n",
      "Epoch:\t 90 Val Loss:\t 0.020686310786149187\n",
      "Epoch:\t 91 Val Loss:\t 0.020692930240669326\n",
      "Epoch:\t 92 Val Loss:\t 0.02069120229574626\n",
      "Epoch:\t 93 Val Loss:\t 0.020690536167181445\n",
      "Epoch:\t 94 Val Loss:\t 0.020679035456197894\n",
      "Epoch:\t 95 Val Loss:\t 0.020684786416769387\n",
      "Epoch:\t 96 Val Loss:\t 0.020688965975984422\n",
      "Epoch:\t 97 Val Loss:\t 0.02068318541018005\n",
      "Epoch:\t 98 Val Loss:\t 0.02068353212048451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 20:26:39,165] Trial 3 finished with value: 0.020679035456197894 and parameters: {'lr': 1e-05, 'weight_decay': 1e-06, 'scheduler_factor': 0.8, 'scheduler_patience': 10, 'batch_size': 32, 'dropout': 0.2, 'hidden_dims': 512}. Best is trial 0 with value: 0.02067433247811819.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 99 Val Loss:\t 0.020681139528527407\n",
      "Epoch:\t 0 Val Loss:\t 0.024382756116663764\n",
      "Epoch:\t 1 Val Loss:\t 0.023253471772363764\n",
      "Epoch:\t 2 Val Loss:\t 0.022910951916315033\n",
      "Epoch:\t 3 Val Loss:\t 0.022665391385346234\n",
      "Epoch:\t 4 Val Loss:\t 0.022423555246574845\n",
      "Epoch:\t 5 Val Loss:\t 0.02222212655301801\n",
      "Epoch:\t 6 Val Loss:\t 0.0220356164780074\n",
      "Epoch:\t 7 Val Loss:\t 0.02184660411691797\n",
      "Epoch:\t 8 Val Loss:\t 0.02174713360910903\n",
      "Epoch:\t 9 Val Loss:\t 0.021616717304041487\n",
      "Epoch:\t 10 Val Loss:\t 0.021522231827040234\n",
      "Epoch:\t 11 Val Loss:\t 0.0214682418203545\n",
      "Epoch:\t 12 Val Loss:\t 0.021388428261455053\n",
      "Epoch:\t 13 Val Loss:\t 0.021332742608262446\n",
      "Epoch:\t 14 Val Loss:\t 0.02132332017551921\n",
      "Epoch:\t 15 Val Loss:\t 0.02125095137523745\n",
      "Epoch:\t 16 Val Loss:\t 0.021232935115471033\n",
      "Epoch:\t 17 Val Loss:\t 0.021197545830018535\n",
      "Epoch:\t 18 Val Loss:\t 0.02116527408772038\n",
      "Epoch:\t 19 Val Loss:\t 0.02114684963617511\n",
      "Epoch:\t 20 Val Loss:\t 0.021119209483474913\n",
      "Epoch:\t 21 Val Loss:\t 0.021097295650305273\n",
      "Epoch:\t 22 Val Loss:\t 0.02107631253351071\n",
      "Epoch:\t 23 Val Loss:\t 0.021065821979784655\n",
      "Epoch:\t 24 Val Loss:\t 0.021044235954990605\n",
      "Epoch:\t 25 Val Loss:\t 0.02103647720329986\n",
      "Epoch:\t 26 Val Loss:\t 0.02102421761932736\n",
      "Epoch:\t 27 Val Loss:\t 0.021005591304453914\n",
      "Epoch:\t 28 Val Loss:\t 0.02099837337831457\n",
      "Epoch:\t 29 Val Loss:\t 0.02098035064445648\n",
      "Epoch:\t 30 Val Loss:\t 0.020972131963124974\n",
      "Epoch:\t 31 Val Loss:\t 0.020964851774618716\n",
      "Epoch:\t 32 Val Loss:\t 0.0209475955595533\n",
      "Epoch:\t 33 Val Loss:\t 0.020942012277358996\n",
      "Epoch:\t 34 Val Loss:\t 0.02093745054441965\n",
      "Epoch:\t 35 Val Loss:\t 0.020932356913560976\n",
      "Epoch:\t 36 Val Loss:\t 0.020926568049093885\n",
      "Epoch:\t 37 Val Loss:\t 0.020911218742942644\n",
      "Epoch:\t 38 Val Loss:\t 0.020894565976006474\n",
      "Epoch:\t 39 Val Loss:\t 0.020894896641060083\n",
      "Epoch:\t 40 Val Loss:\t 0.020902385975501103\n",
      "Epoch:\t 41 Val Loss:\t 0.020865512055107848\n",
      "Epoch:\t 42 Val Loss:\t 0.02087101026406448\n",
      "Epoch:\t 43 Val Loss:\t 0.02086565735897344\n",
      "Epoch:\t 44 Val Loss:\t 0.020853464454337806\n",
      "Epoch:\t 45 Val Loss:\t 0.02084474108277079\n",
      "Epoch:\t 46 Val Loss:\t 0.020839648088720256\n",
      "Epoch:\t 47 Val Loss:\t 0.020838062838093193\n",
      "Epoch:\t 48 Val Loss:\t 0.020831185362426813\n",
      "Epoch:\t 49 Val Loss:\t 0.020828902920360912\n",
      "Epoch:\t 50 Val Loss:\t 0.020823165501107674\n",
      "Epoch:\t 51 Val Loss:\t 0.020817792785908274\n",
      "Epoch:\t 52 Val Loss:\t 0.02081295648302308\n",
      "Epoch:\t 53 Val Loss:\t 0.02081099696016921\n",
      "Epoch:\t 54 Val Loss:\t 0.020809060859611494\n",
      "Epoch:\t 55 Val Loss:\t 0.020801060081633155\n",
      "Epoch:\t 56 Val Loss:\t 0.020801199311558494\n",
      "Epoch:\t 57 Val Loss:\t 0.020795817242446307\n",
      "Epoch:\t 58 Val Loss:\t 0.020780961760851688\n",
      "Epoch:\t 59 Val Loss:\t 0.020777660475778795\n",
      "Epoch:\t 60 Val Loss:\t 0.020785704570148656\n",
      "Epoch:\t 61 Val Loss:\t 0.020773070775539818\n",
      "Epoch:\t 62 Val Loss:\t 0.02076595639044751\n",
      "Epoch:\t 63 Val Loss:\t 0.020769007458073464\n",
      "Epoch:\t 64 Val Loss:\t 0.020772134056146852\n",
      "Epoch:\t 65 Val Loss:\t 0.020767516054899873\n",
      "Epoch:\t 66 Val Loss:\t 0.020762085722374892\n",
      "Epoch:\t 67 Val Loss:\t 0.020762615690086195\n",
      "Epoch:\t 68 Val Loss:\t 0.020757287137120783\n",
      "Epoch:\t 69 Val Loss:\t 0.020754844033512063\n",
      "Epoch:\t 70 Val Loss:\t 0.020777354428996305\n",
      "Epoch:\t 71 Val Loss:\t 0.0207563020277746\n",
      "Epoch:\t 72 Val Loss:\t 0.020756635340845177\n",
      "Epoch:\t 73 Val Loss:\t 0.02074728126120651\n",
      "Epoch:\t 74 Val Loss:\t 0.020757321787546416\n",
      "Epoch:\t 75 Val Loss:\t 0.02075773452320892\n",
      "Epoch:\t 76 Val Loss:\t 0.02075664801056495\n",
      "Epoch:\t 77 Val Loss:\t 0.02075879968486293\n",
      "Epoch:\t 78 Val Loss:\t 0.02075424264810367\n",
      "Epoch:\t 79 Val Loss:\t 0.020755151381906502\n",
      "Epoch:\t 80 Val Loss:\t 0.02076509754417953\n",
      "Epoch:\t 81 Val Loss:\t 0.020755724586874903\n",
      "Epoch:\t 82 Val Loss:\t 0.020758359784816573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 20:52:57,321] Trial 4 finished with value: 0.02074728126120651 and parameters: {'lr': 1e-06, 'weight_decay': 1e-05, 'scheduler_factor': 0.5, 'scheduler_patience': 5, 'batch_size': 32, 'dropout': 0.1, 'hidden_dims': 1024}. Best is trial 0 with value: 0.02067433247811819.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 83 Val Loss:\t 0.020756335308278848\n",
      "Epoch:\t 0 Val Loss:\t 0.02070840121729006\n",
      "Epoch:\t 1 Val Loss:\t 0.020665437809619873\n",
      "Epoch:\t 2 Val Loss:\t 0.020650832054363952\n",
      "Epoch:\t 3 Val Loss:\t 0.020630122410954004\n",
      "Epoch:\t 4 Val Loss:\t 0.02062781764811258\n",
      "Epoch:\t 5 Val Loss:\t 0.02062028981266106\n",
      "Epoch:\t 6 Val Loss:\t 0.020633004689619087\n",
      "Epoch:\t 7 Val Loss:\t 0.02064628260647369\n",
      "Epoch:\t 8 Val Loss:\t 0.02063612898638011\n",
      "Epoch:\t 9 Val Loss:\t 0.020624373287824956\n",
      "Epoch:\t 10 Val Loss:\t 0.020630389985020522\n",
      "Epoch:\t 11 Val Loss:\t 0.020633969689536708\n",
      "Epoch:\t 12 Val Loss:\t 0.020636561191925282\n",
      "Epoch:\t 13 Val Loss:\t 0.02063266030389971\n",
      "Epoch:\t 14 Val Loss:\t 0.02063856521244026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 20:54:18,938] Trial 5 finished with value: 0.02062028981266106 and parameters: {'lr': 0.001, 'weight_decay': 1e-05, 'scheduler_factor': 0.3, 'scheduler_patience': 20, 'batch_size': 256, 'dropout': 0.2, 'hidden_dims': 64}. Best is trial 5 with value: 0.02062028981266106.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 15 Val Loss:\t 0.020638090477495714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 20:54:24,983] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.025879102870343968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 20:54:29,890] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.02427371445791706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 20:54:36,031] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.059810596702690594\n",
      "Epoch:\t 0 Val Loss:\t 0.020854242262523845\n",
      "Epoch:\t 1 Val Loss:\t 0.02063064119736003\n",
      "Epoch:\t 2 Val Loss:\t 0.020595810203585228\n",
      "Epoch:\t 3 Val Loss:\t 0.02057794911403033\n",
      "Epoch:\t 4 Val Loss:\t 0.020571808973752985\n",
      "Epoch:\t 5 Val Loss:\t 0.020563795134938997\n",
      "Epoch:\t 6 Val Loss:\t 0.02055826292648828\n",
      "Epoch:\t 7 Val Loss:\t 0.020558739251307037\n",
      "Epoch:\t 8 Val Loss:\t 0.020558387569862075\n",
      "Epoch:\t 9 Val Loss:\t 0.02055722065030955\n",
      "Epoch:\t 10 Val Loss:\t 0.02055813141657098\n",
      "Epoch:\t 11 Val Loss:\t 0.020558873201931775\n",
      "Epoch:\t 12 Val Loss:\t 0.020558653465071103\n",
      "Epoch:\t 13 Val Loss:\t 0.020539132213487372\n",
      "Epoch:\t 14 Val Loss:\t 0.020539715213950576\n",
      "Epoch:\t 15 Val Loss:\t 0.02053967024757562\n",
      "Epoch:\t 16 Val Loss:\t 0.020540649390987806\n",
      "Epoch:\t 17 Val Loss:\t 0.020539712005480826\n",
      "Epoch:\t 18 Val Loss:\t 0.020536649748145244\n",
      "Epoch:\t 19 Val Loss:\t 0.020539981749957335\n",
      "Epoch:\t 20 Val Loss:\t 0.02054289566635273\n",
      "Epoch:\t 21 Val Loss:\t 0.020538752849281743\n",
      "Epoch:\t 22 Val Loss:\t 0.020541897036117272\n",
      "Epoch:\t 23 Val Loss:\t 0.020539828680706626\n",
      "Epoch:\t 24 Val Loss:\t 0.020544712051581936\n",
      "Epoch:\t 25 Val Loss:\t 0.02053919258290706\n",
      "Epoch:\t 26 Val Loss:\t 0.020536667984740773\n",
      "Epoch:\t 27 Val Loss:\t 0.020536824778534933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 20:57:35,310] Trial 9 finished with value: 0.020536649748145244 and parameters: {'lr': 0.0001, 'weight_decay': 1e-05, 'scheduler_factor': 0.1, 'scheduler_patience': 5, 'batch_size': 64, 'dropout': 0.05, 'hidden_dims': 64}. Best is trial 9 with value: 0.020536649748145244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 28 Val Loss:\t 0.020538556199063755\n",
      "Epoch:\t 0 Val Loss:\t 0.022151469430896673\n",
      "Epoch:\t 1 Val Loss:\t 0.020924163471016416\n",
      "Epoch:\t 2 Val Loss:\t 0.02070075444231351\n",
      "Epoch:\t 3 Val Loss:\t 0.02063296330766827\n",
      "Epoch:\t 4 Val Loss:\t 0.020581589060959617\n",
      "Epoch:\t 5 Val Loss:\t 0.020565837588801046\n",
      "Epoch:\t 6 Val Loss:\t 0.020559898635931613\n",
      "Epoch:\t 7 Val Loss:\t 0.020557284172785798\n",
      "Epoch:\t 8 Val Loss:\t 0.020551433275494108\n",
      "Epoch:\t 9 Val Loss:\t 0.02055760423681231\n",
      "Epoch:\t 10 Val Loss:\t 0.020553714570321777\n",
      "Epoch:\t 11 Val Loss:\t 0.02056063943651668\n",
      "Epoch:\t 12 Val Loss:\t 0.020548646632779277\n",
      "Epoch:\t 13 Val Loss:\t 0.0205521360099507\n",
      "Epoch:\t 14 Val Loss:\t 0.020552083541957564\n",
      "Epoch:\t 15 Val Loss:\t 0.020551661418131993\n",
      "Epoch:\t 16 Val Loss:\t 0.020550352181898456\n",
      "Epoch:\t 17 Val Loss:\t 0.020550330281616406\n",
      "Epoch:\t 18 Val Loss:\t 0.020557005520473515\n",
      "Epoch:\t 19 Val Loss:\t 0.020538365250127463\n",
      "Epoch:\t 20 Val Loss:\t 0.020537169097084102\n",
      "Epoch:\t 21 Val Loss:\t 0.02054079206747094\n",
      "Epoch:\t 22 Val Loss:\t 0.020538949863581558\n",
      "Epoch:\t 23 Val Loss:\t 0.02053688002831002\n",
      "Epoch:\t 24 Val Loss:\t 0.020540053282010803\n",
      "Epoch:\t 25 Val Loss:\t 0.02053889175682638\n",
      "Epoch:\t 26 Val Loss:\t 0.020536237445631534\n",
      "Epoch:\t 27 Val Loss:\t 0.02053633066459318\n",
      "Epoch:\t 28 Val Loss:\t 0.020538915134069434\n",
      "Epoch:\t 29 Val Loss:\t 0.020537300181857655\n",
      "Epoch:\t 30 Val Loss:\t 0.020537323669723294\n",
      "Epoch:\t 31 Val Loss:\t 0.020537263879710943\n",
      "Epoch:\t 32 Val Loss:\t 0.020537358937399344\n",
      "Epoch:\t 33 Val Loss:\t 0.02053676290590059\n",
      "Epoch:\t 34 Val Loss:\t 0.02053708191751764\n",
      "Epoch:\t 35 Val Loss:\t 0.020540015464035697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:01:04,274] Trial 10 finished with value: 0.020536237445631534 and parameters: {'lr': 0.0001, 'weight_decay': 1e-05, 'scheduler_factor': 0.1, 'scheduler_patience': 5, 'batch_size': 128, 'dropout': 0.15, 'hidden_dims': 64}. Best is trial 10 with value: 0.020536237445631534.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 36 Val Loss:\t 0.020537077800563595\n",
      "Epoch:\t 0 Val Loss:\t 0.02216900731130454\n",
      "Epoch:\t 1 Val Loss:\t 0.020858349903437337\n",
      "Epoch:\t 2 Val Loss:\t 0.02064815424023911\n",
      "Epoch:\t 3 Val Loss:\t 0.02060297616782866\n",
      "Epoch:\t 4 Val Loss:\t 0.020574423243825354\n",
      "Epoch:\t 5 Val Loss:\t 0.020568967798357027\n",
      "Epoch:\t 6 Val Loss:\t 0.020565513261320313\n",
      "Epoch:\t 7 Val Loss:\t 0.0205587139966065\n",
      "Epoch:\t 8 Val Loss:\t 0.020557759515044204\n",
      "Epoch:\t 9 Val Loss:\t 0.020555201068783648\n",
      "Epoch:\t 10 Val Loss:\t 0.02055212748005245\n",
      "Epoch:\t 11 Val Loss:\t 0.02055122716468946\n",
      "Epoch:\t 12 Val Loss:\t 0.020546209623208973\n",
      "Epoch:\t 13 Val Loss:\t 0.02055012419473015\n",
      "Epoch:\t 14 Val Loss:\t 0.0205529552838058\n",
      "Epoch:\t 15 Val Loss:\t 0.020547960243557085\n",
      "Epoch:\t 16 Val Loss:\t 0.020549504265763213\n",
      "Epoch:\t 17 Val Loss:\t 0.020552794283097475\n",
      "Epoch:\t 18 Val Loss:\t 0.020549148524458105\n",
      "Epoch:\t 19 Val Loss:\t 0.020536156999093762\n",
      "Epoch:\t 20 Val Loss:\t 0.020535443770440587\n",
      "Epoch:\t 21 Val Loss:\t 0.020539035249268263\n",
      "Epoch:\t 22 Val Loss:\t 0.020535551543746675\n",
      "Epoch:\t 23 Val Loss:\t 0.020537301966768014\n",
      "Epoch:\t 24 Val Loss:\t 0.02053715993334834\n",
      "Epoch:\t 25 Val Loss:\t 0.02053696515089436\n",
      "Epoch:\t 26 Val Loss:\t 0.020537727699281697\n",
      "Epoch:\t 27 Val Loss:\t 0.02053766870754584\n",
      "Epoch:\t 28 Val Loss:\t 0.020536766822538063\n",
      "Epoch:\t 29 Val Loss:\t 0.02053919771796819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:03:58,282] Trial 11 finished with value: 0.020535443770440587 and parameters: {'lr': 0.0001, 'weight_decay': 1e-05, 'scheduler_factor': 0.1, 'scheduler_patience': 5, 'batch_size': 128, 'dropout': 0.15, 'hidden_dims': 64}. Best is trial 11 with value: 0.020535443770440587.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 30 Val Loss:\t 0.020539350972105755\n",
      "Epoch:\t 0 Val Loss:\t 0.02196589240544202\n",
      "Epoch:\t 1 Val Loss:\t 0.02087539615913819\n",
      "Epoch:\t 2 Val Loss:\t 0.020669789826362896\n",
      "Epoch:\t 3 Val Loss:\t 0.020606200095642818\n",
      "Epoch:\t 4 Val Loss:\t 0.02058214277782467\n",
      "Epoch:\t 5 Val Loss:\t 0.02056814855738972\n",
      "Epoch:\t 6 Val Loss:\t 0.02057363907918693\n",
      "Epoch:\t 7 Val Loss:\t 0.020562698215509302\n",
      "Epoch:\t 8 Val Loss:\t 0.02055807314801178\n",
      "Epoch:\t 9 Val Loss:\t 0.02055624487060892\n",
      "Epoch:\t 10 Val Loss:\t 0.020553478438939368\n",
      "Epoch:\t 11 Val Loss:\t 0.020555980712845083\n",
      "Epoch:\t 12 Val Loss:\t 0.02055598817538488\n",
      "Epoch:\t 13 Val Loss:\t 0.020554498268551467\n",
      "Epoch:\t 14 Val Loss:\t 0.020553496434543145\n",
      "Epoch:\t 15 Val Loss:\t 0.02055391249804493\n",
      "Epoch:\t 16 Val Loss:\t 0.02055161887627352\n",
      "Epoch:\t 17 Val Loss:\t 0.020550643077440093\n",
      "Epoch:\t 18 Val Loss:\t 0.020554538762397215\n",
      "Epoch:\t 19 Val Loss:\t 0.020554018866145208\n",
      "Epoch:\t 20 Val Loss:\t 0.020549668468546906\n",
      "Epoch:\t 21 Val Loss:\t 0.020556619106814337\n",
      "Epoch:\t 22 Val Loss:\t 0.02055212218511736\n",
      "Epoch:\t 23 Val Loss:\t 0.020550754833159247\n",
      "Epoch:\t 24 Val Loss:\t 0.02055526649157844\n",
      "Epoch:\t 25 Val Loss:\t 0.02055016380060542\n",
      "Epoch:\t 26 Val Loss:\t 0.020554542753779676\n",
      "Epoch:\t 27 Val Loss:\t 0.020553902144368922\n",
      "Epoch:\t 28 Val Loss:\t 0.0205525816814379\n",
      "Epoch:\t 29 Val Loss:\t 0.02053579098483724\n",
      "Epoch:\t 30 Val Loss:\t 0.020537568629983915\n",
      "Epoch:\t 31 Val Loss:\t 0.020537999750116474\n",
      "Epoch:\t 32 Val Loss:\t 0.020540076766886642\n",
      "Epoch:\t 33 Val Loss:\t 0.020538143353180938\n",
      "Epoch:\t 34 Val Loss:\t 0.020536893013009674\n",
      "Epoch:\t 35 Val Loss:\t 0.020538322331554244\n",
      "Epoch:\t 36 Val Loss:\t 0.020540163758095732\n",
      "Epoch:\t 37 Val Loss:\t 0.02053915403998587\n",
      "Epoch:\t 38 Val Loss:\t 0.020537483357909593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:07:32,435] Trial 12 finished with value: 0.02053579098483724 and parameters: {'lr': 0.0001, 'weight_decay': 1e-05, 'scheduler_factor': 0.1, 'scheduler_patience': 10, 'batch_size': 128, 'dropout': 0.15, 'hidden_dims': 64}. Best is trial 11 with value: 0.020535443770440587.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 39 Val Loss:\t 0.020541345610927617\n",
      "Epoch:\t 0 Val Loss:\t 0.02202886457212664\n",
      "Epoch:\t 1 Val Loss:\t 0.02083353723666928\n",
      "Epoch:\t 2 Val Loss:\t 0.020661593174164213\n",
      "Epoch:\t 3 Val Loss:\t 0.020598788780084008\n",
      "Epoch:\t 4 Val Loss:\t 0.020576673390920817\n",
      "Epoch:\t 5 Val Loss:\t 0.020568107943951988\n",
      "Epoch:\t 6 Val Loss:\t 0.02056240365746316\n",
      "Epoch:\t 7 Val Loss:\t 0.020573986867625106\n",
      "Epoch:\t 8 Val Loss:\t 0.02056391623594692\n",
      "Epoch:\t 9 Val Loss:\t 0.02056103687356697\n",
      "Epoch:\t 10 Val Loss:\t 0.020552971081906873\n",
      "Epoch:\t 11 Val Loss:\t 0.02055387595671425\n",
      "Epoch:\t 12 Val Loss:\t 0.020553631522658357\n",
      "Epoch:\t 13 Val Loss:\t 0.020555799309744306\n",
      "Epoch:\t 14 Val Loss:\t 0.02055157186765445\n",
      "Epoch:\t 15 Val Loss:\t 0.020552454531240615\n",
      "Epoch:\t 16 Val Loss:\t 0.02055472656665893\n",
      "Epoch:\t 17 Val Loss:\t 0.020552703085240355\n",
      "Epoch:\t 18 Val Loss:\t 0.020553589351535034\n",
      "Epoch:\t 19 Val Loss:\t 0.020552502989912493\n",
      "Epoch:\t 20 Val Loss:\t 0.020553488098981866\n",
      "Epoch:\t 21 Val Loss:\t 0.02056036534962838\n",
      "Epoch:\t 22 Val Loss:\t 0.02054056925265594\n",
      "Epoch:\t 23 Val Loss:\t 0.02053948827267267\n",
      "Epoch:\t 24 Val Loss:\t 0.02053809432644714\n",
      "Epoch:\t 25 Val Loss:\t 0.02054332850880646\n",
      "Epoch:\t 26 Val Loss:\t 0.020541683565914917\n",
      "Epoch:\t 27 Val Loss:\t 0.020542309136633696\n",
      "Epoch:\t 28 Val Loss:\t 0.02054023283741543\n",
      "Epoch:\t 29 Val Loss:\t 0.02054282636598446\n",
      "Epoch:\t 30 Val Loss:\t 0.020540755690579237\n",
      "Epoch:\t 31 Val Loss:\t 0.02054264693316162\n",
      "Epoch:\t 32 Val Loss:\t 0.02054681319797211\n",
      "Epoch:\t 33 Val Loss:\t 0.02054251730442047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:10:38,698] Trial 13 finished with value: 0.02053809432644714 and parameters: {'lr': 0.0001, 'weight_decay': 1e-05, 'scheduler_factor': 0.1, 'scheduler_patience': 10, 'batch_size': 128, 'dropout': 0.15, 'hidden_dims': 64}. Best is trial 11 with value: 0.020535443770440587.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 34 Val Loss:\t 0.02054259672844678\n",
      "Epoch:\t 0 Val Loss:\t 0.02116627690425654\n",
      "Epoch:\t 1 Val Loss:\t 0.020679186344936037\n",
      "Epoch:\t 2 Val Loss:\t 0.020609146265094774\n",
      "Epoch:\t 3 Val Loss:\t 0.020584030112738978\n",
      "Epoch:\t 4 Val Loss:\t 0.020584302157594152\n",
      "Epoch:\t 5 Val Loss:\t 0.020573648676443637\n",
      "Epoch:\t 6 Val Loss:\t 0.020573998829813294\n",
      "Epoch:\t 7 Val Loss:\t 0.020559202395319748\n",
      "Epoch:\t 8 Val Loss:\t 0.02056175501446089\n",
      "Epoch:\t 9 Val Loss:\t 0.020555251168855503\n",
      "Epoch:\t 10 Val Loss:\t 0.020551167174360535\n",
      "Epoch:\t 11 Val Loss:\t 0.020554488910478726\n",
      "Epoch:\t 12 Val Loss:\t 0.020557792692850338\n",
      "Epoch:\t 13 Val Loss:\t 0.02055415628331431\n",
      "Epoch:\t 14 Val Loss:\t 0.020556409886618103\n",
      "Epoch:\t 15 Val Loss:\t 0.020556811775479997\n",
      "Epoch:\t 16 Val Loss:\t 0.020555951317135442\n",
      "Epoch:\t 17 Val Loss:\t 0.020556258563891077\n",
      "Epoch:\t 18 Val Loss:\t 0.020556377046659326\n",
      "Epoch:\t 19 Val Loss:\t 0.020560390269608025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:12:25,070] Trial 14 finished with value: 0.020551167174360535 and parameters: {'lr': 0.0001, 'weight_decay': 1e-05, 'scheduler_factor': 0.1, 'scheduler_patience': 10, 'batch_size': 128, 'dropout': 0.15, 'hidden_dims': 128}. Best is trial 11 with value: 0.020535443770440587.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 20 Val Loss:\t 0.02055497449579055\n",
      "Epoch:\t 0 Val Loss:\t 0.02093521228439831\n",
      "Epoch:\t 1 Val Loss:\t 0.02067669252319378\n",
      "Epoch:\t 2 Val Loss:\t 0.020712494730566706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:12:45,070] Trial 15 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 3 Val Loss:\t 0.020659689096372162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:12:50,129] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.0230005740862262\n",
      "Epoch:\t 0 Val Loss:\t 0.02091953902838701\n",
      "Epoch:\t 1 Val Loss:\t 0.020647169122200333\n",
      "Epoch:\t 2 Val Loss:\t 0.020648330297578205\n",
      "Epoch:\t 3 Val Loss:\t 0.020623926488894904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:13:14,928] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 4 Val Loss:\t 0.020622389310340054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:13:20,125] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.02214645373412254\n",
      "Epoch:\t 0 Val Loss:\t 0.02089471299721475\n",
      "Epoch:\t 1 Val Loss:\t 0.020676557740038126\n",
      "Epoch:\t 2 Val Loss:\t 0.02066960394155252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:13:40,550] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 3 Val Loss:\t 0.020672268005473657\n",
      "Epoch:\t 0 Val Loss:\t 0.020646596203496556\n",
      "Epoch:\t 1 Val Loss:\t 0.02064140897490577\n",
      "Epoch:\t 2 Val Loss:\t 0.020586208517631453\n",
      "Epoch:\t 3 Val Loss:\t 0.02058314831371238\n",
      "Epoch:\t 4 Val Loss:\t 0.020579334934482833\n",
      "Epoch:\t 5 Val Loss:\t 0.02058555379412874\n",
      "Epoch:\t 6 Val Loss:\t 0.02057185416298364\n",
      "Epoch:\t 7 Val Loss:\t 0.02057856164447112\n",
      "Epoch:\t 8 Val Loss:\t 0.02057236050459032\n",
      "Epoch:\t 9 Val Loss:\t 0.02057225057679809\n",
      "Epoch:\t 10 Val Loss:\t 0.020577906773524557\n",
      "Epoch:\t 11 Val Loss:\t 0.020577179774910748\n",
      "Epoch:\t 12 Val Loss:\t 0.020582055224699223\n",
      "Epoch:\t 13 Val Loss:\t 0.020547121930830105\n",
      "Epoch:\t 14 Val Loss:\t 0.02054630451964472\n",
      "Epoch:\t 15 Val Loss:\t 0.02055050538804285\n",
      "Epoch:\t 16 Val Loss:\t 0.020547542525063415\n",
      "Epoch:\t 17 Val Loss:\t 0.020548241771011052\n",
      "Epoch:\t 18 Val Loss:\t 0.020547698501997697\n",
      "Epoch:\t 19 Val Loss:\t 0.020551520755107633\n",
      "Epoch:\t 20 Val Loss:\t 0.020545196605618588\n",
      "Epoch:\t 21 Val Loss:\t 0.020544686300571793\n",
      "Epoch:\t 22 Val Loss:\t 0.020545350003965155\n",
      "Epoch:\t 23 Val Loss:\t 0.020547267725179813\n",
      "Epoch:\t 24 Val Loss:\t 0.02054447144613357\n",
      "Epoch:\t 25 Val Loss:\t 0.02054467323294025\n",
      "Epoch:\t 26 Val Loss:\t 0.020549148045674353\n",
      "Epoch:\t 27 Val Loss:\t 0.020544466193772867\n",
      "Epoch:\t 28 Val Loss:\t 0.020545584939136535\n",
      "Epoch:\t 29 Val Loss:\t 0.020544580365708453\n",
      "Epoch:\t 30 Val Loss:\t 0.020550116864900908\n",
      "Epoch:\t 31 Val Loss:\t 0.02054633335033077\n",
      "Epoch:\t 32 Val Loss:\t 0.020544134947155904\n",
      "Epoch:\t 33 Val Loss:\t 0.02054543640009148\n",
      "Epoch:\t 34 Val Loss:\t 0.02054499623651256\n",
      "Epoch:\t 35 Val Loss:\t 0.020544625928099147\n",
      "Epoch:\t 36 Val Loss:\t 0.02054847809327449\n",
      "Epoch:\t 37 Val Loss:\t 0.02054351672701881\n",
      "Epoch:\t 38 Val Loss:\t 0.020546231716348676\n",
      "Epoch:\t 39 Val Loss:\t 0.020543183766320378\n",
      "Epoch:\t 40 Val Loss:\t 0.020546043316324154\n",
      "Epoch:\t 41 Val Loss:\t 0.020543415450261445\n",
      "Epoch:\t 42 Val Loss:\t 0.020548017295021453\n",
      "Epoch:\t 43 Val Loss:\t 0.020543374056239166\n",
      "Epoch:\t 44 Val Loss:\t 0.02054442839103495\n",
      "Epoch:\t 45 Val Loss:\t 0.02054721925198614\n",
      "Epoch:\t 46 Val Loss:\t 0.020552052906107808\n",
      "Epoch:\t 47 Val Loss:\t 0.020545518926469858\n",
      "Epoch:\t 48 Val Loss:\t 0.020545360964829316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:20:50,749] Trial 20 finished with value: 0.020543183766320378 and parameters: {'lr': 0.0001, 'weight_decay': 1e-05, 'scheduler_factor': 0.1, 'scheduler_patience': 5, 'batch_size': 32, 'dropout': 0.15, 'hidden_dims': 128}. Best is trial 11 with value: 0.020535443770440587.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 49 Val Loss:\t 0.020545337803079513\n",
      "Epoch:\t 0 Val Loss:\t 0.022010080011062215\n",
      "Epoch:\t 1 Val Loss:\t 0.02084694904713244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:21:05,865] Trial 21 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 2 Val Loss:\t 0.02069611328072475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:21:11,179] Trial 22 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.02215209150952952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:21:16,424] Trial 23 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.022246596064077716\n",
      "Epoch:\t 0 Val Loss:\t 0.020949326984787638\n",
      "Epoch:\t 1 Val Loss:\t 0.020646413931709805\n",
      "Epoch:\t 2 Val Loss:\t 0.02061887901055105\n",
      "Epoch:\t 3 Val Loss:\t 0.020620776391192003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:21:41,616] Trial 24 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 4 Val Loss:\t 0.020629414230178486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:21:47,004] Trial 25 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.02552449604394543\n",
      "Epoch:\t 0 Val Loss:\t 0.020726838570474037\n",
      "Epoch:\t 1 Val Loss:\t 0.02071795883424098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:22:40,177] Trial 26 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 2 Val Loss:\t 0.020716966126667215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:22:46,029] Trial 27 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.04067061412750622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:22:51,336] Trial 28 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.08852570193010961\n",
      "Epoch:\t 0 Val Loss:\t 0.02089145803643811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:23:34,847] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 1 Val Loss:\t 0.020924378994257423\n",
      "Epoch:\t 0 Val Loss:\t 0.02091033113627047\n",
      "Epoch:\t 1 Val Loss:\t 0.02069746515150055\n",
      "Epoch:\t 2 Val Loss:\t 0.020659055127306314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:23:56,795] Trial 30 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 3 Val Loss:\t 0.02064732156610221\n",
      "Epoch:\t 0 Val Loss:\t 0.020751550272346115\n",
      "Epoch:\t 1 Val Loss:\t 0.0205875253835103\n",
      "Epoch:\t 2 Val Loss:\t 0.02058888119350411\n",
      "Epoch:\t 3 Val Loss:\t 0.020574956612531527\n",
      "Epoch:\t 4 Val Loss:\t 0.020568674197233766\n",
      "Epoch:\t 5 Val Loss:\t 0.020564737478039604\n",
      "Epoch:\t 6 Val Loss:\t 0.020557998336773926\n",
      "Epoch:\t 7 Val Loss:\t 0.020559017336609944\n",
      "Epoch:\t 8 Val Loss:\t 0.020561593618324592\n",
      "Epoch:\t 9 Val Loss:\t 0.020560001218041708\n",
      "Epoch:\t 10 Val Loss:\t 0.02055526637108496\n",
      "Epoch:\t 11 Val Loss:\t 0.020558920331185785\n",
      "Epoch:\t 12 Val Loss:\t 0.02056020276162418\n",
      "Epoch:\t 13 Val Loss:\t 0.0205562330689804\n",
      "Epoch:\t 14 Val Loss:\t 0.020558448996075222\n",
      "Epoch:\t 15 Val Loss:\t 0.020554454077062075\n",
      "Epoch:\t 16 Val Loss:\t 0.02055220337137998\n",
      "Epoch:\t 17 Val Loss:\t 0.020557652709299122\n",
      "Epoch:\t 18 Val Loss:\t 0.020558604159494735\n",
      "Epoch:\t 19 Val Loss:\t 0.02056026480548269\n",
      "Epoch:\t 20 Val Loss:\t 0.02055566333108839\n",
      "Epoch:\t 21 Val Loss:\t 0.020559128863795243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:26:19,038] Trial 31 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 22 Val Loss:\t 0.020554570198871656\n",
      "Epoch:\t 0 Val Loss:\t 0.020751926602845014\n",
      "Epoch:\t 1 Val Loss:\t 0.020603416112655627\n",
      "Epoch:\t 2 Val Loss:\t 0.020579460570655926\n",
      "Epoch:\t 3 Val Loss:\t 0.020571444996161373\n",
      "Epoch:\t 4 Val Loss:\t 0.02057076767146731\n",
      "Epoch:\t 5 Val Loss:\t 0.020561376853928913\n",
      "Epoch:\t 6 Val Loss:\t 0.020560549107569166\n",
      "Epoch:\t 7 Val Loss:\t 0.020557239968344604\n",
      "Epoch:\t 8 Val Loss:\t 0.02055788964911423\n",
      "Epoch:\t 9 Val Loss:\t 0.020557433341382596\n",
      "Epoch:\t 10 Val Loss:\t 0.02055824008630626\n",
      "Epoch:\t 11 Val Loss:\t 0.020558015863861478\n",
      "Epoch:\t 12 Val Loss:\t 0.020555395916785443\n",
      "Epoch:\t 13 Val Loss:\t 0.020558109632435567\n",
      "Epoch:\t 14 Val Loss:\t 0.02053816959488937\n",
      "Epoch:\t 15 Val Loss:\t 0.020540887991798432\n",
      "Epoch:\t 16 Val Loss:\t 0.020540403158858765\n",
      "Epoch:\t 17 Val Loss:\t 0.020540569731913382\n",
      "Epoch:\t 18 Val Loss:\t 0.02054049438963485\n",
      "Epoch:\t 19 Val Loss:\t 0.020543431746680066\n",
      "Epoch:\t 20 Val Loss:\t 0.020541751675110582\n",
      "Epoch:\t 21 Val Loss:\t 0.020539678887142213\n",
      "Epoch:\t 22 Val Loss:\t 0.020541330253512693\n",
      "Epoch:\t 23 Val Loss:\t 0.02053921493016775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:28:53,199] Trial 32 finished with value: 0.02053816959488937 and parameters: {'lr': 0.0001, 'weight_decay': 1e-05, 'scheduler_factor': 0.1, 'scheduler_patience': 5, 'batch_size': 64, 'dropout': 0.05, 'hidden_dims': 64}. Best is trial 11 with value: 0.020535443770440587.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 24 Val Loss:\t 0.02054105013752328\n",
      "Epoch:\t 0 Val Loss:\t 0.02080143448906415\n",
      "Epoch:\t 1 Val Loss:\t 0.02064266912609267\n",
      "Epoch:\t 2 Val Loss:\t 0.020623556503304597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:29:17,928] Trial 33 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 3 Val Loss:\t 0.02062296730547594\n",
      "Epoch:\t 0 Val Loss:\t 0.02079054247569259\n",
      "Epoch:\t 1 Val Loss:\t 0.02068794500534304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:31:24,691] Trial 34 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 2 Val Loss:\t 0.020690923578331095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:31:33,449] Trial 35 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.05540113854623271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:31:39,889] Trial 36 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.025196751124063492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:31:45,812] Trial 37 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03601571098209577\n",
      "Epoch:\t 0 Val Loss:\t 0.02089879646712097\n",
      "Epoch:\t 1 Val Loss:\t 0.020809365569374134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:32:16,270] Trial 38 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 2 Val Loss:\t 0.020685392368432514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:32:25,195] Trial 39 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.03167112494160035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:32:31,321] Trial 40 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.030801211751895898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:32:36,933] Trial 41 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.022140797179784285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:32:42,833] Trial 42 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.022078858574861318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:32:48,682] Trial 43 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.02218603380443005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:32:54,567] Trial 44 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.022124135226944095\n",
      "Epoch:\t 0 Val Loss:\t 0.020686604423969506\n",
      "Epoch:\t 1 Val Loss:\t 0.020648458673112647\n",
      "Epoch:\t 2 Val Loss:\t 0.020630134245638296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:33:17,834] Trial 45 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 3 Val Loss:\t 0.020665909004939715\n",
      "Epoch:\t 0 Val Loss:\t 0.020979286005562037\n",
      "Epoch:\t 1 Val Loss:\t 0.02077902135040079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:33:36,817] Trial 46 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 2 Val Loss:\t 0.02073137966219342\n",
      "Epoch:\t 0 Val Loss:\t 0.02103623749918482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:33:48,643] Trial 47 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 1 Val Loss:\t 0.02123476375629871\n",
      "Epoch:\t 0 Val Loss:\t 0.020825477105370745\n",
      "Epoch:\t 1 Val Loss:\t 0.020800858720736976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:34:46,697] Trial 48 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 2 Val Loss:\t 0.02079721570367255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 21:34:52,620] Trial 49 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 Val Loss:\t 0.02223244510638867\n",
      "Training model with best parameters on train+validation ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401917/401917 [04:17<00:00, 1559.59it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401917/401917 [01:14<00:00, 5410.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting test set predictions and saving results ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 611/611 [00:03<00:00, 178.20it/s]\n"
     ]
    }
   ],
   "source": [
    "train_different_featno(\n",
    "        adata_path=\"./data/feature_number/sciplex_hvg_7500.h5ad\",\n",
    "        run_name=\"mlp_hvg_7500\",\n",
    "        res_savename=\"./results/feature_number/mlp_hvg_7500_res.pkl\",\n",
    "        input_dim=7500,\n",
    "        output_dim=7500,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a6fdd-7a3d-44d1-8bb1-34412adc5944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
