{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02020ce9-8d49-4351-8d27-fef1e62d4250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluator.FiLM_unicond_evaluator import FiLMModelEvaluator\n",
    "from models.FiLM_unicod import FiLMModel\n",
    "from evaluator.evaluator_utils import l2_loss\n",
    "from utils import *\n",
    "from dataset.dataset_unseen_compounds import SciplexDatasetUnseenPerturbations\n",
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import anndata as ad\n",
    "import math\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84266e47-0d8e-4117-9237-7921e031e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read PRNet splits\n",
    "with open(\"../data/sciplex/prnet_drug_splits.pkl\", \"rb\") as f:\n",
    "    drug_splits = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71a70afe-956b-4e4b-b329-7753b29afe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_train = drug_splits['drug_split_0']['train']\n",
    "drugs_validation = drug_splits['drug_split_0']['valid']\n",
    "drugs_test = drug_splits['drug_split_0']['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79041e05-43e8-487e-b181-11f2468090bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 571696/571696 [01:19<00:00, 7211.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 571696/571696 [00:40<00:00, 13947.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 571696/571696 [00:33<00:00, 17323.28it/s]\n"
     ]
    }
   ],
   "source": [
    "ad_path = \"../data/sciplex/sciplex_final.h5ad\"\n",
    "adata = ad.read_h5ad(ad_path)\n",
    "\n",
    "dataset_train = SciplexDatasetUnseenPerturbations(adata, drugs_train, \"sm_coati_emb\", 256, \"X_5000_hvg\", \"X_5000_hvg\")\n",
    "dataset_validation = SciplexDatasetUnseenPerturbations(adata, drugs_validation, \"sm_coati_emb\", 256, \"X_5000_hvg\", \"X_5000_hvg\")\n",
    "dataset_test = SciplexDatasetUnseenPerturbations(adata, drugs_test, \"sm_coati_emb\", 256, \"X_5000_hvg\", \"X_5000_hvg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3ca687c-dd66-4293-8510-405a3ad3168a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 1/100 Validation Loss: 0.023718348822397428\n",
      "Epoch 2/100\n",
      "Epoch 2/100 Validation Loss: 0.023663606331115816\n",
      "Epoch 3/100\n",
      "Epoch 3/100 Validation Loss: 0.02382677100689673\n",
      "Epoch 4/100\n",
      "Epoch 4/100 Validation Loss: 0.023885172510110752\n",
      "Epoch 5/100\n",
      "Epoch 5/100 Validation Loss: 0.023896988896971068\n",
      "Epoch 6/100\n",
      "Epoch 6/100 Validation Loss: 0.0239131490836238\n",
      "Epoch 7/100\n",
      "Epoch 7/100 Validation Loss: 0.02390990810605084\n",
      "Epoch 8/100\n",
      "Epoch 8/100 Validation Loss: 0.023905132692761538\n",
      "Epoch 9/100\n",
      "Epoch 9/100 Validation Loss: 0.02388658391357195\n",
      "Epoch 10/100\n",
      "Epoch 10/100 Validation Loss: 0.023889183920876283\n",
      "Epoch 11/100\n",
      "Epoch 11/100 Validation Loss: 0.023881828918962216\n",
      "Epoch 12/100\n",
      "Epoch 12/100 Validation Loss: 0.02388665498029895\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m ev \u001b[38;5;241m=\u001b[39m FiLMModelEvaluator(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../config/FiLM.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,FiLMModel, dataset_train, dataset_validation, dataset_test)\n\u001b[0;32m----> 2\u001b[0m ev\u001b[38;5;241m.\u001b[39mtrain(l2_loss)\n\u001b[1;32m      3\u001b[0m ev\u001b[38;5;241m.\u001b[39mtest()\n\u001b[1;32m      4\u001b[0m results \u001b[38;5;241m=\u001b[39m ev\u001b[38;5;241m.\u001b[39mget_test_results()\n",
      "File \u001b[0;32m~/projects/dege-fm/src/evaluator/FiLM_unicond_evaluator.py:73\u001b[0m, in \u001b[0;36mFiLMModelEvaluator.train\u001b[0;34m(self, loss_fn)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m control, drug_emb, target, meta \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msciplex_loader_train:\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;66;03m# Move tensors to the specified device\u001b[39;00m\n\u001b[1;32m     75\u001b[0m         control \u001b[38;5;241m=\u001b[39m control\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     76\u001b[0m         drug_emb \u001b[38;5;241m=\u001b[39m drug_emb\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[38;5;241m=\u001b[39mdefault_collate_fn_map)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:212\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 212\u001b[0m         collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[1;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:172\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMutableMapping):\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# The mapping type may have extra properties, so we can't just\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# use `type(data)(...)` to create the new mapping.\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# Create a clone and update it if the mapping type is mutable.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     clone \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(elem)\n\u001b[1;32m    170\u001b[0m     clone\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    171\u001b[0m         {\n\u001b[0;32m--> 172\u001b[0m             key: collate(\n\u001b[1;32m    173\u001b[0m                 [d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map\n\u001b[1;32m    174\u001b[0m             )\n\u001b[1;32m    175\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem\n\u001b[1;32m    176\u001b[0m         }\n\u001b[1;32m    177\u001b[0m     )\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m clone\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:155\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:301\u001b[0m, in \u001b[0;36mcollate_float_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcollate_float_fn\u001b[39m(\n\u001b[1;32m    297\u001b[0m     batch,\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    299\u001b[0m     collate_fn_map: Optional[Dict[Union[Type, Tuple[Type, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]], Callable]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    300\u001b[0m ):\n\u001b[0;32m--> 301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(batch, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ev = FiLMModelEvaluator(\"../config/FiLM.yaml\",FiLMModel, dataset_train, dataset_validation, dataset_test)\n",
    "ev.train(l2_loss)\n",
    "ev.test()\n",
    "results = ev.get_test_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71ef5ff4-799c-43b1-bb34-7ab08aac3e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ctrl_emb</th>\n",
       "      <th>pert_emb</th>\n",
       "      <th>pred_emb</th>\n",
       "      <th>compound</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>dose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.10697009, 0.29219335, 0.01033105, 0.0304261...</td>\n",
       "      <td>UNC1999</td>\n",
       "      <td>A549</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.1749853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.12766299, 0.066295005, 0.0045654313, 0.0261...</td>\n",
       "      <td>UNC1999</td>\n",
       "      <td>K562</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 1.6583109, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.10694998, 0.29218647, 0.010329181, 0.030434...</td>\n",
       "      <td>ENMD-2076</td>\n",
       "      <td>A549</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.12777036, 0.06663413, 0.0045759166, 0.02619...</td>\n",
       "      <td>Daphnetin</td>\n",
       "      <td>K562</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0031049491, 0.07116195, 0.0011935143, 0.025...</td>\n",
       "      <td>Entacapone</td>\n",
       "      <td>MCF7</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27229</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0030677235, 0.07116833, 0.0011933371, 0.025...</td>\n",
       "      <td>PHA-680632</td>\n",
       "      <td>MCF7</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27230</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0030965123, 0.07118223, 0.001194037, 0.0251...</td>\n",
       "      <td>MLN8054</td>\n",
       "      <td>MCF7</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27231</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.12777656, 0.06665549, 0.004576828, 0.026190...</td>\n",
       "      <td>Meprednisone</td>\n",
       "      <td>K562</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27232</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.12776189, 0.066633224, 0.0045758095, 0.0261...</td>\n",
       "      <td>Entacapone</td>\n",
       "      <td>K562</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27233</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.12776366, 0.06654698, 0.0045742663, 0.02617...</td>\n",
       "      <td>Entacapone</td>\n",
       "      <td>K562</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27234 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                ctrl_emb  \\\n",
       "0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "...                                                  ...   \n",
       "27229  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "27230  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "27231  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "27232  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "27233  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                pert_emb  \\\n",
       "0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1      [1.1749853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "2      [0.0, 1.6583109, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "...                                                  ...   \n",
       "27229  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "27230  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "27231  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "27232  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "27233  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                pred_emb      compound  \\\n",
       "0      [0.10697009, 0.29219335, 0.01033105, 0.0304261...       UNC1999   \n",
       "1      [0.12766299, 0.066295005, 0.0045654313, 0.0261...       UNC1999   \n",
       "2      [0.10694998, 0.29218647, 0.010329181, 0.030434...     ENMD-2076   \n",
       "3      [0.12777036, 0.06663413, 0.0045759166, 0.02619...     Daphnetin   \n",
       "4      [0.0031049491, 0.07116195, 0.0011935143, 0.025...    Entacapone   \n",
       "...                                                  ...           ...   \n",
       "27229  [0.0030677235, 0.07116833, 0.0011933371, 0.025...    PHA-680632   \n",
       "27230  [0.0030965123, 0.07118223, 0.001194037, 0.0251...       MLN8054   \n",
       "27231  [0.12777656, 0.06665549, 0.004576828, 0.026190...  Meprednisone   \n",
       "27232  [0.12776189, 0.066633224, 0.0045758095, 0.0261...    Entacapone   \n",
       "27233  [0.12776366, 0.06654698, 0.0045742663, 0.02617...    Entacapone   \n",
       "\n",
       "      cell_type     dose  \n",
       "0          A549  10000.0  \n",
       "1          K562  10000.0  \n",
       "2          A549   1000.0  \n",
       "3          K562     10.0  \n",
       "4          MCF7    100.0  \n",
       "...         ...      ...  \n",
       "27229      MCF7     10.0  \n",
       "27230      MCF7     10.0  \n",
       "27231      K562   1000.0  \n",
       "27232      K562  10000.0  \n",
       "27233      K562     10.0  \n",
       "\n",
       "[27234 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae8d416e-1436-45d5-9589-788cd1c4e58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_control = ad.read_h5ad(\"../data/sciplex/sciplex_final.h5ad\")\n",
    "gene_names = adata_control.uns['gene_names_5000']\n",
    "adata_control = adata_control[adata_control.obs['product_name'] == \"Vehicle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81b619d3-d6b2-4b47-a290-daef6be75e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/.local/lib/python3.12/site-packages/anndata/_core/anndata.py:1756: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    }
   ],
   "source": [
    "performance = get_model_stats(results, adata_control, \"X_5000_hvg\", gene_names, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fe7ac14-7272-4e82-a52d-b11488b86290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key': 'test',\n",
       " 'mse_A549': np.float32(0.0004479424),\n",
       " 'std_mse_A549': np.float32(0.0002185618),\n",
       " 'mse_K562': np.float32(0.00045829226),\n",
       " 'std_mse_K562': np.float32(0.00051411265),\n",
       " 'mse_MCF7': np.float32(0.00015553916),\n",
       " 'std_mse_MCF7': np.float32(7.552573e-05),\n",
       " 'r2_A549': np.float64(0.9707931213908725),\n",
       " 'std_r2_A549': np.float64(0.0056597559336654234),\n",
       " 'r2_K562': np.float64(0.9524753292401632),\n",
       " 'std_r2_K562': np.float64(0.05715454840811647),\n",
       " 'r2_MCF7': np.float64(0.9876757595274184),\n",
       " 'std_r2_MCF7': np.float64(0.0056597559336654234),\n",
       " 'rank_logfc_A549': np.float64(0.4984126984126983),\n",
       " 'std_rank_logfc_A549': np.float64(0.29901155715569455),\n",
       " 'rank_logfc_K562': np.float64(0.5007936507936508),\n",
       " 'std_rank_logfc_K562': np.float64(0.2984834009454457),\n",
       " 'rank_logfc_MCF7': np.float64(0.5023809523809523),\n",
       " 'std_rank_logfc_MCF7': np.float64(0.3081195250602532)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594ef74d-f1c8-40f3-974a-164833a0bc4a",
   "metadata": {},
   "source": [
    "Input is embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94dfda39-d004-4277-8cf4-eff8169b58db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 571696/571696 [01:17<00:00, 7404.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 571696/571696 [00:40<00:00, 13986.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 571696/571696 [00:32<00:00, 17498.91it/s]\n"
     ]
    }
   ],
   "source": [
    "ad_path = \"../data/sciplex/sciplex_final.h5ad\"\n",
    "adata = ad.read_h5ad(ad_path)\n",
    "\n",
    "dataset_train = SciplexDatasetUnseenPerturbations(adata, drugs_train, \"sm_coati_emb\", 256, \"X_uce\", \"X_5000_hvg\")\n",
    "dataset_validation = SciplexDatasetUnseenPerturbations(adata, drugs_validation, \"sm_coati_emb\", 256, \"X_uce\", \"X_5000_hvg\")\n",
    "dataset_test = SciplexDatasetUnseenPerturbations(adata, drugs_test, \"sm_coati_emb\", 256, \"X_uce\", \"X_5000_hvg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "821e23a4-e08e-4c90-804f-036e0c787e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training ...\n",
      "Epoch 1/5\n",
      "Iteration: 100 Test Loss: 0.03051004186272621 Avg. Validation Loss: 0.029551153034880394\n",
      "Iteration: 200 Test Loss: 0.0287473164498806 Avg. Validation Loss: 0.027110976014831444\n",
      "Iteration: 300 Test Loss: 0.025179265066981316 Avg. Validation Loss: 0.025405936479205037\n",
      "Iteration: 400 Test Loss: 0.023532552644610405 Avg. Validation Loss: 0.024814808186961385\n",
      "Iteration: 500 Test Loss: 0.023969629779458046 Avg. Validation Loss: 0.0243900069444463\n",
      "Iteration: 600 Test Loss: 0.02487177588045597 Avg. Validation Loss: 0.02423846522209848\n",
      "Iteration: 700 Test Loss: 0.02517470344901085 Avg. Validation Loss: 0.024089415216954742\n",
      "Iteration: 800 Test Loss: 0.02509240061044693 Avg. Validation Loss: 0.024047689948503564\n",
      "Iteration: 900 Test Loss: 0.024241549894213676 Avg. Validation Loss: 0.02392287068296133\n",
      "Iteration: 1000 Test Loss: 0.02795124426484108 Avg. Validation Loss: 0.023909342752360715\n",
      "Iteration: 1100 Test Loss: 0.021746398881077766 Avg. Validation Loss: 0.023805605440695838\n",
      "Iteration: 1200 Test Loss: 0.02262364700436592 Avg. Validation Loss: 0.023759205489442117\n",
      "Iteration: 1300 Test Loss: 0.02363738603889942 Avg. Validation Loss: 0.023757027250873607\n",
      "Iteration: 1400 Test Loss: 0.02407250553369522 Avg. Validation Loss: 0.023753721768990523\n",
      "Iteration: 1500 Test Loss: 0.025645622983574867 Avg. Validation Loss: 0.023757914028970935\n",
      "Iteration: 1600 Test Loss: 0.026013804599642754 Avg. Validation Loss: 0.023750819070491848\n",
      "Iteration: 1700 Test Loss: 0.02474626898765564 Avg. Validation Loss: 0.023733997385858036\n",
      "Iteration: 1800 Test Loss: 0.026581017300486565 Avg. Validation Loss: 0.02374600328096166\n",
      "Iteration: 1900 Test Loss: 0.02718287892639637 Avg. Validation Loss: 0.023741995222957397\n",
      "Iteration: 2000 Test Loss: 0.020232610404491425 Avg. Validation Loss: 0.023712381066345586\n",
      "Iteration: 2100 Test Loss: 0.024889709427952766 Avg. Validation Loss: 0.023713113217637305\n",
      "Iteration: 2200 Test Loss: 0.02170337550342083 Avg. Validation Loss: 0.02371638271866775\n",
      "Iteration: 2300 Test Loss: 0.026195542886853218 Avg. Validation Loss: 0.023698995237397713\n",
      "Iteration: 2400 Test Loss: 0.025062628090381622 Avg. Validation Loss: 0.023709916977620708\n",
      "Iteration: 2500 Test Loss: 0.022416533902287483 Avg. Validation Loss: 0.023708347410599632\n",
      "Iteration: 2600 Test Loss: 0.0230880007147789 Avg. Validation Loss: 0.023720086068369266\n",
      "Epoch 2/5\n",
      "Iteration: 2700 Test Loss: 0.02669900469481945 Avg. Validation Loss: 0.023730887431742214\n",
      "Iteration: 2800 Test Loss: 0.026767168194055557 Avg. Validation Loss: 0.023722022717318884\n",
      "Iteration: 2900 Test Loss: 0.022502167150378227 Avg. Validation Loss: 0.023680657863889527\n",
      "Iteration: 3000 Test Loss: 0.024770325049757957 Avg. Validation Loss: 0.023706879398626524\n",
      "Iteration: 3100 Test Loss: 0.022584982216358185 Avg. Validation Loss: 0.02369530153029212\n",
      "Iteration: 3200 Test Loss: 0.02579818107187748 Avg. Validation Loss: 0.02369994076150583\n",
      "Iteration: 3300 Test Loss: 0.02552751637995243 Avg. Validation Loss: 0.023700669675883725\n",
      "Iteration: 3400 Test Loss: 0.022631719708442688 Avg. Validation Loss: 0.0236858985159637\n",
      "Iteration: 3500 Test Loss: 0.0236820075660944 Avg. Validation Loss: 0.02369321526323513\n",
      "Iteration: 3600 Test Loss: 0.024838043376803398 Avg. Validation Loss: 0.023688558857070236\n",
      "Iteration: 3700 Test Loss: 0.02252248302102089 Avg. Validation Loss: 0.023706617476645767\n",
      "Iteration: 3800 Test Loss: 0.02579694241285324 Avg. Validation Loss: 0.02369431532783116\n",
      "Iteration: 3900 Test Loss: 0.024832259863615036 Avg. Validation Loss: 0.02382825819275728\n",
      "Iteration: 4000 Test Loss: 0.02328772284090519 Avg. Validation Loss: 0.023689096611810893\n",
      "Iteration: 4100 Test Loss: 0.023078734055161476 Avg. Validation Loss: 0.023690133868921093\n",
      "Iteration: 4200 Test Loss: 0.023028692230582237 Avg. Validation Loss: 0.023687265120537544\n",
      "Iteration: 4300 Test Loss: 0.02247747965157032 Avg. Validation Loss: 0.023695190964130367\n",
      "Iteration: 4400 Test Loss: 0.025544892996549606 Avg. Validation Loss: 0.02371612881514721\n",
      "Iteration: 4500 Test Loss: 0.024621961638331413 Avg. Validation Loss: 0.02369089034363264\n",
      "Iteration: 4600 Test Loss: 0.022780898958444595 Avg. Validation Loss: 0.023702171849223172\n",
      "Iteration: 4700 Test Loss: 0.02534579485654831 Avg. Validation Loss: 0.023689919253584088\n",
      "Iteration: 4800 Test Loss: 0.02424328587949276 Avg. Validation Loss: 0.02370180775434142\n",
      "Iteration: 4900 Test Loss: 0.023867616429924965 Avg. Validation Loss: 0.023691853828637338\n",
      "Iteration: 5000 Test Loss: 0.02604380063712597 Avg. Validation Loss: 0.023698417419885716\n",
      "Iteration: 5100 Test Loss: 0.026058753952383995 Avg. Validation Loss: 0.023694886364860505\n",
      "Iteration: 5200 Test Loss: 0.025661351159214973 Avg. Validation Loss: 0.02369447605366387\n",
      "Iteration: 5300 Test Loss: 0.02455112151801586 Avg. Validation Loss: 0.02370091361652424\n",
      "Epoch 3/5\n",
      "Iteration: 5400 Test Loss: 0.022191209718585014 Avg. Validation Loss: 0.023691044354856743\n",
      "Iteration: 5500 Test Loss: 0.02763141319155693 Avg. Validation Loss: 0.023698616068719362\n",
      "Iteration: 5600 Test Loss: 0.02652059495449066 Avg. Validation Loss: 0.02370514754069651\n",
      "Iteration: 5700 Test Loss: 0.02480260469019413 Avg. Validation Loss: 0.02370910486660716\n",
      "Iteration: 5800 Test Loss: 0.02508039027452469 Avg. Validation Loss: 0.023722934986396535\n",
      "Iteration: 5900 Test Loss: 0.02487129531800747 Avg. Validation Loss: 0.02372119251138917\n",
      "Iteration: 6000 Test Loss: 0.022051295265555382 Avg. Validation Loss: 0.023713666355101075\n",
      "Iteration: 6100 Test Loss: 0.024448378011584282 Avg. Validation Loss: 0.023717814340914894\n",
      "Iteration: 6200 Test Loss: 0.025715788826346397 Avg. Validation Loss: 0.023718821573093896\n",
      "Iteration: 6300 Test Loss: 0.022600185126066208 Avg. Validation Loss: 0.02375996396536144\n",
      "Iteration: 6400 Test Loss: 0.024995794519782066 Avg. Validation Loss: 0.02371513767440508\n",
      "Iteration: 6500 Test Loss: 0.02382604219019413 Avg. Validation Loss: 0.0237225734878604\n",
      "Iteration: 6600 Test Loss: 0.023344337940216064 Avg. Validation Loss: 0.02373021774720855\n",
      "Iteration: 6700 Test Loss: 0.027009913697838783 Avg. Validation Loss: 0.02373832155291627\n",
      "Iteration: 6800 Test Loss: 0.02494269609451294 Avg. Validation Loss: 0.023796883784234522\n",
      "Iteration: 6900 Test Loss: 0.02395787090063095 Avg. Validation Loss: 0.023744027496020243\n",
      "Iteration: 7000 Test Loss: 0.022617388516664505 Avg. Validation Loss: 0.023777526971407052\n",
      "Iteration: 7100 Test Loss: 0.02541179209947586 Avg. Validation Loss: 0.02376868874970369\n",
      "Iteration: 7200 Test Loss: 0.023394787684082985 Avg. Validation Loss: 0.023773220783417544\n",
      "Iteration: 7300 Test Loss: 0.025728311389684677 Avg. Validation Loss: 0.024162621737071652\n",
      "Iteration: 7400 Test Loss: 0.022563451901078224 Avg. Validation Loss: 0.023799822077427694\n",
      "Iteration: 7500 Test Loss: 0.023783843964338303 Avg. Validation Loss: 0.023793959606257152\n",
      "Iteration: 7600 Test Loss: 0.024115875363349915 Avg. Validation Loss: 0.023801428656570794\n",
      "Iteration: 7700 Test Loss: 0.025502841919660568 Avg. Validation Loss: 0.02381620519317505\n",
      "Iteration: 7800 Test Loss: 0.027122441679239273 Avg. Validation Loss: 0.02383884447286042\n",
      "Iteration: 7900 Test Loss: 0.022273296490311623 Avg. Validation Loss: 0.023838099866832902\n",
      "Iteration: 8000 Test Loss: 0.023003410547971725 Avg. Validation Loss: 0.02386081104462103\n",
      "Epoch 4/5\n",
      "Iteration: 8100 Test Loss: 0.020501721650362015 Avg. Validation Loss: 0.02385218774490967\n",
      "Iteration: 8200 Test Loss: 0.024578871205449104 Avg. Validation Loss: 0.023854897100841852\n",
      "Iteration: 8300 Test Loss: 0.023963863030076027 Avg. Validation Loss: 0.02387022776302041\n",
      "Iteration: 8400 Test Loss: 0.022148746997117996 Avg. Validation Loss: 0.023879796832163885\n",
      "Iteration: 8500 Test Loss: 0.02561030164361 Avg. Validation Loss: 0.023874790273697637\n",
      "Iteration: 8600 Test Loss: 0.023731209337711334 Avg. Validation Loss: 0.023861007074393877\n",
      "Iteration: 8700 Test Loss: 0.02229921892285347 Avg. Validation Loss: 0.02386404095308446\n",
      "Iteration: 8800 Test Loss: 0.0255171749740839 Avg. Validation Loss: 0.023863740503878857\n",
      "Iteration: 8900 Test Loss: 0.025838110595941544 Avg. Validation Loss: 0.023932519502846934\n",
      "Iteration: 9000 Test Loss: 0.02550824172794819 Avg. Validation Loss: 0.02386845229647872\n",
      "Iteration: 9100 Test Loss: 0.0248337984085083 Avg. Validation Loss: 0.023902361240328813\n",
      "Iteration: 9200 Test Loss: 0.022064607590436935 Avg. Validation Loss: 0.023904931938230265\n",
      "Iteration: 9300 Test Loss: 0.02715465985238552 Avg. Validation Loss: 0.0239106508607908\n",
      "Iteration: 9400 Test Loss: 0.02203868329524994 Avg. Validation Loss: 0.023897387875562035\n",
      "Iteration: 9500 Test Loss: 0.02387397363781929 Avg. Validation Loss: 0.02389270618058196\n",
      "Iteration: 9600 Test Loss: 0.021742556244134903 Avg. Validation Loss: 0.023902977855376355\n",
      "Iteration: 9700 Test Loss: 0.02368667535483837 Avg. Validation Loss: 0.02390764835177035\n",
      "Iteration: 9800 Test Loss: 0.023832807317376137 Avg. Validation Loss: 0.0239074005336478\n",
      "Iteration: 9900 Test Loss: 0.021394427865743637 Avg. Validation Loss: 0.023922786148401296\n",
      "Iteration: 10000 Test Loss: 0.023723464459180832 Avg. Validation Loss: 0.023917856705715744\n",
      "Iteration: 10100 Test Loss: 0.0243118517100811 Avg. Validation Loss: 0.02392702199200668\n",
      "Iteration: 10200 Test Loss: 0.021704481914639473 Avg. Validation Loss: 0.023934607859700918\n",
      "Iteration: 10300 Test Loss: 0.02461555041372776 Avg. Validation Loss: 0.02394846232789682\n",
      "Iteration: 10400 Test Loss: 0.02352028898894787 Avg. Validation Loss: 0.023952110843142357\n",
      "Iteration: 10500 Test Loss: 0.025394458323717117 Avg. Validation Loss: 0.023952215866799034\n",
      "Iteration: 10600 Test Loss: 0.025584734976291656 Avg. Validation Loss: 0.023951056113512052\n",
      "Epoch 5/5\n",
      "Iteration: 10700 Test Loss: 0.02439676970243454 Avg. Validation Loss: 0.023974849099702225\n",
      "Iteration: 10800 Test Loss: 0.023631738498806953 Avg. Validation Loss: 0.023975098555589595\n",
      "Iteration: 10900 Test Loss: 0.026482101529836655 Avg. Validation Loss: 0.023981019227606495\n",
      "Iteration: 11000 Test Loss: 0.028097569942474365 Avg. Validation Loss: 0.023975717108242395\n",
      "Iteration: 11100 Test Loss: 0.025256160646677017 Avg. Validation Loss: 0.023980755261259108\n",
      "Iteration: 11200 Test Loss: 0.022624125704169273 Avg. Validation Loss: 0.023970413278424887\n",
      "Iteration: 11300 Test Loss: 0.028271568939089775 Avg. Validation Loss: 0.02398243839966088\n",
      "Iteration: 11400 Test Loss: 0.024305596947669983 Avg. Validation Loss: 0.023966107240355597\n",
      "Iteration: 11500 Test Loss: 0.02572188340127468 Avg. Validation Loss: 0.023974296053099198\n",
      "Iteration: 11600 Test Loss: 0.023408815264701843 Avg. Validation Loss: 0.023978244311108093\n",
      "Iteration: 11700 Test Loss: 0.023356689140200615 Avg. Validation Loss: 0.02397254064179412\n",
      "Iteration: 11800 Test Loss: 0.023862279951572418 Avg. Validation Loss: 0.023971570001506223\n",
      "Iteration: 11900 Test Loss: 0.021661153063178062 Avg. Validation Loss: 0.024030597060464506\n",
      "Iteration: 12000 Test Loss: 0.023184530436992645 Avg. Validation Loss: 0.023985063002967252\n",
      "Iteration: 12100 Test Loss: 0.026153990998864174 Avg. Validation Loss: 0.023992121274151453\n",
      "Iteration: 12200 Test Loss: 0.023386714980006218 Avg. Validation Loss: 0.023995049141074826\n",
      "Iteration: 12300 Test Loss: 0.024457860738039017 Avg. Validation Loss: 0.024002091241319006\n",
      "Iteration: 12400 Test Loss: 0.02332250215113163 Avg. Validation Loss: 0.023988941747967788\n",
      "Iteration: 12500 Test Loss: 0.020277114585042 Avg. Validation Loss: 0.02397975798287406\n",
      "Iteration: 12600 Test Loss: 0.022767052054405212 Avg. Validation Loss: 0.023964248470416883\n",
      "Iteration: 12700 Test Loss: 0.02511296607553959 Avg. Validation Loss: 0.023974738285944958\n",
      "Iteration: 12800 Test Loss: 0.024413293227553368 Avg. Validation Loss: 0.02397390794599565\n",
      "Iteration: 12900 Test Loss: 0.025226978585124016 Avg. Validation Loss: 0.023979419408502376\n",
      "Iteration: 13000 Test Loss: 0.025025073438882828 Avg. Validation Loss: 0.023994668398234175\n",
      "Iteration: 13100 Test Loss: 0.02309543453156948 Avg. Validation Loss: 0.02397922756286656\n",
      "Iteration: 13200 Test Loss: 0.02266000397503376 Avg. Validation Loss: 0.02399305338494298\n",
      "Iteration: 13300 Test Loss: 0.023446956649422646 Avg. Validation Loss: 0.023976748227709677\n",
      "Training completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 426/426 [00:01<00:00, 304.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing completed. Results stored in 'self.test_results'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evalautor = FiLMModelEvaluator(\"../config/FiLM.yaml\",FiLMModel, dataset_train, dataset_validation, dataset_test)\n",
    "evalautor.train()\n",
    "evalautor.test()\n",
    "results = evalautor.get_test_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f8de702-64f4-407a-a26e-90e8a0548aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_control = ad.read_h5ad(\"../data/sciplex/sciplex_final.h5ad\")\n",
    "gene_names = adata_control.uns['gene_names_5000']\n",
    "adata_control = adata_control[adata_control.obs['product_name'] == \"Vehicle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbc9ebc3-c90c-4a31-8deb-5e6c562b3f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/.local/lib/python3.12/site-packages/anndata/_core/anndata.py:1756: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    }
   ],
   "source": [
    "performance = get_model_stats(results, adata_control, \"X_5000_hvg\", gene_names, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13f4455e-38a6-4525-9f15-b8c7f10322a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key': 'test',\n",
       " 'mse_A549': np.float32(0.00036196486),\n",
       " 'std_mse_A549': np.float32(0.00019244739),\n",
       " 'mse_K562': np.float32(0.00041910863),\n",
       " 'std_mse_K562': np.float32(0.0005383968),\n",
       " 'mse_MCF7': np.float32(0.00015627808),\n",
       " 'std_mse_MCF7': np.float32(8.094748e-05),\n",
       " 'r2_A549': np.float64(0.9764206343226962),\n",
       " 'std_r2_A549': np.float64(0.006089159532163539),\n",
       " 'r2_K562': np.float64(0.9563086960050795),\n",
       " 'std_r2_K562': np.float64(0.05968984914235292),\n",
       " 'r2_MCF7': np.float64(0.9876242346233792),\n",
       " 'std_r2_MCF7': np.float64(0.006089159532163539),\n",
       " 'rank_logfc_A549': np.float64(0.4976190476190476),\n",
       " 'std_rank_logfc_A549': np.float64(0.29588063720683533),\n",
       " 'rank_logfc_K562': np.float64(0.5007936507936508),\n",
       " 'std_rank_logfc_K562': np.float64(0.30128117295162515),\n",
       " 'rank_logfc_MCF7': np.float64(0.5095238095238095),\n",
       " 'std_rank_logfc_MCF7': np.float64(0.24803079320200797)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48aa6ed-ba6a-439c-815d-51b7f35c41eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
